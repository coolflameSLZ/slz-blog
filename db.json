{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/img/home_banner.png","path":"img/home_banner.png","modified":1,"renderable":0},{"_id":"source/img/other_banner.png","path":"img/other_banner.png","modified":1,"renderable":0},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"node_modules/hexo-theme-fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"c72e2b37a792c600a11ac5de227116801220c84c","modified":1627613034754},{"_id":"source/about/index.md","hash":"dfe6e6e5065fdea76d7e472bc354b6907b78d81b","modified":1627568393246},{"_id":"source/_posts/mycat/mycat【1】配置文件概述.md","hash":"0707accbf1036f0a1a5c4f23419da36b89542829","modified":1627800842756},{"_id":"source/_posts/mycat/mycat【2】分库配置实践.md","hash":"8a27a65a0e6acdaf4494ebd9e38ba79e6cb787cb","modified":1627800972003},{"_id":"source/_posts/mycat/mycat【3】高可用方案.md","hash":"7bd2cbf78c6c46334436ffd044ced7acc54548cb","modified":1627800912491},{"_id":"source/_posts/mycat/mycat【4】容器化.md","hash":"fa151b52ec9bbc65374af7f95dd8cffe3a04517f","modified":1627801008457},{"_id":"source/_posts/mycat/mycat【5】使用技巧.md","hash":"8031660950803b7e3b109ee9525dab094ef37685","modified":1627810671384},{"_id":"source/_posts/mycat/mycat【6】一次mycat在线分库记录.md","hash":"93573e5c1049fa60069679e9f8c62048930d17d8","modified":1627809374457},{"_id":"source/_posts/mysql/innodb存储实现.md","hash":"d73a7e7872982ae6c2cf99ce970bd019985ae1fa","modified":1627743421690},{"_id":"source/_posts/mysql/innodb索引优化.md","hash":"3240eea04a5a29d219d0cd53dd342fd4d65c6ae1","modified":1627743424976},{"_id":"source/_posts/mysql/分库分表策略概述.md","hash":"f593d76dcf45f484f5ada8cf782bca3ca1e8053f","modified":1627743415593},{"_id":"source/_posts/mysql/分布式事务解决方案.md","hash":"825047bb76126df5159d63623fbd2f8585d919a6","modified":1627745741732},{"_id":"source/_posts/写代码避坑指南/写代码避坑指南【1】java_集合.md","hash":"02fe25acf9b8976fbfa130ba9cb455b261f715b1","modified":1628004183182},{"_id":"source/_posts/rpc框架/rpc【1】概述.md","hash":"a44af79ab90d2228a08dfe68a951e878b6b9566f","modified":1627817105831},{"_id":"source/_posts/技术规范/API设计规范.md","hash":"f67220d4097452339d36458721e38890c4b587f2","modified":1627629936495},{"_id":"source/_posts/技术规范/mysql开发规范.md","hash":"25446ccd4442d6f43831137b95b6dc07d3a069ef","modified":1627718255241},{"_id":"source/_posts/注册中心/注册中心的选型与设计.md","hash":"88ccbf60a885c12df8743c07c1bebb410117ef0b","modified":1627925093962},{"_id":"source/_posts/技术规范/分支规范.md","hash":"5ab9389385bfbf760ea4742eb10cbd8543be3836","modified":1627629966349},{"_id":"source/_posts/技术规范/生产就绪备忘清单.md","hash":"f11574043b551e4eac529fb76a244ebcafa2c615","modified":1627723857785},{"_id":"source/_posts/技术规范/监控规范.md","hash":"4ba51de3f508ab28f7fee6b274258d0022f6db7c","modified":1627876399494},{"_id":"source/_posts/消息系统/kafka【1】概述.md","hash":"e3dad861ef54b6806db8605d12546129b256439e","modified":1627892611120},{"_id":"source/_posts/消息系统/kafka【2】版本&部署规划.md","hash":"fb29a0f83c482e4d960aca3950ccb7b2905a284d","modified":1627879383938},{"_id":"source/_posts/消息系统/kafka【3】server端配置实践.md","hash":"c3267d62341801ca23180250ebcfc45d05b4aae3","modified":1627881915478},{"_id":"source/_posts/消息系统/kafka【4】client端最佳实践.md","hash":"1f7d4854b648c4cf9c1fbafdc89c4d404ca9e0e8","modified":1627892499139},{"_id":"source/_posts/消息系统/kafka【5】命令行工具.md","hash":"fb506a9ec2ef5a1e5719006a139ffd54a99973a4","modified":1627892760531},{"_id":"source/img/home_banner.png","hash":"8a9101638183360cef533ef0d0f32d65860d0293","modified":1627587234995},{"_id":"source/img/other_banner.png","hash":"ce4d76c8c04723bfe171903d3c1650513a3d8e5d","modified":1627587616837},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/LICENSE","hash":"df5b54be535593d5442cebafbea34eb9bd69b987","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/package.json","hash":"45b68110fcaf5819452f45ecd77282f97d1386f5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/README.md","hash":"523b9db3801ca892124502c17d72864457cc4b21","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/README_en.md","hash":"ca8fd19a4948de1f253616a62c0e8a7d81f692f5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/gulpfile.js","hash":"a7c87a83becf7080bddd14e81a6f09ce8c3df109","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/_config.yml","hash":"dac9d10d95b9e179e8cd7c439300b450db51f0c2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/de.yml","hash":"13a6a799415fc2f6f69ebd1a399fb44426a5d641","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/en.yml","hash":"a85dcc5cc21f9cab50df31e5001b8818ee62d1e2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/eo.yml","hash":"a0c7984495d4f2d33b64adfa33adebbf768a5ac3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/ja.yml","hash":"91020031a847c0361a6fd7ab990c7be4bf17529b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-CN.yml","hash":"21307b4137c3d9b04bb58243747e75af0abc5a71","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/languages/zh-TW.yml","hash":"1a6d415446da11dee5c5f400e7d67544fbe743ea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/404.ejs","hash":"689d9f4efd2a7f5edfd9b24561a7ade69d46617c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/archive.ejs","hash":"472d0813ca5b88000a7bc6039f33b7e27b5a3216","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/about.ejs","hash":"ad6fed7b646d3ca961db83db0fbe020e3a5d42ad","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/categories.ejs","hash":"6cbd88a2ef9dd2198d72ccc1899c4966ac5f49f9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/layout.ejs","hash":"9d6ff8772bf54d7458ae4e846e5a2d1f2921b8a7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/category.ejs","hash":"58291dfec65c36889dfce0ddc603540b67e4c598","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/index.ejs","hash":"a154785aef120988d29409847977f24069d3a3d5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/links.ejs","hash":"19c6db0ccebc8f59fa4ef9567a066b33223eccd6","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/page.ejs","hash":"1014b901d396f4fc445cb1ffc938d5380d894d71","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tag.ejs","hash":"0ad89eb7c92a822980fa9a85285e6d94ad845d1d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/post.ejs","hash":"79e3679a7069351a6172c281b9d09f59d7580484","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"16d33eb89ecf90f4046720fde5395d972c7ba1fd","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"af977ed0792508bb0766ea8afe82d34ef1e8fb3c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"ed08574b196447376dd74411cca664ac9227a5d4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"c134dd57ffd269b93402ccfffe7dbe0f0b583bec","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/beian.ejs","hash":"6ec30a9dd56341590af07f4227324f619025c109","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/archive-list.ejs","hash":"8723aa57f61134a2c1dc84cc7ea88ea366f4fda3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/.github/workflows/lint.yaml","hash":"64d521c9c5b61d3a4852c74894fb574082dc7009","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/css.ejs","hash":"cdcb607f1104543a42beda647f3c9cf0f3d11623","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/footer.ejs","hash":"39e63b3e1502803c9e8ea0c44ea662a7bbe15744","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/head.ejs","hash":"248ecd01aead6e07ac1904a7b7c45395a922bcc7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/nav.ejs","hash":"245f49aad0e4124b52aa82d981281ad9c871f1f8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/paginator.ejs","hash":"0f38a2c238169edcb63fc46c23bfc529ff3859b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/scripts.ejs","hash":"b3d93135d9ae74f006da31ec54343308bbd77cb5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/post-meta.ejs","hash":"3e0fa1731b6e54dbcf52ccf8e200e83dc4549bfa","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/index.js","hash":"44faef3e77ab08b91e4c5c6f1cd9087a9faff443","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/search.ejs","hash":"cdd7919fa01f6ef7ccc09938d662ff3d77f5d999","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"6c37e9f1ac1d6d00b3c32794e02e244dba942cd9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"606131cb807846bf43776a9073fcc1473d359ec9","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/url.js","hash":"99ab4551dc9c035abcc3bf4da5def2f63449d7ec","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/utils.js","hash":"9045f47c7a71aab39f16cffb3e3847b752c2e0f1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"e58d422eddb44c1be893f65f79f4c7feecfe6d5f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"63468f7875c09d9557fe8315afc97175745d9087","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/statistics.ejs","hash":"920bc618d357d48d2b96f8758f6ae8f9488fc4d8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/tags/note.js","hash":"f52f3a005b41f48b4da274ac64710177c8d4502f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/toc.ejs","hash":"3d2fb5552f373e5a0c56bc356702d807bcbcb411","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/join-path.js","hash":"629e7deb3955f750c1cfa6fc773f412e020fcef4","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/utils/object.js","hash":"649457796374c79e49a19bd541e4ad8e78fe8995","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/main.styl","hash":"d5a8a59c8d1fd17d699a951e59c4ce9ae44c419d","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/color-schema.js","hash":"cc712fc71bf33d561e1ba74fe1d52d2353092171","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/leancloud.js","hash":"b7985ac3cff9ee2722db43ee6b32b5484c43f5f2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/local-search.js","hash":"bf00f5786bb8de7241f635455b67243d26656222","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/utils.js","hash":"9d492fab9c26311ad0ab553c890e09b9575a76f2","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/js/plugins.js","hash":"342b1fbc30d1465687ce389a4e07f967266d5d86","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/changyan.ejs","hash":"725a1fe23c672fca87edc57739b748c3adf705da","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/cusdis.ejs","hash":"5f9dc012be27040bbe874d0c093c0d53958cc987","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/disqus.ejs","hash":"fb4502fc9204284f8b4e8dabde8477d478e826e5","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/gitalk.ejs","hash":"843bc141a4545eb20d1c92fb63c85d459b4271ec","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/livere.ejs","hash":"2264758fed57542a7389c7aa9f00f1aefa17eb87","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/remark42.ejs","hash":"d4e9532feeb02aed61bd15eda536b5b631454dac","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/twikoo.ejs","hash":"ffe08e76c9ebd4fc27715b8a60f385b3f10d0348","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/utterances.ejs","hash":"e1ed6530dfd7310f91060a75766a93ac3c39be3a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/valine.ejs","hash":"9238063c5e2928bb6fce2b99cd25ad85e78c4d1c","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/comments/waline.ejs","hash":"5b61661fbc65752f54f99402077dbb03044149a1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/math.ejs","hash":"76c4e0608ae362a265ac5e9c0fc49f75c1bc568e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/analytics.ejs","hash":"557077a8825fffc0a2c7fe2b29f319287950244f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"b5fd5a2d9c463eb59318af0f47c591c485b6ad27","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"3b2abc5f5e3b681874637e98e047dc4969eb1983","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"28e186c32576eb3d5d923273471a001c47fe8071","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"deed966f38cf0c8dee3f72e5b1f2e878510db0e1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"a2d08e3b9f98b6371b2e64d664f079c99571494b","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"c1db1a4f9eca6e36b660530641e3a4fb6a30c8d8","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/mermaid.ejs","hash":"10ed1f9a611449d37736e17c4e251127b38b3772","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/nprogress.ejs","hash":"4c2d39ce816b8a6dcd6b53113c8695f8bd650a23","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/layout/_partial/plugins/typed.ejs","hash":"ab71df2e56b60e8e193ff827e81704e5b358a977","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_variables/base.styl","hash":"26d29403d8ecb0b533e63bde3ca73b2c91f171ff","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"6e6f22b664199772370b59ce1678b0c148b5849f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"dabd87267d60240c0daea0f35a46f30ee1b2337a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"15d2786d00418e61022475194ad76445d68e27ea","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"32fb938d72b2d86159cb315a98b086bd17fa4415","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"d547ab0b91f84eb0acd0bc0c5d716ce17c30361a","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/rewrite.styl","hash":"4c6fffc6d4a3b8830931800ee7da99dccf1be36e","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_category/categories.styl","hash":"1ab7db37c2f7dc7ccdb994dcb41c16a4c8920397","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"cd4ebb1426abed9fda93b797b02c6d5dd71dc2a1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"ad7dcc8a060d94d3c44ca5e0788a24ca38be0f79","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/post.styl","hash":"3a6b4f8a29648d9d2c1e99b52a7b42df3f15cf62","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_post/tag_plugin.styl","hash":"766fcf017deb4c8b0c260ac4c8d2e3489407ad89","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"30f8fab95a5214d79df0ccc02b937df8bd885676","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"32d90bcc8bf2fd5d8d78e86a567973d4b69bcfa1","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"9f932ca3f9625c13aa5353f58319881e62c0c653","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"35539a1ce8476e75515015a06d01ec66e4af6834","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"d8011325756eb6e4ce619b3e7b4d6d80c2de8a57","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"461d609a802a4f9aa9f492411ed8074813a956b7","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"55e10a6965462f8f62f85e75fd5e143af02a4b44","modified":499162500000},{"_id":"node_modules/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":499162500000},{"_id":"public/search.xml","hash":"66ff9bcf7a64994cb94f6bdf007834df680f4613","modified":1628004242720},{"_id":"public/local-search.xml","hash":"6d4b3a07beefc2b62a5c89826a4620d5ffa8b669","modified":1628004242720},{"_id":"public/about/index.html","hash":"e95d7a8dedbb7eb8f9534c163ab9851e9fd54bb1","modified":1628004242720},{"_id":"public/2021/08/02/消息系统/kafka【3】server端配置实践/index.html","hash":"156f3fdd017933dbab14c156baefe678401ba376","modified":1628004242720},{"_id":"public/2021/08/02/消息系统/kafka【1】概述/index.html","hash":"78cc6e3d5c3a542431276d14a4fbf45f4b2db77b","modified":1628004242720},{"_id":"public/2021/08/01/rpc框架/rpc【1】概述/index.html","hash":"fc0c09d530b706fb25bf3aa649bf699c66715d05","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【1】配置文件概述/index.html","hash":"7f4b7fb644bdc401553dc8c1b8c3519013f93235","modified":1628004242720},{"_id":"public/2021/07/31/mysql/分布式事务解决方案/index.html","hash":"d174a796982351fc2a08f2543f4172eea9b6423b","modified":1628004242720},{"_id":"public/2021/07/31/mysql/分库分表策略概述/index.html","hash":"69e829bff94b3aab0660fff076ec490d2116b4b1","modified":1628004242720},{"_id":"public/2021/07/30/技术规范/监控规范/index.html","hash":"26cedcc68ffe500116138415e0a2d4a516169b58","modified":1628004242720},{"_id":"public/2021/07/30/技术规范/生产就绪备忘清单/index.html","hash":"71222af50f59c284917ce5ec6daf03510cff9724","modified":1628004242720},{"_id":"public/2021/07/30/技术规范/分支规范/index.html","hash":"adfe9c45e38368b0547a32d8c358047119a2cb6c","modified":1628004242720},{"_id":"public/archives/index.html","hash":"76f8615d7daea35e915d60a5bc45ec19eb3a1e14","modified":1628004242720},{"_id":"public/archives/2021/index.html","hash":"76f8615d7daea35e915d60a5bc45ec19eb3a1e14","modified":1628004242720},{"_id":"public/archives/2021/07/index.html","hash":"804107169919bc7005b9bde20f2af87e84294121","modified":1628004242720},{"_id":"public/archives/2021/08/index.html","hash":"260ba3a2c2be98fc074f0784eebc3bf5a4d4abcb","modified":1628004242720},{"_id":"public/categories/数据库/index.html","hash":"5fdff95b325a23c1c35dbda1a0e056fbb121e1eb","modified":1628004242720},{"_id":"public/categories/数据库/mycat/index.html","hash":"226a3980fcdbb6071380bd77454c6ba643591044","modified":1628004242720},{"_id":"public/categories/数据库/mysql/index.html","hash":"d24cad32d83cab17afcfd8d53dbb769622e4a772","modified":1628004242720},{"_id":"public/categories/后端/index.html","hash":"d83ab0547cac955cf829e7d9107abe391109995e","modified":1628004242720},{"_id":"public/categories/消息系统/index.html","hash":"0f3c577ca570db7bd28ac07c8cc7e2fea367ddd9","modified":1628004242720},{"_id":"public/categories/消息系统/kafka/index.html","hash":"98178c33c05e077905f236f20aec9617c760580e","modified":1628004242720},{"_id":"public/tags/中间件/index.html","hash":"fc83c20eba4befe27733a4b00935ee357bbcdead","modified":1628004242720},{"_id":"public/tags/分库分表/index.html","hash":"5f69ad30ca05a00544e1c60b697f717390ab18fd","modified":1628004242720},{"_id":"public/tags/mycat/index.html","hash":"ae203b1ec21a63ac5105af430c72216ec8a6938f","modified":1628004242720},{"_id":"public/tags/dockerfile/index.html","hash":"8a8602d6efa3b60a5d19194e7f18bf0f293614a0","modified":1628004242720},{"_id":"public/tags/innodb/index.html","hash":"00a0f075a7eeece79e97fb0236a03ede0a5433e6","modified":1628004242720},{"_id":"public/tags/分布式事务/index.html","hash":"3f885587088294896424570f55dcbb15a61b78aa","modified":1628004242720},{"_id":"public/tags/mysql/index.html","hash":"e9aaf5bce179a273b9910bd6bf234ed4d3ae94bc","modified":1628004242720},{"_id":"public/tags/技术规范/index.html","hash":"8238f75c7db8b7bdfbec32fd4dfa858983e92cfa","modified":1628004242720},{"_id":"public/tags/设计/index.html","hash":"c5893d67e23244115471d91817ca369774667dc9","modified":1628004242720},{"_id":"public/tags/devOps/index.html","hash":"e57f5f8294c40709cf5343e059e7b05ff9295769","modified":1628004242720},{"_id":"public/tags/kafka/index.html","hash":"c754d373026341205a902714fe726ceab883add2","modified":1628004242720},{"_id":"public/404.html","hash":"b1b8b50403d62b55255a3d9661f679d433f804c7","modified":1628004242720},{"_id":"public/tags/index.html","hash":"ee23415b8620a3bd40a34a40679ac4540ed1fd98","modified":1628004242720},{"_id":"public/links/index.html","hash":"4059a08ec27b886d1732535283cb7024d18ecf3d","modified":1628004242720},{"_id":"public/2021/08/03/写代码避坑指南/写代码避坑指南【1】java_集合/index.html","hash":"c64518250cc6ac43f09d0468db86434383a0c0b7","modified":1628004242720},{"_id":"public/2021/08/02/消息系统/kafka【5】命令行工具/index.html","hash":"d2eec5ab3d1098cf6fc76a5ed1dacb45394b5cf3","modified":1628004242720},{"_id":"public/2021/08/02/消息系统/kafka【4】client端最佳实践/index.html","hash":"23bcaa3bcaebac40ad7ae79c02655253b523d920","modified":1628004242720},{"_id":"public/2021/08/02/消息系统/kafka【2】版本&部署规划/index.html","hash":"8c9231a87c69d2b7ba3e090c00e45e9dce425c76","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【6】一次mycat在线分库记录/index.html","hash":"7da281b10b00347af7c2cd6c97896cbeb825d57b","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【5】使用技巧/index.html","hash":"822efa842d4746281216dc3855f72b4afc314b85","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【3】高可用方案/index.html","hash":"63b0a85e8da36080bd10b873d9638739003aec14","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【2】分库配置实践/index.html","hash":"357de9a7e0280a23a53c9bf34df8f2e7242ab313","modified":1628004242720},{"_id":"public/2021/08/01/mycat/mycat【4】容器化/index.html","hash":"747c14de1c8367c054f44164f292f54fd5d72ace","modified":1628004242720},{"_id":"public/2021/07/31/注册中心/注册中心的选型与设计/index.html","hash":"d603d62fdb22b58ac54402c698eb7c2c1613b8ac","modified":1628004242720},{"_id":"public/2021/07/31/mysql/innodb索引优化/index.html","hash":"99d6f2e6221bc44fb44c0028e6c3dbe7603d252b","modified":1628004242720},{"_id":"public/2021/07/30/mysql/innodb存储实现/index.html","hash":"89bb649eede7b3d0176bff650f66766ffcfbe0e9","modified":1628004242720},{"_id":"public/2021/07/30/技术规范/API设计规范/index.html","hash":"14114194f4333e4e92aa5815cc1c2ce8934478d4","modified":1628004242720},{"_id":"public/2021/07/27/技术规范/mysql开发规范/index.html","hash":"75ba5d53be1a7bf2c3b48967caa14397ea1bf321","modified":1628004242720},{"_id":"public/index.html","hash":"f796afb0ff61218f00c9e00b7ea2a68326fa0f43","modified":1628004242720},{"_id":"public/categories/index.html","hash":"8b34108c62bdb80f30a86438e774ddcf8807a6e8","modified":1628004242720},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1628004242720},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1628004242720},{"_id":"public/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1628004242720},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1628004242720},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1628004242720},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1628004242720},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1628004242720},{"_id":"public/js/color-schema.js","hash":"cc712fc71bf33d561e1ba74fe1d52d2353092171","modified":1628004242720},{"_id":"public/js/boot.js","hash":"3de344ee619da989f6dccf7c2ae459fe91075983","modified":1628004242720},{"_id":"public/js/events.js","hash":"4b9d2676c9544db9cc40a8c7d18456792299ba86","modified":1628004242720},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1628004242720},{"_id":"public/js/leancloud.js","hash":"b7985ac3cff9ee2722db43ee6b32b5484c43f5f2","modified":1628004242720},{"_id":"public/js/local-search.js","hash":"bf00f5786bb8de7241f635455b67243d26656222","modified":1628004242720},{"_id":"public/js/plugins.js","hash":"342b1fbc30d1465687ce389a4e07f967266d5d86","modified":1628004242720},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1628004242720},{"_id":"public/js/utils.js","hash":"9d492fab9c26311ad0ab553c890e09b9575a76f2","modified":1628004242720},{"_id":"public/css/main.css","hash":"58284db98a06a580c30292ce645cc6b57a6a7c08","modified":1628004242720},{"_id":"public/img/home_banner.png","hash":"8a9101638183360cef533ef0d0f32d65860d0293","modified":1628004242720},{"_id":"public/img/other_banner.png","hash":"ce4d76c8c04723bfe171903d3c1650513a3d8e5d","modified":1628004242720}],"Category":[{"name":"数据库","_id":"ckrw7oxmh0003cpfyh409gmwa"},{"name":"mycat","parent":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxmr000gcpfy2med1uq7"},{"name":"mysql","parent":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxmy000ycpfy8zad24u2"},{"name":"rpc框架","_id":"ckrw7oxn90025cpfyhh240stb"},{"name":"写代码避坑指南","_id":"ckrw7oxna002dcpfy7turblvd"},{"name":"后端","_id":"ckrw7oxnd002jcpfycig7frzb"},{"name":"消息系统","_id":"ckrw7oxnh0038cpfy7sr913ug"},{"name":"java","parent":"ckrw7oxna002dcpfy7turblvd","_id":"ckrw7oxnm003ocpfy8haebs3p"},{"name":"kafka","parent":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxnm003scpfy7ug16iys"}],"Data":[],"Page":[{"title":"about","date":"2021-07-29T05:45:33.000Z","_content":"\nheihei\n\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2021-07-29 13:45:33\n---\n\nheihei\n\n","updated":"2021-07-29T05:45:33.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckrw7oxma0000cpfyeuga70a1","content":"<p>heihei</p>\n","site":{"data":{}},"excerpt":"","more":"<p>heihei</p>\n"}],"Post":[{"title":"mycat【1】配置文件概述","toc":true,"hide":false,"date":"2021-08-01T05:53:05.000Z","sortn":10,"_content":"\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# mycat配置文件概述\n\n\n\n## 配置文件依赖关系\n\n```mermaid\ngraph LR\n\tAPP --> mycat-server\n\tmycat-server --> server.xml \n\tmycat-server --> schema.xml --> rule.xml\n\tmycat-server --> log4j2.xml --> 日志文件\n\tmycat-server --> DBserver\n```\n\n### server.xml\n\n1. 系统相关参数\n2. 用户访问权限\n3. sql防火墙，屏蔽一些特殊的sql语句，控制访问者主机ip。\n4. sql拦截器功能，记录特定 sql 的日志。\n\n\n\n### rule.xml\n\n常用分片算法\n\n- 简单取模 - partitionByMod，对column直接取模\n\n  只能用在整数类型的表\n\n- 哈希取模 - partitionByHashMod，对 column 先进行hashcode计算后再取模\n\n  可以用在字符串类型的表\n\n- 字符串范围取模 - partitionByPrefixPattern，字符串转ASCII码后，进行累加后再对取模基数进行取模。\n\n  根据字符串的范围进行分片，比如订单号的后五位，日期的前3位，等。\n\n- 分片枚举 - PartitionByFileMap， 根据列的值进行映射分表，\n\n  列的值需要有限，枚举值与数据库映射关系配置在 mapFile 中。\n\n\n\n### schema.xml\n\n- 配置 逻辑库与物理库直接的关系\n- 配置 逻辑库的具体分片rule\n- 配置 物理库的连接信息\n\n\n\n## mycat命令行操作\n\nshow @@help ，查看所有命令\n\nreload @@config，重新加载配置文件。（重新加载的时候，系统是不可用的，高峰期的时候还是需要使用滚动重启的方式）\n\nshow @@databases，显示所有物理数据库\n\nshow @@datanodes，显示所有数据节点\n\n","source":"_posts/mycat/mycat【1】配置文件概述.md","raw":"---\ntitle: mycat【1】配置文件概述\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\n\nhide: false\ndate: 2021-08-01 13:53:05\nsortn: 10\n---\n\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# mycat配置文件概述\n\n\n\n## 配置文件依赖关系\n\n```mermaid\ngraph LR\n\tAPP --> mycat-server\n\tmycat-server --> server.xml \n\tmycat-server --> schema.xml --> rule.xml\n\tmycat-server --> log4j2.xml --> 日志文件\n\tmycat-server --> DBserver\n```\n\n### server.xml\n\n1. 系统相关参数\n2. 用户访问权限\n3. sql防火墙，屏蔽一些特殊的sql语句，控制访问者主机ip。\n4. sql拦截器功能，记录特定 sql 的日志。\n\n\n\n### rule.xml\n\n常用分片算法\n\n- 简单取模 - partitionByMod，对column直接取模\n\n  只能用在整数类型的表\n\n- 哈希取模 - partitionByHashMod，对 column 先进行hashcode计算后再取模\n\n  可以用在字符串类型的表\n\n- 字符串范围取模 - partitionByPrefixPattern，字符串转ASCII码后，进行累加后再对取模基数进行取模。\n\n  根据字符串的范围进行分片，比如订单号的后五位，日期的前3位，等。\n\n- 分片枚举 - PartitionByFileMap， 根据列的值进行映射分表，\n\n  列的值需要有限，枚举值与数据库映射关系配置在 mapFile 中。\n\n\n\n### schema.xml\n\n- 配置 逻辑库与物理库直接的关系\n- 配置 逻辑库的具体分片rule\n- 配置 物理库的连接信息\n\n\n\n## mycat命令行操作\n\nshow @@help ，查看所有命令\n\nreload @@config，重新加载配置文件。（重新加载的时候，系统是不可用的，高峰期的时候还是需要使用滚动重启的方式）\n\nshow @@databases，显示所有物理数据库\n\nshow @@datanodes，显示所有数据节点\n\n","slug":"mycat/mycat【1】配置文件概述","published":1,"updated":"2021-08-01T05:53:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmd0001cpfydflo258b","content":"<p>这是摘要</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"mycat配置文件概述\"> mycat配置文件概述</span></h1>\n<h2><span id=\"配置文件依赖关系\"> 配置文件依赖关系</span></h2>\n<pre><code class=\" mermaid\">graph LR\n\tAPP --&gt; mycat-server\n\tmycat-server --&gt; server.xml \n\tmycat-server --&gt; schema.xml --&gt; rule.xml\n\tmycat-server --&gt; log4j2.xml --&gt; 日志文件\n\tmycat-server --&gt; DBserver\n</code></pre>\n<h3><span id=\"serverxml\"> server.xml</span></h3>\n<ol>\n<li>系统相关参数</li>\n<li>用户访问权限</li>\n<li>sql防火墙，屏蔽一些特殊的sql语句，控制访问者主机ip。</li>\n<li>sql拦截器功能，记录特定 sql 的日志。</li>\n</ol>\n<h3><span id=\"rulexml\"> rule.xml</span></h3>\n<p>常用分片算法</p>\n<ul>\n<li>\n<p>简单取模 - partitionByMod，对column直接取模</p>\n<p>只能用在整数类型的表</p>\n</li>\n<li>\n<p>哈希取模 - partitionByHashMod，对 column 先进行hashcode计算后再取模</p>\n<p>可以用在字符串类型的表</p>\n</li>\n<li>\n<p>字符串范围取模 - partitionByPrefixPattern，字符串转ASCII码后，进行累加后再对取模基数进行取模。</p>\n<p>根据字符串的范围进行分片，比如订单号的后五位，日期的前3位，等。</p>\n</li>\n<li>\n<p>分片枚举 - PartitionByFileMap， 根据列的值进行映射分表，</p>\n<p>列的值需要有限，枚举值与数据库映射关系配置在 mapFile 中。</p>\n</li>\n</ul>\n<h3><span id=\"schemaxml\"> schema.xml</span></h3>\n<ul>\n<li>配置 逻辑库与物理库直接的关系</li>\n<li>配置 逻辑库的具体分片rule</li>\n<li>配置 物理库的连接信息</li>\n</ul>\n<h2><span id=\"mycat命令行操作\"> mycat命令行操作</span></h2>\n<p>show @@help ，查看所有命令</p>\n<p>reload @@config，重新加载配置文件。（重新加载的时候，系统是不可用的，高峰期的时候还是需要使用滚动重启的方式）</p>\n<p>show @@databases，显示所有物理数据库</p>\n<p>show @@datanodes，显示所有数据节点</p>\n","site":{"data":{}},"excerpt":"<p>这是摘要</p>","more":"<hr />\n<h1 id=\"mycat配置文件概述\"><a class=\"markdownIt-Anchor\" href=\"#mycat配置文件概述\"></a> mycat配置文件概述</h1>\n<h2 id=\"配置文件依赖关系\"><a class=\"markdownIt-Anchor\" href=\"#配置文件依赖关系\"></a> 配置文件依赖关系</h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph LR<br>\tAPP --&gt; mycat-server<br>\tmycat-server --&gt; server.xml <br>\tmycat-server --&gt; schema.xml --&gt; rule.xml<br>\tmycat-server --&gt; log4j2.xml --&gt; 日志文件<br>\tmycat-server --&gt; DBserver<br></code></pre></td></tr></table></figure>\n<h3 id=\"serverxml\"><a class=\"markdownIt-Anchor\" href=\"#serverxml\"></a> server.xml</h3>\n<ol>\n<li>系统相关参数</li>\n<li>用户访问权限</li>\n<li>sql防火墙，屏蔽一些特殊的sql语句，控制访问者主机ip。</li>\n<li>sql拦截器功能，记录特定 sql 的日志。</li>\n</ol>\n<h3 id=\"rulexml\"><a class=\"markdownIt-Anchor\" href=\"#rulexml\"></a> rule.xml</h3>\n<p>常用分片算法</p>\n<ul>\n<li>\n<p>简单取模 - partitionByMod，对column直接取模</p>\n<p>只能用在整数类型的表</p>\n</li>\n<li>\n<p>哈希取模 - partitionByHashMod，对 column 先进行hashcode计算后再取模</p>\n<p>可以用在字符串类型的表</p>\n</li>\n<li>\n<p>字符串范围取模 - partitionByPrefixPattern，字符串转ASCII码后，进行累加后再对取模基数进行取模。</p>\n<p>根据字符串的范围进行分片，比如订单号的后五位，日期的前3位，等。</p>\n</li>\n<li>\n<p>分片枚举 - PartitionByFileMap， 根据列的值进行映射分表，</p>\n<p>列的值需要有限，枚举值与数据库映射关系配置在 mapFile 中。</p>\n</li>\n</ul>\n<h3 id=\"schemaxml\"><a class=\"markdownIt-Anchor\" href=\"#schemaxml\"></a> schema.xml</h3>\n<ul>\n<li>配置 逻辑库与物理库直接的关系</li>\n<li>配置 逻辑库的具体分片rule</li>\n<li>配置 物理库的连接信息</li>\n</ul>\n<h2 id=\"mycat命令行操作\"><a class=\"markdownIt-Anchor\" href=\"#mycat命令行操作\"></a> mycat命令行操作</h2>\n<p>show @@help ，查看所有命令</p>\n<p>reload @@config，重新加载配置文件。（重新加载的时候，系统是不可用的，高峰期的时候还是需要使用滚动重启的方式）</p>\n<p>show @@databases，显示所有物理数据库</p>\n<p>show @@datanodes，显示所有数据节点</p>"},{"title":"mycat【3】高可用方案","toc":true,"hide":false,"sortn":30,"date":"2021-08-01T06:39:58.000Z","mermaid":true,"_content":"\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# mycat高可用方案\n\n\n\n## Haproxy + Mycat + zookeeper + Mysql主从\n\n\n\n### 架构图\n\n```mermaid\ngraph TD\n\tAPP1[APP] --> Haproxy1[Haproxy] \n\tHaproxy1[Haproxy] --> mycat1[Mycat] \n\tmycat1[Mycat] --> 订单库01\n\tmycat1[Mycat] --> 订单库02\n\tmycat1[Mycat] --> 用户库\n\tmycat1[Mycat] --> 商品库\n\t\n\tZK[ZK] --> mycat2\n\tZK[ZK] --> mycat1\n\t\n\tAPP2[APP] --> Haproxy2[Haproxy] \n\tHaproxy2[Haproxy] --> mycat2[Mycat] \n\tmycat2[Mycat] --> 订单库01\n\tmycat2[Mycat] --> 订单库02\n\tmycat2[Mycat] --> 用户库\n\tmycat2[Mycat] --> 商品库\n\t\n\t订单库01 --> 订单库01_slave\n\t订单库02 --> 订单库02_slave\n\t用户库 --> 用户库_slave\n\t商品库 --> 商品库_slave\n```\n\n\n\n### 实现步骤\n\n\n\n#### 使用 zookeeper 管理 mycat 的配置文件\n\n（schema.xml、server.xml、rule.xml、sequence_db_conf.properties）\n\n1. 将 mycat/conf 下的配置文件 ，schema.xml server.xml rule.xml sequence_db_conf.properties 复制到 mycat/conf/zkconf下\n\n2. 使用 bin/init_zk_data.sh 脚本 将mycat配置信息初始化到zk中。\n\n   配置信息存在于 zk 中的/mycat/mycat-cluster-1下面\n\n3. 配置mycat，使用zk模式启动，配置 myid.properties 中的内容\n\n   ```properties\n   loadZK=true\n   zkURL=192.168.x.x，192.168.x.x，192.168.x.x，\n   clusterId=mycat-cluster-1\n   myid=mycat_01 [mycat集群中，本实例的id，该值不能重复]\n   clusterSize=2 [有多少个mycat实例]\n   clusterNodes=mycat_01,mycat_02 [全部的mycat实例id]\n   ```\n\n4. 使用 mycat start 重启mycat\n\n5.  后续维护配置信息，只要修改zk中的配置即可。可以使用 1，2步骤对zk中的配置进行修改\n\n\n\n#### **使用 HAProxy 实现 mycat的 LB & HA**\n\n1. 安装HAProxy，并使用 Keepalived 监控 HAProxy。\n2. 配置 HAProxy 监控 Mycat\n3. 配置应用通过 VIP 访问 HAProxy\n\n\n\n#### **mycat 配置 mysql 主从读写分离**\n\n1. 配置 mysql ，直线主从复制\n\n2. 配置 mycat 对后端db 进行读写分离，修改schema.xml 中的dataHost标签，新增一个readHost\n\n   ```xml\n   <dataHost name=\"userHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n     <heartbeat>select user()</heartbeat>\n     <!-- 主写，从读 -->\n     <writeHost host=\"localhost\" url=\"localhost:3306\" user=\"user_db_user\" password=\"123456\" >\n       <readHost host=\"192.168.1.6\" url=\"192.168.1.6:3306\" user=\"user_db_user\" password=\"123456\"/>\n     </writeHost>\n     <!-- 配置从库，读写。他可以保证主库挂掉的时候，读写操作都进入从库 -->\n     <writeHost host=\"192.168.1.6\" url=\"192.168.1.6:3306\" user=\"user_db_user\" password=\"123456\" />\n   </dataHost>\n   ```\n\n3. 滚动重启mycat\n","source":"_posts/mycat/mycat【3】高可用方案.md","raw":"---\ntitle: mycat【3】高可用方案\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\nhide: false\nsortn: 30\ndate: 2021-08-01 14:39:58\nmermaid: true\n---\n\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# mycat高可用方案\n\n\n\n## Haproxy + Mycat + zookeeper + Mysql主从\n\n\n\n### 架构图\n\n```mermaid\ngraph TD\n\tAPP1[APP] --> Haproxy1[Haproxy] \n\tHaproxy1[Haproxy] --> mycat1[Mycat] \n\tmycat1[Mycat] --> 订单库01\n\tmycat1[Mycat] --> 订单库02\n\tmycat1[Mycat] --> 用户库\n\tmycat1[Mycat] --> 商品库\n\t\n\tZK[ZK] --> mycat2\n\tZK[ZK] --> mycat1\n\t\n\tAPP2[APP] --> Haproxy2[Haproxy] \n\tHaproxy2[Haproxy] --> mycat2[Mycat] \n\tmycat2[Mycat] --> 订单库01\n\tmycat2[Mycat] --> 订单库02\n\tmycat2[Mycat] --> 用户库\n\tmycat2[Mycat] --> 商品库\n\t\n\t订单库01 --> 订单库01_slave\n\t订单库02 --> 订单库02_slave\n\t用户库 --> 用户库_slave\n\t商品库 --> 商品库_slave\n```\n\n\n\n### 实现步骤\n\n\n\n#### 使用 zookeeper 管理 mycat 的配置文件\n\n（schema.xml、server.xml、rule.xml、sequence_db_conf.properties）\n\n1. 将 mycat/conf 下的配置文件 ，schema.xml server.xml rule.xml sequence_db_conf.properties 复制到 mycat/conf/zkconf下\n\n2. 使用 bin/init_zk_data.sh 脚本 将mycat配置信息初始化到zk中。\n\n   配置信息存在于 zk 中的/mycat/mycat-cluster-1下面\n\n3. 配置mycat，使用zk模式启动，配置 myid.properties 中的内容\n\n   ```properties\n   loadZK=true\n   zkURL=192.168.x.x，192.168.x.x，192.168.x.x，\n   clusterId=mycat-cluster-1\n   myid=mycat_01 [mycat集群中，本实例的id，该值不能重复]\n   clusterSize=2 [有多少个mycat实例]\n   clusterNodes=mycat_01,mycat_02 [全部的mycat实例id]\n   ```\n\n4. 使用 mycat start 重启mycat\n\n5.  后续维护配置信息，只要修改zk中的配置即可。可以使用 1，2步骤对zk中的配置进行修改\n\n\n\n#### **使用 HAProxy 实现 mycat的 LB & HA**\n\n1. 安装HAProxy，并使用 Keepalived 监控 HAProxy。\n2. 配置 HAProxy 监控 Mycat\n3. 配置应用通过 VIP 访问 HAProxy\n\n\n\n#### **mycat 配置 mysql 主从读写分离**\n\n1. 配置 mysql ，直线主从复制\n\n2. 配置 mycat 对后端db 进行读写分离，修改schema.xml 中的dataHost标签，新增一个readHost\n\n   ```xml\n   <dataHost name=\"userHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n     <heartbeat>select user()</heartbeat>\n     <!-- 主写，从读 -->\n     <writeHost host=\"localhost\" url=\"localhost:3306\" user=\"user_db_user\" password=\"123456\" >\n       <readHost host=\"192.168.1.6\" url=\"192.168.1.6:3306\" user=\"user_db_user\" password=\"123456\"/>\n     </writeHost>\n     <!-- 配置从库，读写。他可以保证主库挂掉的时候，读写操作都进入从库 -->\n     <writeHost host=\"192.168.1.6\" url=\"192.168.1.6:3306\" user=\"user_db_user\" password=\"123456\" />\n   </dataHost>\n   ```\n\n3. 滚动重启mycat\n","slug":"mycat/mycat【3】高可用方案","published":1,"updated":"2021-08-01T06:39:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmg0002cpfyar9gcl2u","content":"<p>这是摘要</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"mycat高可用方案\"> mycat高可用方案</span></h1>\n<h2><span id=\"haproxy-mycat-zookeeper-mysql主从\"> Haproxy + Mycat + zookeeper + Mysql主从</span></h2>\n<h3><span id=\"架构图\"> 架构图</span></h3>\n<pre><code class=\" mermaid\">graph TD\n\tAPP1[APP] --&gt; Haproxy1[Haproxy] \n\tHaproxy1[Haproxy] --&gt; mycat1[Mycat] \n\tmycat1[Mycat] --&gt; 订单库01\n\tmycat1[Mycat] --&gt; 订单库02\n\tmycat1[Mycat] --&gt; 用户库\n\tmycat1[Mycat] --&gt; 商品库\n\t\n\tZK[ZK] --&gt; mycat2\n\tZK[ZK] --&gt; mycat1\n\t\n\tAPP2[APP] --&gt; Haproxy2[Haproxy] \n\tHaproxy2[Haproxy] --&gt; mycat2[Mycat] \n\tmycat2[Mycat] --&gt; 订单库01\n\tmycat2[Mycat] --&gt; 订单库02\n\tmycat2[Mycat] --&gt; 用户库\n\tmycat2[Mycat] --&gt; 商品库\n\t\n\t订单库01 --&gt; 订单库01_slave\n\t订单库02 --&gt; 订单库02_slave\n\t用户库 --&gt; 用户库_slave\n\t商品库 --&gt; 商品库_slave\n</code></pre>\n<h3><span id=\"实现步骤\"> 实现步骤</span></h3>\n<h4><span id=\"使用-zookeeper-管理-mycat-的配置文件\"> 使用 zookeeper 管理 mycat 的配置文件</span></h4>\n<p>（schema.xml、server.xml、rule.xml、sequence_db_conf.properties）</p>\n<ol>\n<li>\n<p>将 mycat/conf 下的配置文件 ，schema.xml server.xml rule.xml sequence_db_conf.properties 复制到 mycat/conf/zkconf下</p>\n</li>\n<li>\n<p>使用 bin/init_zk_data.sh 脚本 将mycat配置信息初始化到zk中。</p>\n<p>配置信息存在于 zk 中的/mycat/mycat-cluster-1下面</p>\n</li>\n<li>\n<p>配置mycat，使用zk模式启动，配置 myid.properties 中的内容</p>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs properties\"><span class=\"hljs-attr\">loadZK</span>=<span class=\"hljs-string\">true</span><br><span class=\"hljs-attr\">zkURL</span>=<span class=\"hljs-string\">192.168.x.x，192.168.x.x，192.168.x.x，</span><br><span class=\"hljs-attr\">clusterId</span>=<span class=\"hljs-string\">mycat-cluster-1</span><br><span class=\"hljs-attr\">myid</span>=<span class=\"hljs-string\">mycat_01 [mycat集群中，本实例的id，该值不能重复]</span><br><span class=\"hljs-attr\">clusterSize</span>=<span class=\"hljs-string\">2 [有多少个mycat实例]</span><br><span class=\"hljs-attr\">clusterNodes</span>=<span class=\"hljs-string\">mycat_01,mycat_02 [全部的mycat实例id]</span><br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<p>使用 mycat start 重启mycat</p>\n</li>\n<li>\n<p>后续维护配置信息，只要修改zk中的配置即可。可以使用 1，2步骤对zk中的配置进行修改</p>\n</li>\n</ol>\n<h4><span id=\"使用-haproxy-实现-mycat的-lb-amp-ha\"> <strong>使用 HAProxy 实现 mycat的 LB &amp; HA</strong></span></h4>\n<ol>\n<li>安装HAProxy，并使用 Keepalived 监控 HAProxy。</li>\n<li>配置 HAProxy 监控 Mycat</li>\n<li>配置应用通过 VIP 访问 HAProxy</li>\n</ol>\n<h4><span id=\"mycat-配置-mysql-主从读写分离\"> <strong>mycat 配置 mysql 主从读写分离</strong></span></h4>\n<ol>\n<li>\n<p>配置 mysql ，直线主从复制</p>\n</li>\n<li>\n<p>配置 mycat 对后端db 进行读写分离，修改schema.xml 中的dataHost标签，新增一个readHost</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 主写，从读 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> &gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">readHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;192.168.1.6&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;192.168.1.6:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span>/&gt;</span><br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">writeHost</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置从库，读写。他可以保证主库挂掉的时候，读写操作都进入从库 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;192.168.1.6&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;192.168.1.6:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<p>滚动重启mycat</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>这是摘要</p>","more":"<hr />\n<h1 id=\"mycat高可用方案\"><a class=\"markdownIt-Anchor\" href=\"#mycat高可用方案\"></a> mycat高可用方案</h1>\n<h2 id=\"haproxy-mycat-zookeeper-mysql主从\"><a class=\"markdownIt-Anchor\" href=\"#haproxy-mycat-zookeeper-mysql主从\"></a> Haproxy + Mycat + zookeeper + Mysql主从</h2>\n<h3 id=\"架构图\"><a class=\"markdownIt-Anchor\" href=\"#架构图\"></a> 架构图</h3>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>\tAPP1[APP] --&gt; Haproxy1[Haproxy] <br>\tHaproxy1[Haproxy] --&gt; mycat1[Mycat] <br>\tmycat1[Mycat] --&gt; 订单库01<br>\tmycat1[Mycat] --&gt; 订单库02<br>\tmycat1[Mycat] --&gt; 用户库<br>\tmycat1[Mycat] --&gt; 商品库<br>\t<br>\tZK[ZK] --&gt; mycat2<br>\tZK[ZK] --&gt; mycat1<br>\t<br>\tAPP2[APP] --&gt; Haproxy2[Haproxy] <br>\tHaproxy2[Haproxy] --&gt; mycat2[Mycat] <br>\tmycat2[Mycat] --&gt; 订单库01<br>\tmycat2[Mycat] --&gt; 订单库02<br>\tmycat2[Mycat] --&gt; 用户库<br>\tmycat2[Mycat] --&gt; 商品库<br>\t<br>\t订单库01 --&gt; 订单库01_slave<br>\t订单库02 --&gt; 订单库02_slave<br>\t用户库 --&gt; 用户库_slave<br>\t商品库 --&gt; 商品库_slave<br></code></pre></td></tr></table></figure>\n<h3 id=\"实现步骤\"><a class=\"markdownIt-Anchor\" href=\"#实现步骤\"></a> 实现步骤</h3>\n<h4 id=\"使用-zookeeper-管理-mycat-的配置文件\"><a class=\"markdownIt-Anchor\" href=\"#使用-zookeeper-管理-mycat-的配置文件\"></a> 使用 zookeeper 管理 mycat 的配置文件</h4>\n<p>（schema.xml、server.xml、rule.xml、sequence_db_conf.properties）</p>\n<ol>\n<li>\n<p>将 mycat/conf 下的配置文件 ，schema.xml server.xml rule.xml sequence_db_conf.properties 复制到 mycat/conf/zkconf下</p>\n</li>\n<li>\n<p>使用 bin/init_zk_data.sh 脚本 将mycat配置信息初始化到zk中。</p>\n<p>配置信息存在于 zk 中的/mycat/mycat-cluster-1下面</p>\n</li>\n<li>\n<p>配置mycat，使用zk模式启动，配置 myid.properties 中的内容</p>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs properties\"><span class=\"hljs-attr\">loadZK</span>=<span class=\"hljs-string\">true</span><br><span class=\"hljs-attr\">zkURL</span>=<span class=\"hljs-string\">192.168.x.x，192.168.x.x，192.168.x.x，</span><br><span class=\"hljs-attr\">clusterId</span>=<span class=\"hljs-string\">mycat-cluster-1</span><br><span class=\"hljs-attr\">myid</span>=<span class=\"hljs-string\">mycat_01 [mycat集群中，本实例的id，该值不能重复]</span><br><span class=\"hljs-attr\">clusterSize</span>=<span class=\"hljs-string\">2 [有多少个mycat实例]</span><br><span class=\"hljs-attr\">clusterNodes</span>=<span class=\"hljs-string\">mycat_01,mycat_02 [全部的mycat实例id]</span><br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<p>使用 mycat start 重启mycat</p>\n</li>\n<li>\n<p>后续维护配置信息，只要修改zk中的配置即可。可以使用 1，2步骤对zk中的配置进行修改</p>\n</li>\n</ol>\n<h4 id=\"使用-haproxy-实现-mycat的-lb-ha\"><a class=\"markdownIt-Anchor\" href=\"#使用-haproxy-实现-mycat的-lb-ha\"></a> <strong>使用 HAProxy 实现 mycat的 LB &amp; HA</strong></h4>\n<ol>\n<li>安装HAProxy，并使用 Keepalived 监控 HAProxy。</li>\n<li>配置 HAProxy 监控 Mycat</li>\n<li>配置应用通过 VIP 访问 HAProxy</li>\n</ol>\n<h4 id=\"mycat-配置-mysql-主从读写分离\"><a class=\"markdownIt-Anchor\" href=\"#mycat-配置-mysql-主从读写分离\"></a> <strong>mycat 配置 mysql 主从读写分离</strong></h4>\n<ol>\n<li>\n<p>配置 mysql ，直线主从复制</p>\n</li>\n<li>\n<p>配置 mycat 对后端db 进行读写分离，修改schema.xml 中的dataHost标签，新增一个readHost</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 主写，从读 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> &gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">readHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;192.168.1.6&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;192.168.1.6:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span>/&gt;</span><br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">writeHost</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置从库，读写。他可以保证主库挂掉的时候，读写操作都进入从库 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;192.168.1.6&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;192.168.1.6:3306&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<p>滚动重启mycat</p>\n</li>\n</ol>"},{"title":"mycat【2】分库配置实践","toc":true,"hide":false,"sortn":20,"date":"2021-08-01T05:56:48.000Z","_content":"\n本章主要讲了mycat 分库的配置，与实践套路\n\n<!-- more -->\n\n------\n\n\n\n## mycat垂直切分\n\n\n\n### 垂直分库步骤\n\n1. #### 分析数据库依赖关系\n\n   比如我们需要将订单表，用户表进行分库操作，master_db -> order_db , master_db -> user_db\n\n   \n\n2. #### 配置主从复制\n\n   1. 备份原数据库并记录相关事务点（在主库中操作）\n\n   ```shell\n   # 数据导出，--master-data=2 --single-transaction 不能忘\n   $ mysqldump --master-data=2 --single-transaction --routines --trigger --events -uroot -pxxxx master_db.sql > sub_master_db.sql\n   \n   # 数据导入\n   $ mysql -uroot -pxxxx order_db < sub_master_db.sql\n   \n   ```\n\n   2. 新建复制用户（在主库中操作，）\n\n   ```mysql\n   create user 'trans_user'@'192.168.1.%' identified by '[passward]' ;\n   \n   grant replication slave on *.* to 'trans_user'@'192.168.1.%';\n   ```\n\n   3. 在从库实例上恢复备份数据，并配置binlog 链路。\n\n   ```mysql\n   # 在从库中的配置主库地址\n   change master to master_host ='192.168.1.x' , \n   master_user = 'trans_user' , \n   master_password = 'xxx' , \n   master_log_file = '[开始同步的日志文件名，这个值在备份文件中，MASTER_LOG_FILE = 'xxx']' ,\n   master_log_pos = '[开始同步的事务点，这个值在备份文件中，MASTER_LOG_POS = 'xxx']' ;\n   \n   # 改写从库同步数据的数据库名称，主库中 master_db 在从库中则需要改写为 order_db \n   # 使用主从复制中的过滤函数 RELICATE_REWRITE\n   filter replicate_rewrite_db = ((master_db,order_db))\n   \n   # 查询从库状态\n   show slave status\n   # 启动复制链路\n   start slave\n   \n   # Slave_IO_Running, Slave_SQL_Running 状态为YES，则代表成功\n   ```\n\n   \n\n3. #### 配置垂直分库逻辑\n\n   通过中间件访问DB（垂直切分不需要配置 rule.xml）\n\n   1. 假如主库需要分2个库，一个是order库，一个是user库。\n   2. 配置 schema.xml ，配置顺序为：dataHost(2个) -> dataNode(2个) -> schema(1个)\n\n   ```xml\n   <?xml version=\"1.0\"?>\n   <!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n   <mycat:schema xmlns:mycat=\"http://io.mycat/\">\n          \n       <!-- ③ 配置逻辑数据库中， table 与dataNode间关系-->\n       <schema name=\"mall_db\" checkSQLschema=\"true\" sqlMaxLimit=\"100\">\n         <table name=\"order_detail\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"order_account\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"order_img\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"user_address\" primarykey=\"id\" dataNode=\"userNode\" ></table>\n         <table name=\"user_info\" primarykey=\"id\" dataNode=\"userNode\" ></table>\n         <!-- 全局表，该表在所有的从库中都会有-->\n         <table name=\"address\" primarykey=\"id\" dataNode=\"userNode,orderNode\" type=\"global\" ></table>\n     \t</schema>\n      \n       <!-- ② dataNode 数据库实例，与mysql实例映射-->\n       <dataNode name=\"orderNode\" dataHost=\"orderHost\" database=\"order_db\" />\n       <dataNode name=\"userNode\" dataHost=\"userHost\" database=\"user_db\" />\n       \n       <!-- ① dataHost mysql实例-->\n   \t\t<dataHost name=\"orderHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n     \n     \t<dataHost name=\"userHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"user_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n       \n   </mycat:schema>\n   ```\n\n   2. 配置 server.xml 配置系统遍历及用户权限\n\n   ```xml\n   <user name=\"mall_user\">\n   \t\t<property name=\"password\">123456</property>\n   \t\t<property name=\"schemas\">mall_db</property>\n   </user>\n   ```\n\n\n\n4. #### 开始作案\n\n   万事俱备后，夜黑风高之夜进行切换操作，需要预留足够的作案时间，回滚时间\n\n   \n\n5. #### 收尾\n\n   删除原库中，的已迁移数据。从库中，多余的数据。\n\n   1. 停止主从同步，stop slave;  reset slave all;  show status\\g;\n   2. 备份 ，drop表\n\n\n\n\n\n## 水平切分\n\n### 原则：\n\n1. 能不切分就不切分。对于日志，历史记录这种大表，可以使用历史数据归档的方式进行数据转移，保证热点数据在数据库中即可。无法归档的数据时才考虑进行水平切分。\n2. 选择合适的分片字段及分配规则，一定要提前想好，因为查询的时候也尽量需要带上分片键，这个后期修改困难\n3. 尽量避免跨分片join\n\n\n\n### 步骤\n\n1. #### 确定分片键\n\n   确定 分片表，分片键，分片算法，全局唯一id生成算法；记住要讨论一下有没有坑。\n\n   **分片表**：将需要分片的表，以及频繁需要和分片表关联查询的表一起分片。（不经常使用join语句的话，可以忽略）\n\n   **分片键**：主键id，业务唯一id（比如订单id），**外键或namespace**（比如订单关联的user_id,或者订单的日期, 订单的查询往往是以用户为单位查询，或者以时间为单位查询的，这一点需要考虑业务上的常用查询方式）\n\n   **分片算法**：简单取模算法，哈希取模算法。\n\n   \n\n2. #### 配置 mycat \n\n   schema.xml\n\n   ```xml\n   <?xml version=\"1.0\"?>\n   <!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n   <mycat:schema xmlns:mycat=\"http://io.mycat/\">\n          \n       <!-- ③ 配置逻辑数据库中， table 与dataNode间关系-->\n       <schema name=\"order\" checkSQLschema=\"true\" sqlMaxLimit=\"100\">\n         <table name=\"order_master\" primarykey=\"id\" dataNode=\"orderNode0101,orderNode0102,orderNode0203,orderNode0204\" rule=\"order_master\" >\n           <!-- ER分片表 -->\n           <childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"id\" parentKey=\"id\" />\n           \n         </table>\n     \t</schema>\n      \n       <!-- ② dataNode 数据库实例，与mysql实例映射-->\n       <dataNode name=\"orderNode0101\" dataHost=\"orderHost01\" database=\"order_db_01\" />\n       <dataNode name=\"orderNode0102\" dataHost=\"orderHost01\" database=\"order_db_02\" />\n       <dataNode name=\"orderNode0203\" dataHost=\"orderHost02\" database=\"order_db_03\" />\n       <dataNode name=\"orderNode0204\" dataHost=\"orderHost02\" database=\"order_db_04\" />\n       \n       <!-- ① dataHost mysql实例-->\n   \t\t<dataHost name=\"orderHost01\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n     \n     \t<dataHost name=\"orderHost02\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n       \n   </mycat:schema>\n   ```\n\n   rule.xml\n\n   ```xml\n   <mycat:rule xmlns:mycat=\"http://io.mycat/\">\n   \t<tableRule name=\"order_mater\">\n   \t\t<rule>\n   \t\t\t<columns>user_id</columns>\n   \t\t\t<algorithm>mod-long</algorithm>\n   \t\t</rule>\n   \t</tableRule>\n   \n   \t<function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\">\n   \t\t<property name=\"count\">4</property>\n   \t</function>\n     \n   </mycat:rule>\n   ```\n\n   server.xml\n\n   ```xml\n   <user name=\"mall_order\">\n   \t\t<property name=\"password\">123456</property>\n   \t\t<property name=\"schemas\">order</property>\n   </user>\n   ```\n\n   \n\n3. 数据迁移，使用脚本，按照规定的分片算法进行数据迁移即可。\n\n","source":"_posts/mycat/mycat【2】分库配置实践.md","raw":"---\ntitle: mycat【2】分库配置实践\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\nhide: false\nsortn: 20\ndate: 2021-08-01 13:56:48\n---\n\n本章主要讲了mycat 分库的配置，与实践套路\n\n<!-- more -->\n\n------\n\n\n\n## mycat垂直切分\n\n\n\n### 垂直分库步骤\n\n1. #### 分析数据库依赖关系\n\n   比如我们需要将订单表，用户表进行分库操作，master_db -> order_db , master_db -> user_db\n\n   \n\n2. #### 配置主从复制\n\n   1. 备份原数据库并记录相关事务点（在主库中操作）\n\n   ```shell\n   # 数据导出，--master-data=2 --single-transaction 不能忘\n   $ mysqldump --master-data=2 --single-transaction --routines --trigger --events -uroot -pxxxx master_db.sql > sub_master_db.sql\n   \n   # 数据导入\n   $ mysql -uroot -pxxxx order_db < sub_master_db.sql\n   \n   ```\n\n   2. 新建复制用户（在主库中操作，）\n\n   ```mysql\n   create user 'trans_user'@'192.168.1.%' identified by '[passward]' ;\n   \n   grant replication slave on *.* to 'trans_user'@'192.168.1.%';\n   ```\n\n   3. 在从库实例上恢复备份数据，并配置binlog 链路。\n\n   ```mysql\n   # 在从库中的配置主库地址\n   change master to master_host ='192.168.1.x' , \n   master_user = 'trans_user' , \n   master_password = 'xxx' , \n   master_log_file = '[开始同步的日志文件名，这个值在备份文件中，MASTER_LOG_FILE = 'xxx']' ,\n   master_log_pos = '[开始同步的事务点，这个值在备份文件中，MASTER_LOG_POS = 'xxx']' ;\n   \n   # 改写从库同步数据的数据库名称，主库中 master_db 在从库中则需要改写为 order_db \n   # 使用主从复制中的过滤函数 RELICATE_REWRITE\n   filter replicate_rewrite_db = ((master_db,order_db))\n   \n   # 查询从库状态\n   show slave status\n   # 启动复制链路\n   start slave\n   \n   # Slave_IO_Running, Slave_SQL_Running 状态为YES，则代表成功\n   ```\n\n   \n\n3. #### 配置垂直分库逻辑\n\n   通过中间件访问DB（垂直切分不需要配置 rule.xml）\n\n   1. 假如主库需要分2个库，一个是order库，一个是user库。\n   2. 配置 schema.xml ，配置顺序为：dataHost(2个) -> dataNode(2个) -> schema(1个)\n\n   ```xml\n   <?xml version=\"1.0\"?>\n   <!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n   <mycat:schema xmlns:mycat=\"http://io.mycat/\">\n          \n       <!-- ③ 配置逻辑数据库中， table 与dataNode间关系-->\n       <schema name=\"mall_db\" checkSQLschema=\"true\" sqlMaxLimit=\"100\">\n         <table name=\"order_detail\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"order_account\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"order_img\" primarykey=\"id\" dataNode=\"orderNode\" ></table>\n         <table name=\"user_address\" primarykey=\"id\" dataNode=\"userNode\" ></table>\n         <table name=\"user_info\" primarykey=\"id\" dataNode=\"userNode\" ></table>\n         <!-- 全局表，该表在所有的从库中都会有-->\n         <table name=\"address\" primarykey=\"id\" dataNode=\"userNode,orderNode\" type=\"global\" ></table>\n     \t</schema>\n      \n       <!-- ② dataNode 数据库实例，与mysql实例映射-->\n       <dataNode name=\"orderNode\" dataHost=\"orderHost\" database=\"order_db\" />\n       <dataNode name=\"userNode\" dataHost=\"userHost\" database=\"user_db\" />\n       \n       <!-- ① dataHost mysql实例-->\n   \t\t<dataHost name=\"orderHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n     \n     \t<dataHost name=\"userHost\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"user_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n       \n   </mycat:schema>\n   ```\n\n   2. 配置 server.xml 配置系统遍历及用户权限\n\n   ```xml\n   <user name=\"mall_user\">\n   \t\t<property name=\"password\">123456</property>\n   \t\t<property name=\"schemas\">mall_db</property>\n   </user>\n   ```\n\n\n\n4. #### 开始作案\n\n   万事俱备后，夜黑风高之夜进行切换操作，需要预留足够的作案时间，回滚时间\n\n   \n\n5. #### 收尾\n\n   删除原库中，的已迁移数据。从库中，多余的数据。\n\n   1. 停止主从同步，stop slave;  reset slave all;  show status\\g;\n   2. 备份 ，drop表\n\n\n\n\n\n## 水平切分\n\n### 原则：\n\n1. 能不切分就不切分。对于日志，历史记录这种大表，可以使用历史数据归档的方式进行数据转移，保证热点数据在数据库中即可。无法归档的数据时才考虑进行水平切分。\n2. 选择合适的分片字段及分配规则，一定要提前想好，因为查询的时候也尽量需要带上分片键，这个后期修改困难\n3. 尽量避免跨分片join\n\n\n\n### 步骤\n\n1. #### 确定分片键\n\n   确定 分片表，分片键，分片算法，全局唯一id生成算法；记住要讨论一下有没有坑。\n\n   **分片表**：将需要分片的表，以及频繁需要和分片表关联查询的表一起分片。（不经常使用join语句的话，可以忽略）\n\n   **分片键**：主键id，业务唯一id（比如订单id），**外键或namespace**（比如订单关联的user_id,或者订单的日期, 订单的查询往往是以用户为单位查询，或者以时间为单位查询的，这一点需要考虑业务上的常用查询方式）\n\n   **分片算法**：简单取模算法，哈希取模算法。\n\n   \n\n2. #### 配置 mycat \n\n   schema.xml\n\n   ```xml\n   <?xml version=\"1.0\"?>\n   <!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n   <mycat:schema xmlns:mycat=\"http://io.mycat/\">\n          \n       <!-- ③ 配置逻辑数据库中， table 与dataNode间关系-->\n       <schema name=\"order\" checkSQLschema=\"true\" sqlMaxLimit=\"100\">\n         <table name=\"order_master\" primarykey=\"id\" dataNode=\"orderNode0101,orderNode0102,orderNode0203,orderNode0204\" rule=\"order_master\" >\n           <!-- ER分片表 -->\n           <childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"id\" parentKey=\"id\" />\n           \n         </table>\n     \t</schema>\n      \n       <!-- ② dataNode 数据库实例，与mysql实例映射-->\n       <dataNode name=\"orderNode0101\" dataHost=\"orderHost01\" database=\"order_db_01\" />\n       <dataNode name=\"orderNode0102\" dataHost=\"orderHost01\" database=\"order_db_02\" />\n       <dataNode name=\"orderNode0203\" dataHost=\"orderHost02\" database=\"order_db_03\" />\n       <dataNode name=\"orderNode0204\" dataHost=\"orderHost02\" database=\"order_db_04\" />\n       \n       <!-- ① dataHost mysql实例-->\n   \t\t<dataHost name=\"orderHost01\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n     \n     \t<dataHost name=\"orderHost02\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\"> \n         <heartbeat>select user()</heartbeat>\n         <writeHost host=\"localhost\" url=\"localhost:3307\" user=\"order_db_user\" password=\"123456\" /> \n   \t\t</dataHost>\n       \n   </mycat:schema>\n   ```\n\n   rule.xml\n\n   ```xml\n   <mycat:rule xmlns:mycat=\"http://io.mycat/\">\n   \t<tableRule name=\"order_mater\">\n   \t\t<rule>\n   \t\t\t<columns>user_id</columns>\n   \t\t\t<algorithm>mod-long</algorithm>\n   \t\t</rule>\n   \t</tableRule>\n   \n   \t<function name=\"mod-long\" class=\"io.mycat.route.function.PartitionByMod\">\n   \t\t<property name=\"count\">4</property>\n   \t</function>\n     \n   </mycat:rule>\n   ```\n\n   server.xml\n\n   ```xml\n   <user name=\"mall_order\">\n   \t\t<property name=\"password\">123456</property>\n   \t\t<property name=\"schemas\">order</property>\n   </user>\n   ```\n\n   \n\n3. 数据迁移，使用脚本，按照规定的分片算法进行数据迁移即可。\n\n","slug":"mycat/mycat【2】分库配置实践","published":1,"updated":"2021-08-01T05:56:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmj0005cpfycti684r8","content":"<p>本章主要讲了mycat 分库的配置，与实践套路</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"mycat垂直切分\"> mycat垂直切分</span></h2>\n<h3><span id=\"垂直分库步骤\"> 垂直分库步骤</span></h3>\n<ol>\n<li>\n<h4><span id=\"分析数据库依赖关系\"> 分析数据库依赖关系</span></h4>\n<p>比如我们需要将订单表，用户表进行分库操作，master_db -&gt; order_db , master_db -&gt; user_db</p>\n</li>\n<li>\n<h4><span id=\"配置主从复制\"> 配置主从复制</span></h4>\n<ol>\n<li>备份原数据库并记录相关事务点（在主库中操作）</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 数据导出，--master-data=2 --single-transaction 不能忘</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> mysqldump --master-data=2 --single-transaction --routines --trigger --events -uroot -pxxxx master_db.sql &gt; sub_master_db.sql</span><br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 数据导入</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> mysql -uroot -pxxxx order_db &lt; sub_master_db.sql</span><br><br></code></pre></div></td></tr></table></figure>\n<ol start=\"2\">\n<li>新建复制用户（在主库中操作，）</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs mysql\">create user &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27; identified by &#x27;[passward]&#x27; ;<br><br>grant replication slave on *.* to &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27;;<br></code></pre></div></td></tr></table></figure>\n<ol start=\"3\">\n<li>在从库实例上恢复备份数据，并配置binlog 链路。</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs mysql\"># 在从库中的配置主库地址<br>change master to master_host =&#x27;192.168.1.x&#x27; , <br>master_user = &#x27;trans_user&#x27; , <br>master_password = &#x27;xxx&#x27; , <br>master_log_file = &#x27;[开始同步的日志文件名，这个值在备份文件中，MASTER_LOG_FILE = &#x27;xxx&#x27;]&#x27; ,<br>master_log_pos = &#x27;[开始同步的事务点，这个值在备份文件中，MASTER_LOG_POS = &#x27;xxx&#x27;]&#x27; ;<br><br># 改写从库同步数据的数据库名称，主库中 master_db 在从库中则需要改写为 order_db <br># 使用主从复制中的过滤函数 RELICATE_REWRITE<br>filter replicate_rewrite_db = ((master_db,order_db))<br><br># 查询从库状态<br>show slave status<br># 启动复制链路<br>start slave<br><br># Slave_IO_Running, Slave_SQL_Running 状态为YES，则代表成功<br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<h4><span id=\"配置垂直分库逻辑\"> 配置垂直分库逻辑</span></h4>\n<p>通过中间件访问DB（垂直切分不需要配置 rule.xml）</p>\n<ol>\n<li>假如主库需要分2个库，一个是order库，一个是user库。</li>\n<li>配置 schema.xml ，配置顺序为：dataHost(2个) -&gt; dataNode(2个) -&gt; schema(1个)</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-meta\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"hljs-meta\">&lt;!DOCTYPE <span class=\"hljs-meta-keyword\">mycat</span>:schema <span class=\"hljs-meta-keyword\">SYSTEM</span> <span class=\"hljs-meta-string\">&quot;schema.dtd&quot;</span>&gt;</span><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:schema</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class=\"hljs-comment\">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">schema</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_db&quot;</span> <span class=\"hljs-attr\">checkSQLschema</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">sqlMaxLimit</span>=<span class=\"hljs-string\">&quot;100&quot;</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_detail&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_account&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_img&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;user_address&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;user_info&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-comment\">&lt;!-- 全局表，该表在所有的从库中都会有--&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;address&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode,orderNode&quot;</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;global&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>  \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">schema</span>&gt;</span><br>   <br>    <span class=\"hljs-comment\">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;user_db&quot;</span> /&gt;</span><br>    <br>    <span class=\"hljs-comment\">&lt;!-- ① dataHost mysql实例--&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>  <br>  \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>    <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:schema</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n<ol start=\"2\">\n<li>配置 server.xml 配置系统遍历及用户权限</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">user</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_user&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;password&quot;</span>&gt;</span>123456<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;schemas&quot;</span>&gt;</span>mall_db<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">user</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<h4><span id=\"开始作案\"> 开始作案</span></h4>\n<p>万事俱备后，夜黑风高之夜进行切换操作，需要预留足够的作案时间，回滚时间</p>\n</li>\n<li>\n<h4><span id=\"收尾\"> 收尾</span></h4>\n<p>删除原库中，的已迁移数据。从库中，多余的数据。</p>\n<ol>\n<li>停止主从同步，stop slave;  reset slave all;  show status\\g;</li>\n<li>备份 ，drop表</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"水平切分\"> 水平切分</span></h2>\n<h3><span id=\"原则\"> 原则：</span></h3>\n<ol>\n<li>能不切分就不切分。对于日志，历史记录这种大表，可以使用历史数据归档的方式进行数据转移，保证热点数据在数据库中即可。无法归档的数据时才考虑进行水平切分。</li>\n<li>选择合适的分片字段及分配规则，一定要提前想好，因为查询的时候也尽量需要带上分片键，这个后期修改困难</li>\n<li>尽量避免跨分片join</li>\n</ol>\n<h3><span id=\"步骤\"> 步骤</span></h3>\n<ol>\n<li>\n<h4><span id=\"确定分片键\"> 确定分片键</span></h4>\n<p>确定 分片表，分片键，分片算法，全局唯一id生成算法；记住要讨论一下有没有坑。</p>\n<p><strong>分片表</strong>：将需要分片的表，以及频繁需要和分片表关联查询的表一起分片。（不经常使用join语句的话，可以忽略）</p>\n<p><strong>分片键</strong>：主键id，业务唯一id（比如订单id），<strong>外键或namespace</strong>（比如订单关联的user_id,或者订单的日期, 订单的查询往往是以用户为单位查询，或者以时间为单位查询的，这一点需要考虑业务上的常用查询方式）</p>\n<p><strong>分片算法</strong>：简单取模算法，哈希取模算法。</p>\n</li>\n<li>\n<h4><span id=\"配置-mycat\"> 配置 mycat</span></h4>\n<p>schema.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-meta\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"hljs-meta\">&lt;!DOCTYPE <span class=\"hljs-meta-keyword\">mycat</span>:schema <span class=\"hljs-meta-keyword\">SYSTEM</span> <span class=\"hljs-meta-string\">&quot;schema.dtd&quot;</span>&gt;</span><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:schema</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class=\"hljs-comment\">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">schema</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order&quot;</span> <span class=\"hljs-attr\">checkSQLschema</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">sqlMaxLimit</span>=<span class=\"hljs-string\">&quot;100&quot;</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_master&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode0101,orderNode0102,orderNode0203,orderNode0204&quot;</span> <span class=\"hljs-attr\">rule</span>=<span class=\"hljs-string\">&quot;order_master&quot;</span> &gt;</span><br>        <span class=\"hljs-comment\">&lt;!-- ER分片表 --&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">childTable</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_detail&quot;</span> <span class=\"hljs-attr\">primaryKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">joinKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">parentKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> /&gt;</span><br>        <br>      <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>  \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">schema</span>&gt;</span><br>   <br>    <span class=\"hljs-comment\">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0101&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_01&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0102&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_02&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0203&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_03&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0204&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_04&quot;</span> /&gt;</span><br>    <br>    <span class=\"hljs-comment\">&lt;!-- ① dataHost mysql实例--&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>  <br>  \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>    <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:schema</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n<p>rule.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:rule</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">tableRule</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_mater&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">rule</span>&gt;</span><br>\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">columns</span>&gt;</span>user_id<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">columns</span>&gt;</span><br>\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">algorithm</span>&gt;</span>mod-long<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">algorithm</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">rule</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">tableRule</span>&gt;</span><br><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">function</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mod-long&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;io.mycat.route.function.PartitionByMod&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;count&quot;</span>&gt;</span>4<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">function</span>&gt;</span><br>  <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:rule</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n<p>server.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">user</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_order&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;password&quot;</span>&gt;</span>123456<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;schemas&quot;</span>&gt;</span>order<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">user</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<p>数据迁移，使用脚本，按照规定的分片算法进行数据迁移即可。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>本章主要讲了mycat 分库的配置，与实践套路</p>","more":"<hr />\n<h2 id=\"mycat垂直切分\"><a class=\"markdownIt-Anchor\" href=\"#mycat垂直切分\"></a> mycat垂直切分</h2>\n<h3 id=\"垂直分库步骤\"><a class=\"markdownIt-Anchor\" href=\"#垂直分库步骤\"></a> 垂直分库步骤</h3>\n<ol>\n<li>\n<h4 id=\"分析数据库依赖关系\"><a class=\"markdownIt-Anchor\" href=\"#分析数据库依赖关系\"></a> 分析数据库依赖关系</h4>\n<p>比如我们需要将订单表，用户表进行分库操作，master_db -&gt; order_db , master_db -&gt; user_db</p>\n</li>\n<li>\n<h4 id=\"配置主从复制\"><a class=\"markdownIt-Anchor\" href=\"#配置主从复制\"></a> 配置主从复制</h4>\n<ol>\n<li>备份原数据库并记录相关事务点（在主库中操作）</li>\n</ol>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\"> 数据导出，--master-data=2 --single-transaction 不能忘</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> mysqldump --master-data=2 --single-transaction --routines --trigger --events -uroot -pxxxx master_db.sql &gt; sub_master_db.sql</span><br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\"> 数据导入</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> mysql -uroot -pxxxx order_db &lt; sub_master_db.sql</span><br><br></code></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>新建复制用户（在主库中操作，）</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">create user &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27; identified by &#x27;[passward]&#x27; ;<br><br>grant replication slave on *.* to &#x27;trans_user&#x27;@&#x27;192.168.1.%&#x27;;<br></code></pre></td></tr></table></figure>\n<ol start=\"3\">\n<li>在从库实例上恢复备份数据，并配置binlog 链路。</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\"># 在从库中的配置主库地址<br>change master to master_host =&#x27;192.168.1.x&#x27; , <br>master_user = &#x27;trans_user&#x27; , <br>master_password = &#x27;xxx&#x27; , <br>master_log_file = &#x27;[开始同步的日志文件名，这个值在备份文件中，MASTER_LOG_FILE = &#x27;xxx&#x27;]&#x27; ,<br>master_log_pos = &#x27;[开始同步的事务点，这个值在备份文件中，MASTER_LOG_POS = &#x27;xxx&#x27;]&#x27; ;<br><br># 改写从库同步数据的数据库名称，主库中 master_db 在从库中则需要改写为 order_db <br># 使用主从复制中的过滤函数 RELICATE_REWRITE<br>filter replicate_rewrite_db = ((master_db,order_db))<br><br># 查询从库状态<br>show slave status<br># 启动复制链路<br>start slave<br><br># Slave_IO_Running, Slave_SQL_Running 状态为YES，则代表成功<br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<h4 id=\"配置垂直分库逻辑\"><a class=\"markdownIt-Anchor\" href=\"#配置垂直分库逻辑\"></a> 配置垂直分库逻辑</h4>\n<p>通过中间件访问DB（垂直切分不需要配置 rule.xml）</p>\n<ol>\n<li>假如主库需要分2个库，一个是order库，一个是user库。</li>\n<li>配置 schema.xml ，配置顺序为：dataHost(2个) -&gt; dataNode(2个) -&gt; schema(1个)</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-meta\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"hljs-meta\">&lt;!DOCTYPE <span class=\"hljs-meta-keyword\">mycat</span>:schema <span class=\"hljs-meta-keyword\">SYSTEM</span> <span class=\"hljs-meta-string\">&quot;schema.dtd&quot;</span>&gt;</span><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:schema</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class=\"hljs-comment\">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">schema</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_db&quot;</span> <span class=\"hljs-attr\">checkSQLschema</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">sqlMaxLimit</span>=<span class=\"hljs-string\">&quot;100&quot;</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_detail&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_account&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_img&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;user_address&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;user_info&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>      <span class=\"hljs-comment\">&lt;!-- 全局表，该表在所有的从库中都会有--&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;address&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;userNode,orderNode&quot;</span> <span class=\"hljs-attr\">type</span>=<span class=\"hljs-string\">&quot;global&quot;</span> &gt;</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>  \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">schema</span>&gt;</span><br>   <br>    <span class=\"hljs-comment\">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userNode&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;user_db&quot;</span> /&gt;</span><br>    <br>    <span class=\"hljs-comment\">&lt;!-- ① dataHost mysql实例--&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>  <br>  \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;userHost&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;user_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>    <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:schema</span>&gt;</span><br></code></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>配置 server.xml 配置系统遍历及用户权限</li>\n</ol>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">user</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_user&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;password&quot;</span>&gt;</span>123456<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;schemas&quot;</span>&gt;</span>mall_db<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">user</span>&gt;</span><br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<h4 id=\"开始作案\"><a class=\"markdownIt-Anchor\" href=\"#开始作案\"></a> 开始作案</h4>\n<p>万事俱备后，夜黑风高之夜进行切换操作，需要预留足够的作案时间，回滚时间</p>\n</li>\n<li>\n<h4 id=\"收尾\"><a class=\"markdownIt-Anchor\" href=\"#收尾\"></a> 收尾</h4>\n<p>删除原库中，的已迁移数据。从库中，多余的数据。</p>\n<ol>\n<li>停止主从同步，stop slave;  reset slave all;  show status\\g;</li>\n<li>备份 ，drop表</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"水平切分\"><a class=\"markdownIt-Anchor\" href=\"#水平切分\"></a> 水平切分</h2>\n<h3 id=\"原则\"><a class=\"markdownIt-Anchor\" href=\"#原则\"></a> 原则：</h3>\n<ol>\n<li>能不切分就不切分。对于日志，历史记录这种大表，可以使用历史数据归档的方式进行数据转移，保证热点数据在数据库中即可。无法归档的数据时才考虑进行水平切分。</li>\n<li>选择合适的分片字段及分配规则，一定要提前想好，因为查询的时候也尽量需要带上分片键，这个后期修改困难</li>\n<li>尽量避免跨分片join</li>\n</ol>\n<h3 id=\"步骤\"><a class=\"markdownIt-Anchor\" href=\"#步骤\"></a> 步骤</h3>\n<ol>\n<li>\n<h4 id=\"确定分片键\"><a class=\"markdownIt-Anchor\" href=\"#确定分片键\"></a> 确定分片键</h4>\n<p>确定 分片表，分片键，分片算法，全局唯一id生成算法；记住要讨论一下有没有坑。</p>\n<p><strong>分片表</strong>：将需要分片的表，以及频繁需要和分片表关联查询的表一起分片。（不经常使用join语句的话，可以忽略）</p>\n<p><strong>分片键</strong>：主键id，业务唯一id（比如订单id），<strong>外键或namespace</strong>（比如订单关联的user_id,或者订单的日期, 订单的查询往往是以用户为单位查询，或者以时间为单位查询的，这一点需要考虑业务上的常用查询方式）</p>\n<p><strong>分片算法</strong>：简单取模算法，哈希取模算法。</p>\n</li>\n<li>\n<h4 id=\"配置-mycat\"><a class=\"markdownIt-Anchor\" href=\"#配置-mycat\"></a> 配置 mycat</h4>\n<p>schema.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-meta\">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class=\"hljs-meta\">&lt;!DOCTYPE <span class=\"hljs-meta-keyword\">mycat</span>:schema <span class=\"hljs-meta-keyword\">SYSTEM</span> <span class=\"hljs-meta-string\">&quot;schema.dtd&quot;</span>&gt;</span><br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:schema</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>       <br>    <span class=\"hljs-comment\">&lt;!-- ③ 配置逻辑数据库中， table 与dataNode间关系--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">schema</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order&quot;</span> <span class=\"hljs-attr\">checkSQLschema</span>=<span class=\"hljs-string\">&quot;true&quot;</span> <span class=\"hljs-attr\">sqlMaxLimit</span>=<span class=\"hljs-string\">&quot;100&quot;</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">table</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_master&quot;</span> <span class=\"hljs-attr\">primarykey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">dataNode</span>=<span class=\"hljs-string\">&quot;orderNode0101,orderNode0102,orderNode0203,orderNode0204&quot;</span> <span class=\"hljs-attr\">rule</span>=<span class=\"hljs-string\">&quot;order_master&quot;</span> &gt;</span><br>        <span class=\"hljs-comment\">&lt;!-- ER分片表 --&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">childTable</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_detail&quot;</span> <span class=\"hljs-attr\">primaryKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">joinKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> <span class=\"hljs-attr\">parentKey</span>=<span class=\"hljs-string\">&quot;id&quot;</span> /&gt;</span><br>        <br>      <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">table</span>&gt;</span><br>  \t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">schema</span>&gt;</span><br>   <br>    <span class=\"hljs-comment\">&lt;!-- ② dataNode 数据库实例，与mysql实例映射--&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0101&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_01&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0102&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_02&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0203&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_03&quot;</span> /&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataNode</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderNode0204&quot;</span> <span class=\"hljs-attr\">dataHost</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">database</span>=<span class=\"hljs-string\">&quot;order_db_04&quot;</span> /&gt;</span><br>    <br>    <span class=\"hljs-comment\">&lt;!-- ① dataHost mysql实例--&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost01&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>  <br>  \t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">dataHost</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;orderHost02&quot;</span> <span class=\"hljs-attr\">maxCon</span>=<span class=\"hljs-string\">&quot;1000&quot;</span> <span class=\"hljs-attr\">minCon</span>=<span class=\"hljs-string\">&quot;10&quot;</span> <span class=\"hljs-attr\">balance</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">writeType</span>=<span class=\"hljs-string\">&quot;0&quot;</span> <span class=\"hljs-attr\">dbType</span>=<span class=\"hljs-string\">&quot;mysql&quot;</span> <span class=\"hljs-attr\">dbDriver</span>=<span class=\"hljs-string\">&quot;native&quot;</span> <span class=\"hljs-attr\">switchType</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span> <br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">heartbeat</span>&gt;</span>select user()<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">heartbeat</span>&gt;</span><br>      <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">writeHost</span> <span class=\"hljs-attr\">host</span>=<span class=\"hljs-string\">&quot;localhost&quot;</span> <span class=\"hljs-attr\">url</span>=<span class=\"hljs-string\">&quot;localhost:3307&quot;</span> <span class=\"hljs-attr\">user</span>=<span class=\"hljs-string\">&quot;order_db_user&quot;</span> <span class=\"hljs-attr\">password</span>=<span class=\"hljs-string\">&quot;123456&quot;</span> /&gt;</span> <br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">dataHost</span>&gt;</span><br>    <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:schema</span>&gt;</span><br></code></pre></td></tr></table></figure>\n<p>rule.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">mycat:rule</span> <span class=\"hljs-attr\">xmlns:mycat</span>=<span class=\"hljs-string\">&quot;http://io.mycat/&quot;</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">tableRule</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;order_mater&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">rule</span>&gt;</span><br>\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">columns</span>&gt;</span>user_id<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">columns</span>&gt;</span><br>\t\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">algorithm</span>&gt;</span>mod-long<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">algorithm</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">rule</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">tableRule</span>&gt;</span><br><br>\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">function</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mod-long&quot;</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">&quot;io.mycat.route.function.PartitionByMod&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;count&quot;</span>&gt;</span>4<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">function</span>&gt;</span><br>  <br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">mycat:rule</span>&gt;</span><br></code></pre></td></tr></table></figure>\n<p>server.xml</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">user</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;mall_order&quot;</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;password&quot;</span>&gt;</span>123456<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>\t\t<span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;schemas&quot;</span>&gt;</span>order<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">user</span>&gt;</span><br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<p>数据迁移，使用脚本，按照规定的分片算法进行数据迁移即可。</p>\n</li>\n</ol>"},{"title":"mycat【4】容器化","toc":true,"hide":false,"date":"2021-08-01T04:43:59.000Z","sortn":40,"_content":"\n本章讲的是，mycat 具体实践的代码，小抄\n\n<!-- more -->\n\n------\n\n# mycat容器化\n\n\n\n## dockerfile\n\n当前目录一览\n\n```\n.\n├── Dockerfile\n├── mycat-conf\n│   ├── log4j2.xml\n│   ├── rule.xml\n│   ├── schema.xml\n│   ├── server.xml\n│   └── 此目录会覆盖 mycat/conf ，简略展示\n└── mycat-server-1.6.7.5-release\n    ├── bin\n    ├── catlet\n    ├── conf\n    ├── lib\n    ├── logs\n    └── version.txt\n\n```\n\nDockerfile\n\n```dockerfile\nFROM openjdk:8\n\n\n# 标记mycat 版本号\nENV MYCAT_HOME=/app/mycat\n\n# 添加 mycat - server\nCOPY ./mycat-server-1.6.7.5-release $MYCAT_HOME\n\n# 添加 mycat 分库分表配置\nCOPY ./mycat-conf $MYCAT_HOME/conf\n\n# 添加 mycat -class path\nENV PATH=$PATH:$MYCAT_HOME/bin\n\n# 启动\n# mycat 需要使用root\nUSER root\nWORKDIR $MYCAT_HOME/bin\nRUN chmod u+x ./mycat\nEXPOSE 8066 9066\nCMD [\"./mycat\",\"console\"]\n```\n\n\n\nmycat 关键配置，\n\n- rule.xml\n\n- schema.xml\n\n- server.xml\n\n  \n\n含数据库敏感信息，详见上文。\n\n\n\n","source":"_posts/mycat/mycat【4】容器化.md","raw":"---\ntitle: mycat【4】容器化\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\n  - dockerfile\n\nhide: false\ndate: 2021-08-01 12:43:59\nsortn: 40\n---\n\n本章讲的是，mycat 具体实践的代码，小抄\n\n<!-- more -->\n\n------\n\n# mycat容器化\n\n\n\n## dockerfile\n\n当前目录一览\n\n```\n.\n├── Dockerfile\n├── mycat-conf\n│   ├── log4j2.xml\n│   ├── rule.xml\n│   ├── schema.xml\n│   ├── server.xml\n│   └── 此目录会覆盖 mycat/conf ，简略展示\n└── mycat-server-1.6.7.5-release\n    ├── bin\n    ├── catlet\n    ├── conf\n    ├── lib\n    ├── logs\n    └── version.txt\n\n```\n\nDockerfile\n\n```dockerfile\nFROM openjdk:8\n\n\n# 标记mycat 版本号\nENV MYCAT_HOME=/app/mycat\n\n# 添加 mycat - server\nCOPY ./mycat-server-1.6.7.5-release $MYCAT_HOME\n\n# 添加 mycat 分库分表配置\nCOPY ./mycat-conf $MYCAT_HOME/conf\n\n# 添加 mycat -class path\nENV PATH=$PATH:$MYCAT_HOME/bin\n\n# 启动\n# mycat 需要使用root\nUSER root\nWORKDIR $MYCAT_HOME/bin\nRUN chmod u+x ./mycat\nEXPOSE 8066 9066\nCMD [\"./mycat\",\"console\"]\n```\n\n\n\nmycat 关键配置，\n\n- rule.xml\n\n- schema.xml\n\n- server.xml\n\n  \n\n含数据库敏感信息，详见上文。\n\n\n\n","slug":"mycat/mycat【4】容器化","published":1,"updated":"2021-08-01T04:43:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmk0006cpfy6pus5thn","content":"<p>本章讲的是，mycat 具体实践的代码，小抄</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"mycat容器化\"> mycat容器化</span></h1>\n<h2><span id=\"dockerfile\"> dockerfile</span></h2>\n<p>当前目录一览</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs crmsh\">.<br>├── Dockerfile<br>├── mycat-conf<br>│   ├── log4j2.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── rule</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── schema</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── server</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   └── 此目录会覆盖 mycat</span>/conf ，简略展示<br>└── mycat-server-<span class=\"hljs-number\">1.6</span>.<span class=\"hljs-number\">7.5</span>-release<br>    ├── bin<br>    ├── catlet<br>    ├── conf<br>    ├── lib<br>    ├── logs<br>    └── <span class=\"hljs-keyword\">version</span>.txt<br><br></code></pre></div></td></tr></table></figure>\n<p>Dockerfile</p>\n<figure class=\"highlight dockerfile\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs dockerfile\"><span class=\"hljs-keyword\">FROM</span> openjdk:<span class=\"hljs-number\">8</span><br><br><br><span class=\"hljs-comment\"># 标记mycat 版本号</span><br><span class=\"hljs-keyword\">ENV</span> MYCAT_HOME=/app/mycat<br><br><span class=\"hljs-comment\"># 添加 mycat - server</span><br><span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> ./mycat-server-1.6.7.5-release <span class=\"hljs-variable\">$MYCAT_HOME</span></span><br><br><span class=\"hljs-comment\"># 添加 mycat 分库分表配置</span><br><span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> ./mycat-conf <span class=\"hljs-variable\">$MYCAT_HOME</span>/conf</span><br><br><span class=\"hljs-comment\"># 添加 mycat -class path</span><br><span class=\"hljs-keyword\">ENV</span> PATH=$PATH:$MYCAT_HOME/bin<br><br><span class=\"hljs-comment\"># 启动</span><br><span class=\"hljs-comment\"># mycat 需要使用root</span><br><span class=\"hljs-keyword\">USER</span> root<br><span class=\"hljs-keyword\">WORKDIR</span><span class=\"bash\"> <span class=\"hljs-variable\">$MYCAT_HOME</span>/bin</span><br><span class=\"hljs-keyword\">RUN</span><span class=\"bash\"> chmod u+x ./mycat</span><br><span class=\"hljs-keyword\">EXPOSE</span> <span class=\"hljs-number\">8066</span> <span class=\"hljs-number\">9066</span><br><span class=\"hljs-keyword\">CMD</span><span class=\"bash\"> [<span class=\"hljs-string\">&quot;./mycat&quot;</span>,<span class=\"hljs-string\">&quot;console&quot;</span>]</span><br></code></pre></div></td></tr></table></figure>\n<p>mycat 关键配置，</p>\n<ul>\n<li>\n<p>rule.xml</p>\n</li>\n<li>\n<p>schema.xml</p>\n</li>\n<li>\n<p>server.xml</p>\n</li>\n</ul>\n<p>含数据库敏感信息，详见上文。</p>\n","site":{"data":{}},"excerpt":"<p>本章讲的是，mycat 具体实践的代码，小抄</p>","more":"<hr />\n<h1 id=\"mycat容器化\"><a class=\"markdownIt-Anchor\" href=\"#mycat容器化\"></a> mycat容器化</h1>\n<h2 id=\"dockerfile\"><a class=\"markdownIt-Anchor\" href=\"#dockerfile\"></a> dockerfile</h2>\n<p>当前目录一览</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">.<br>├── Dockerfile<br>├── mycat-conf<br>│   ├── log4j2.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── rule</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── schema</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   ├── server</span>.<span class=\"hljs-keyword\">xml</span><br><span class=\"hljs-title\">│   └── 此目录会覆盖 mycat</span>/conf ，简略展示<br>└── mycat-server-<span class=\"hljs-number\">1.6</span>.<span class=\"hljs-number\">7.5</span>-release<br>    ├── bin<br>    ├── catlet<br>    ├── conf<br>    ├── lib<br>    ├── logs<br>    └── <span class=\"hljs-keyword\">version</span>.txt<br><br></code></pre></td></tr></table></figure>\n<p>Dockerfile</p>\n<figure class=\"highlight dockerfile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dockerfile\"><span class=\"hljs-keyword\">FROM</span> openjdk:<span class=\"hljs-number\">8</span><br><br><br><span class=\"hljs-comment\"># 标记mycat 版本号</span><br><span class=\"hljs-keyword\">ENV</span> MYCAT_HOME=/app/mycat<br><br><span class=\"hljs-comment\"># 添加 mycat - server</span><br><span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> ./mycat-server-1.6.7.5-release <span class=\"hljs-variable\">$MYCAT_HOME</span></span><br><br><span class=\"hljs-comment\"># 添加 mycat 分库分表配置</span><br><span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> ./mycat-conf <span class=\"hljs-variable\">$MYCAT_HOME</span>/conf</span><br><br><span class=\"hljs-comment\"># 添加 mycat -class path</span><br><span class=\"hljs-keyword\">ENV</span> PATH=$PATH:$MYCAT_HOME/bin<br><br><span class=\"hljs-comment\"># 启动</span><br><span class=\"hljs-comment\"># mycat 需要使用root</span><br><span class=\"hljs-keyword\">USER</span> root<br><span class=\"hljs-keyword\">WORKDIR</span><span class=\"bash\"> <span class=\"hljs-variable\">$MYCAT_HOME</span>/bin</span><br><span class=\"hljs-keyword\">RUN</span><span class=\"bash\"> chmod u+x ./mycat</span><br><span class=\"hljs-keyword\">EXPOSE</span> <span class=\"hljs-number\">8066</span> <span class=\"hljs-number\">9066</span><br><span class=\"hljs-keyword\">CMD</span><span class=\"bash\"> [<span class=\"hljs-string\">&quot;./mycat&quot;</span>,<span class=\"hljs-string\">&quot;console&quot;</span>]</span><br></code></pre></td></tr></table></figure>\n<p>mycat 关键配置，</p>\n<ul>\n<li>\n<p>rule.xml</p>\n</li>\n<li>\n<p>schema.xml</p>\n</li>\n<li>\n<p>server.xml</p>\n</li>\n</ul>\n<p>含数据库敏感信息，详见上文。</p>"},{"title":"mycat【5】使用技巧","toc":true,"hide":false,"sortn":50,"date":"2021-08-01T06:52:13.000Z","_content":"\nmycat一些常见的使用技巧，和特殊sql语句\n\n<!-- more -->\n\n------\n\n\n\n# mycat 使用技巧\n\n\n\n## mycat 限制\n\n**mycat 不适用的场景**\n\n1. 需要大量使用，mycat禁用sql语句的场景\n2. 经常需要跨分片关联查询的场景，ER分区表，全局表都不合适的时候。\n3. 必须保证跨分片事物的强一致性的时候。\n\n\n\n**mycat 不支持的sql语句**\n\n1. `create table like XXX / create table select XXX`\n\n2. 跨库（跨分片）多表关联查询，子查询\n\n3. `select for update / select lock in share mode` ，\n\n   悲观锁只会锁住一个数据节点，其他数据节点不加锁；并且加锁的时候，也不会抛出异常。\n\n   可能会产生数据不一致。\n\n4. 多表 update 更新 、update 分片键。update 分片键后可能会导致后面的查询找不到数据。\n\n5. 跨分片update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，会造成数据删多了。\n\n   \n\n**mycat 的弱分布式事务**\n\n使用的XA方式提交，但当所有事物ready之后，发送commit，此时有一个节点commit失败，则其他节点不会回滚。\n\n所以 mycat 的XA事物只能支持到 ready 操作之前。\n\n这种情况很难出现。\n\n\n\n## mycat系统配置优化\n\n\n\n### jvm参数优化\n\n配置 /bin/startup_nowrap.sh\n\n\n\n### server.xml 系统参数优化\n\n| 值                   | 解释                                                 | 推荐值                       |\n| -------------------- | ---------------------------------------------------- | ---------------------------- |\n| frontWriteQueueSize  | 指定前端写队列的大小                                 | 2048                         |\n| processors           | 系统可用线程的数量                                   | 根据cpu压力，一般是cpu数量*4 |\n| processorBufferPool  | 指定所使用的ByteBuffer池的总字节容量，<br>单位为字节 | 2097152B                     |\n| processorBufferChunk | 指定所使用的单个ByteBuffer的容量，<br>单位为字节     | 4096B                        |\n| processorExecutor    | 每个processor的线程池大小                            | 16-64                        |\n\n\n\n#### log4j2.xml 日志级别优化\n\n修改日志级别就好，其他不用动\n\n```xml\n<asyncRoot level=\"info\" includeLocation=\"true\">\n```\n\n\n\n\n\n## mycat-web性能监控工具\n\n已经打好包，在dockerhub上。\n\n```sh\ndocker run --name mycat-web -d -p 8082:8082 --restart=always coolflame/mycat-web  \n```\n\n访问地址：\n\nhttp://localhost:8082/mycat/\n\n\n\n## mycat常用sql语句\n\n使用 ` mysql -u[username] -p -P[管理端口，默认9066] -h[ip]`连接MyCat命令行管理端\n\n```mysql\n-- 常用:\n# sql统计: 高频sql\nshow @@sql.high;\n# sql统计: 大返回值\nshow @@sql.resultset  ;\n# sql统计: 慢查询\nshow @@sql.slow  ;\n# 线程池状态\nshow @@threadpool ;\n\n-- 不常用:\n#连接信息\nshow @@connection \n#后端库信息\nshow @@datasource;\n#非堆内存使用情况\nshow @@directmemory=1;\n#心跳情况\nshow @@heartbeat ;\n#活动线程情况\nshow @@processor;\n#mycat 服务器情况,主要是内存使用\nshow @@server;\n```\n\n\n\n## 使用MyCat生成执行SQL记录\n\n在server.xml的system标签下配置拦截\n\n```xml\n<system>\n  <!-- 配置拦截器 -->\n  <property name=\"sqlInterceptor\">\n    io.mycat.server.interceptor.impl.StatisticsSqlInterceptor\n  </property>\n  <!-- 配置拦截SQL类型 -->\n  <property name=\"sqlInterceptorType\">\n    select，update，insert，delete\n  </property>\n  <!-- 配置SQL生成文件位置 -->\n  <property name=\"sqlInterceptorFile\">\n    /opt/mycat/InterceptorFile/sql.txt\n  </property>\n</system>\n```\n","source":"_posts/mycat/mycat【5】使用技巧.md","raw":"---\ntitle: mycat【5】使用技巧\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\nhide: false\nsortn: 50\ndate: 2021-08-01 14:52:13\n---\n\nmycat一些常见的使用技巧，和特殊sql语句\n\n<!-- more -->\n\n------\n\n\n\n# mycat 使用技巧\n\n\n\n## mycat 限制\n\n**mycat 不适用的场景**\n\n1. 需要大量使用，mycat禁用sql语句的场景\n2. 经常需要跨分片关联查询的场景，ER分区表，全局表都不合适的时候。\n3. 必须保证跨分片事物的强一致性的时候。\n\n\n\n**mycat 不支持的sql语句**\n\n1. `create table like XXX / create table select XXX`\n\n2. 跨库（跨分片）多表关联查询，子查询\n\n3. `select for update / select lock in share mode` ，\n\n   悲观锁只会锁住一个数据节点，其他数据节点不加锁；并且加锁的时候，也不会抛出异常。\n\n   可能会产生数据不一致。\n\n4. 多表 update 更新 、update 分片键。update 分片键后可能会导致后面的查询找不到数据。\n\n5. 跨分片update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，会造成数据删多了。\n\n   \n\n**mycat 的弱分布式事务**\n\n使用的XA方式提交，但当所有事物ready之后，发送commit，此时有一个节点commit失败，则其他节点不会回滚。\n\n所以 mycat 的XA事物只能支持到 ready 操作之前。\n\n这种情况很难出现。\n\n\n\n## mycat系统配置优化\n\n\n\n### jvm参数优化\n\n配置 /bin/startup_nowrap.sh\n\n\n\n### server.xml 系统参数优化\n\n| 值                   | 解释                                                 | 推荐值                       |\n| -------------------- | ---------------------------------------------------- | ---------------------------- |\n| frontWriteQueueSize  | 指定前端写队列的大小                                 | 2048                         |\n| processors           | 系统可用线程的数量                                   | 根据cpu压力，一般是cpu数量*4 |\n| processorBufferPool  | 指定所使用的ByteBuffer池的总字节容量，<br>单位为字节 | 2097152B                     |\n| processorBufferChunk | 指定所使用的单个ByteBuffer的容量，<br>单位为字节     | 4096B                        |\n| processorExecutor    | 每个processor的线程池大小                            | 16-64                        |\n\n\n\n#### log4j2.xml 日志级别优化\n\n修改日志级别就好，其他不用动\n\n```xml\n<asyncRoot level=\"info\" includeLocation=\"true\">\n```\n\n\n\n\n\n## mycat-web性能监控工具\n\n已经打好包，在dockerhub上。\n\n```sh\ndocker run --name mycat-web -d -p 8082:8082 --restart=always coolflame/mycat-web  \n```\n\n访问地址：\n\nhttp://localhost:8082/mycat/\n\n\n\n## mycat常用sql语句\n\n使用 ` mysql -u[username] -p -P[管理端口，默认9066] -h[ip]`连接MyCat命令行管理端\n\n```mysql\n-- 常用:\n# sql统计: 高频sql\nshow @@sql.high;\n# sql统计: 大返回值\nshow @@sql.resultset  ;\n# sql统计: 慢查询\nshow @@sql.slow  ;\n# 线程池状态\nshow @@threadpool ;\n\n-- 不常用:\n#连接信息\nshow @@connection \n#后端库信息\nshow @@datasource;\n#非堆内存使用情况\nshow @@directmemory=1;\n#心跳情况\nshow @@heartbeat ;\n#活动线程情况\nshow @@processor;\n#mycat 服务器情况,主要是内存使用\nshow @@server;\n```\n\n\n\n## 使用MyCat生成执行SQL记录\n\n在server.xml的system标签下配置拦截\n\n```xml\n<system>\n  <!-- 配置拦截器 -->\n  <property name=\"sqlInterceptor\">\n    io.mycat.server.interceptor.impl.StatisticsSqlInterceptor\n  </property>\n  <!-- 配置拦截SQL类型 -->\n  <property name=\"sqlInterceptorType\">\n    select，update，insert，delete\n  </property>\n  <!-- 配置SQL生成文件位置 -->\n  <property name=\"sqlInterceptorFile\">\n    /opt/mycat/InterceptorFile/sql.txt\n  </property>\n</system>\n```\n","slug":"mycat/mycat【5】使用技巧","published":1,"updated":"2021-08-01T06:52:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxml0007cpfy96tk8kkj","content":"<p>mycat一些常见的使用技巧，和特殊sql语句</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"mycat-使用技巧\"> mycat 使用技巧</span></h1>\n<h2><span id=\"mycat-限制\"> mycat 限制</span></h2>\n<p><strong>mycat 不适用的场景</strong></p>\n<ol>\n<li>需要大量使用，mycat禁用sql语句的场景</li>\n<li>经常需要跨分片关联查询的场景，ER分区表，全局表都不合适的时候。</li>\n<li>必须保证跨分片事物的强一致性的时候。</li>\n</ol>\n<p><strong>mycat 不支持的sql语句</strong></p>\n<ol>\n<li>\n<p><code>create table like XXX / create table select XXX</code></p>\n</li>\n<li>\n<p>跨库（跨分片）多表关联查询，子查询</p>\n</li>\n<li>\n<p><code>select for update / select lock in share mode</code> ，</p>\n<p>悲观锁只会锁住一个数据节点，其他数据节点不加锁；并且加锁的时候，也不会抛出异常。</p>\n<p>可能会产生数据不一致。</p>\n</li>\n<li>\n<p>多表 update 更新 、update 分片键。update 分片键后可能会导致后面的查询找不到数据。</p>\n</li>\n<li>\n<p>跨分片update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，会造成数据删多了。</p>\n</li>\n</ol>\n<p><strong>mycat 的弱分布式事务</strong></p>\n<p>使用的XA方式提交，但当所有事物ready之后，发送commit，此时有一个节点commit失败，则其他节点不会回滚。</p>\n<p>所以 mycat 的XA事物只能支持到 ready 操作之前。</p>\n<p>这种情况很难出现。</p>\n<h2><span id=\"mycat系统配置优化\"> mycat系统配置优化</span></h2>\n<h3><span id=\"jvm参数优化\"> jvm参数优化</span></h3>\n<p>配置 /bin/startup_nowrap.sh</p>\n<h3><span id=\"serverxml-系统参数优化\"> server.xml 系统参数优化</span></h3>\n<table>\n<thead>\n<tr>\n<th>值</th>\n<th>解释</th>\n<th>推荐值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>frontWriteQueueSize</td>\n<td>指定前端写队列的大小</td>\n<td>2048</td>\n</tr>\n<tr>\n<td>processors</td>\n<td>系统可用线程的数量</td>\n<td>根据cpu压力，一般是cpu数量*4</td>\n</tr>\n<tr>\n<td>processorBufferPool</td>\n<td>指定所使用的ByteBuffer池的总字节容量，<br>单位为字节</td>\n<td>2097152B</td>\n</tr>\n<tr>\n<td>processorBufferChunk</td>\n<td>指定所使用的单个ByteBuffer的容量，<br>单位为字节</td>\n<td>4096B</td>\n</tr>\n<tr>\n<td>processorExecutor</td>\n<td>每个processor的线程池大小</td>\n<td>16-64</td>\n</tr>\n</tbody>\n</table>\n<h4><span id=\"log4j2xml-日志级别优化\"> log4j2.xml 日志级别优化</span></h4>\n<p>修改日志级别就好，其他不用动</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">asyncRoot</span> <span class=\"hljs-attr\">level</span>=<span class=\"hljs-string\">&quot;info&quot;</span> <span class=\"hljs-attr\">includeLocation</span>=<span class=\"hljs-string\">&quot;true&quot;</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n<h2><span id=\"mycat-web性能监控工具\"> mycat-web性能监控工具</span></h2>\n<p>已经打好包，在dockerhub上。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs sh\">docker run --name mycat-web -d -p 8082:8082 --restart=always coolflame/mycat-web  <br></code></pre></div></td></tr></table></figure>\n<p>访问地址：</p>\n<p><a href=\"http://localhost:8082/mycat/\">http://localhost:8082/mycat/</a></p>\n<h2><span id=\"mycat常用sql语句\"> mycat常用sql语句</span></h2>\n<p>使用 <code>mysql -u[username] -p -P[管理端口，默认9066] -h[ip]</code>连接MyCat命令行管理端</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs mysql\">-- 常用:<br># sql统计: 高频sql<br>show @@sql.high;<br># sql统计: 大返回值<br>show @@sql.resultset  ;<br># sql统计: 慢查询<br>show @@sql.slow  ;<br># 线程池状态<br>show @@threadpool ;<br><br>-- 不常用:<br>#连接信息<br>show @@connection <br>#后端库信息<br>show @@datasource;<br>#非堆内存使用情况<br>show @@directmemory=1;<br>#心跳情况<br>show @@heartbeat ;<br>#活动线程情况<br>show @@processor;<br>#mycat 服务器情况,主要是内存使用<br>show @@server;<br></code></pre></div></td></tr></table></figure>\n<h2><span id=\"使用mycat生成执行sql记录\"> 使用MyCat生成执行SQL记录</span></h2>\n<p>在server.xml的system标签下配置拦截</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">system</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置拦截器 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptor&quot;</span>&gt;</span><br>    io.mycat.server.interceptor.impl.StatisticsSqlInterceptor<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置拦截SQL类型 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptorType&quot;</span>&gt;</span><br>    select，update，insert，delete<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置SQL生成文件位置 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptorFile&quot;</span>&gt;</span><br>    /opt/mycat/InterceptorFile/sql.txt<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">system</span>&gt;</span><br></code></pre></div></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>mycat一些常见的使用技巧，和特殊sql语句</p>","more":"<hr />\n<h1 id=\"mycat-使用技巧\"><a class=\"markdownIt-Anchor\" href=\"#mycat-使用技巧\"></a> mycat 使用技巧</h1>\n<h2 id=\"mycat-限制\"><a class=\"markdownIt-Anchor\" href=\"#mycat-限制\"></a> mycat 限制</h2>\n<p><strong>mycat 不适用的场景</strong></p>\n<ol>\n<li>需要大量使用，mycat禁用sql语句的场景</li>\n<li>经常需要跨分片关联查询的场景，ER分区表，全局表都不合适的时候。</li>\n<li>必须保证跨分片事物的强一致性的时候。</li>\n</ol>\n<p><strong>mycat 不支持的sql语句</strong></p>\n<ol>\n<li>\n<p><code>create table like XXX / create table select XXX</code></p>\n</li>\n<li>\n<p>跨库（跨分片）多表关联查询，子查询</p>\n</li>\n<li>\n<p><code>select for update / select lock in share mode</code> ，</p>\n<p>悲观锁只会锁住一个数据节点，其他数据节点不加锁；并且加锁的时候，也不会抛出异常。</p>\n<p>可能会产生数据不一致。</p>\n</li>\n<li>\n<p>多表 update 更新 、update 分片键。update 分片键后可能会导致后面的查询找不到数据。</p>\n</li>\n<li>\n<p>跨分片update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，会造成数据删多了。</p>\n</li>\n</ol>\n<p><strong>mycat 的弱分布式事务</strong></p>\n<p>使用的XA方式提交，但当所有事物ready之后，发送commit，此时有一个节点commit失败，则其他节点不会回滚。</p>\n<p>所以 mycat 的XA事物只能支持到 ready 操作之前。</p>\n<p>这种情况很难出现。</p>\n<h2 id=\"mycat系统配置优化\"><a class=\"markdownIt-Anchor\" href=\"#mycat系统配置优化\"></a> mycat系统配置优化</h2>\n<h3 id=\"jvm参数优化\"><a class=\"markdownIt-Anchor\" href=\"#jvm参数优化\"></a> jvm参数优化</h3>\n<p>配置 /bin/startup_nowrap.sh</p>\n<h3 id=\"serverxml-系统参数优化\"><a class=\"markdownIt-Anchor\" href=\"#serverxml-系统参数优化\"></a> server.xml 系统参数优化</h3>\n<table>\n<thead>\n<tr>\n<th>值</th>\n<th>解释</th>\n<th>推荐值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>frontWriteQueueSize</td>\n<td>指定前端写队列的大小</td>\n<td>2048</td>\n</tr>\n<tr>\n<td>processors</td>\n<td>系统可用线程的数量</td>\n<td>根据cpu压力，一般是cpu数量*4</td>\n</tr>\n<tr>\n<td>processorBufferPool</td>\n<td>指定所使用的ByteBuffer池的总字节容量，<br>单位为字节</td>\n<td>2097152B</td>\n</tr>\n<tr>\n<td>processorBufferChunk</td>\n<td>指定所使用的单个ByteBuffer的容量，<br>单位为字节</td>\n<td>4096B</td>\n</tr>\n<tr>\n<td>processorExecutor</td>\n<td>每个processor的线程池大小</td>\n<td>16-64</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"log4j2xml-日志级别优化\"><a class=\"markdownIt-Anchor\" href=\"#log4j2xml-日志级别优化\"></a> log4j2.xml 日志级别优化</h4>\n<p>修改日志级别就好，其他不用动</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">asyncRoot</span> <span class=\"hljs-attr\">level</span>=<span class=\"hljs-string\">&quot;info&quot;</span> <span class=\"hljs-attr\">includeLocation</span>=<span class=\"hljs-string\">&quot;true&quot;</span>&gt;</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"mycat-web性能监控工具\"><a class=\"markdownIt-Anchor\" href=\"#mycat-web性能监控工具\"></a> mycat-web性能监控工具</h2>\n<p>已经打好包，在dockerhub上。</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sh\">docker run --name mycat-web -d -p 8082:8082 --restart=always coolflame/mycat-web  <br></code></pre></td></tr></table></figure>\n<p>访问地址：</p>\n<p><a href=\"http://localhost:8082/mycat/\">http://localhost:8082/mycat/</a></p>\n<h2 id=\"mycat常用sql语句\"><a class=\"markdownIt-Anchor\" href=\"#mycat常用sql语句\"></a> mycat常用sql语句</h2>\n<p>使用 <code>mysql -u[username] -p -P[管理端口，默认9066] -h[ip]</code>连接MyCat命令行管理端</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">-- 常用:<br># sql统计: 高频sql<br>show @@sql.high;<br># sql统计: 大返回值<br>show @@sql.resultset  ;<br># sql统计: 慢查询<br>show @@sql.slow  ;<br># 线程池状态<br>show @@threadpool ;<br><br>-- 不常用:<br>#连接信息<br>show @@connection <br>#后端库信息<br>show @@datasource;<br>#非堆内存使用情况<br>show @@directmemory=1;<br>#心跳情况<br>show @@heartbeat ;<br>#活动线程情况<br>show @@processor;<br>#mycat 服务器情况,主要是内存使用<br>show @@server;<br></code></pre></td></tr></table></figure>\n<h2 id=\"使用mycat生成执行sql记录\"><a class=\"markdownIt-Anchor\" href=\"#使用mycat生成执行sql记录\"></a> 使用MyCat生成执行SQL记录</h2>\n<p>在server.xml的system标签下配置拦截</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">system</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置拦截器 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptor&quot;</span>&gt;</span><br>    io.mycat.server.interceptor.impl.StatisticsSqlInterceptor<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置拦截SQL类型 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptorType&quot;</span>&gt;</span><br>    select，update，insert，delete<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br>  <span class=\"hljs-comment\">&lt;!-- 配置SQL生成文件位置 --&gt;</span><br>  <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">property</span> <span class=\"hljs-attr\">name</span>=<span class=\"hljs-string\">&quot;sqlInterceptorFile&quot;</span>&gt;</span><br>    /opt/mycat/InterceptorFile/sql.txt<br>  <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">property</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">system</span>&gt;</span><br></code></pre></td></tr></table></figure>"},{"title":"innodb存储实现","toc":true,"hide":false,"date":"2021-07-30T14:15:07.000Z","sortn":10,"_content":"\n\n\n本章主要介绍 innodb 引擎的存储实现\n\n<!-- more -->\n\n------\n\n\n\n## mysql innodb 存储磁盘存储结构\n\n\n\ninnodb 的存储结构分为 5 级：**表空间、段、簇、页、行。**\n\n\n\n###  簇（B+树，聚簇索引）\n\n![img](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png)\n\n- 整个树有序，结构类似于跳表。\n- 分为非叶子节点、叶子节点\n- 非叶子节点，存主键+下一级指针。叶子节点存主键+数据\n- 行是有序的，根据主键排序，所以支持2分查找\n- 数据有冗余，有未分配空间，有已删除空间。所以数据主键要保递增，减少碎片化。\n\n\n\n### 页(Page)\n\n\n\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210730224756.png\" alt=\"image-20210730224756023\" style=\"zoom:40%;\" />\n\n\n\n- 默认1页为16kb\n- 页头，本页基本信息\n- 虚记录，本页最小主键，本页最大主键。\n- 【行】记录堆，行记录存储区，分为有效记录和已删除记录\n- 未分配空间，页中未使用的空间\n- 页尾，占8字节，主键存页面的校验信息\n\n\n\n## mysql innodb 内存管理\n\n\n\ntodo\n\n\n\n\n\n\n\n## mysql innodb 事务实现原理\n\n\n\n### 事务特性：\n\n- A（atomicity 原子性）：全部成功，全部失败。不允许中间状态\n- I （isolation 隔离性）：并行事务不干扰\n- D（Durability 持久性）：提交事务后，数据不能丢\n- C（consistency 一致性）：凑数的\n\n\n\n### 并发问题：\n\n- 脏读（dirty read）： 读取到其他事务，没有提交的数据\n- 不可重复读（non-repeatable read）：查询同一条数据两次，有可能结果不一样\n- 幻读（phantom read）：select 出来的结果，可能是不存在的。<br>被其他事务插入后又删了，但中间存在期间，本事务恰好扫描到他了\n\n\n\n### 隔离级别：\n\n- Read Uncommitted（读取未提交内容）: 最低隔离级别，会读取到其他事务未提交的数据，\n\n  出现的问题：**脏读**\n\n- Read Committed（读取提交内容）: 事务过程中可以读取到其他事务已提交的数据，\n\n  出现的问：**不可重复读**\n\n- Repeatable Read（可重复读）: 每次读取相同结果集，不管其他事务是否提交，\n\n  出现的问题：**幻读**\n\n- Serializable （串行化）: 事务排队，隔离级别最高，性能最差;\n\n  出现的问题：**性能差**\n\n- 总结：\n\n  1. 一般使用 RR （可重复读），但写事务的时候，尽量避免 select 范围修改。<br>如果有范围修改，则思考一下，有没有可能出现幻读，如果出现了是否有影响。\n  2. 对于innodb，mvcc 并没有完全解决幻读问题。\n\n\n\n## innodb - mvcc\n\n\n\n### 两种查询模式\n\n- 当前读：永远查询某一行数据的最新的版本\n- 读快照：假设当前事务为A，根据事务A的 trx id（事务id）总能查到，A事务开启的那一刻， <br>数据的历史版本快照。这个快照是永远不会发生改变的。\n\n\n\n### 可见性逻辑\n\n- trx id 指的是事务id，是一个自增的序列。id 大，证明事务发生的时间靠后\n- innodb 维护一个事务活跃列表，即 select * from information_schema.INNODB_TRX 查出来的数据。\n- 可见性逻辑：\n  1. 事务开始的那一刻，查询所有当前事务。tmp_trx = [当前所有事务id]\n  2. tmp_trx_max = [时间轴最靠后的事务]，tmp_trx_min = [时间轴最靠前的事务]\n  3. 搜索出来的数据，需要满足2个条件其中之一即可。\n     - 事务id，比tmp_trx_min 的id要小（查出来的记录，在事务创建之前，就提交了）\n     - 不在事务活跃列表里面。（这个事务跑得快，已经先一步提交）\n  4. 如果不满足，则通过历史版本指针，找到该行数据的历史快照，正常使用即可\n\n\n\n## mysql 锁实现原理\n\n\n\n### **需要加锁的语句**\n\nselect for update 、update、delete ，其他语句不用加锁。\n\n\n\n### **分析锁的几个重要前提**\n\n- 索引：唯一索引 、 非唯一索引\n- 事务隔离级别：RC 、 RR\n\n\n\n### **根据颗粒度划分**\n\n- 行级，锁1行\n\n  - RC下，唯一索引，非唯一索引，使用该级别锁。\n\n    RR下，唯一索引，使用该级别\n\n  - 作用在索引上\n\n  - 聚簇索引 & 二级索引\n\n    \n\n- 间隙，锁一部分\n\n  - RR下，唯一索引，才使用这个锁类型\n\n  - 索引是有序的，新的记录插入，只能插入到GAP区间内；<br>GAP锁，是计算出两条记录之间的GAP；<br>一旦锁住这个GAP。就封住了新纪录插入的可能性；<br>就能保证2次当前读返回的数据是一致的。\n\n  - GAP锁的问题：查询where条件没有索引的时候，没法加GAP锁，很容易锁升级为表锁。\n\n    \n\n- 表级，锁1个表\n\n  - **没有命中索引的时候，有概率锁表，概率还不小。**\n  - 所以，事务中，加锁的语句中的where条件一定要加索引。\n  - 一般来说，分两个步骤实现修改\n    1. 范围查询，返回主键id\n    2. 根据主键id list 进行 update。\n\n  \n\n### **根据类型划分**\n\n- 共享锁\n  - 读锁，可以被多个事务获取，阻止其他事务对记录的修改\n- 排他锁\n  - 写锁，只能被1个事务获取，只允许获得锁的事务修改数据\n","source":"_posts/mysql/innodb存储实现.md","raw":"---\ntitle: 'innodb存储实现'\ntoc: true\ncategories:\n  - 数据库\n  - mysql\ntags:\n  - innodb\nhide: false\ndate: 2021-07-30 22:15:07\nsortn: 10\n---\n\n\n\n本章主要介绍 innodb 引擎的存储实现\n\n<!-- more -->\n\n------\n\n\n\n## mysql innodb 存储磁盘存储结构\n\n\n\ninnodb 的存储结构分为 5 级：**表空间、段、簇、页、行。**\n\n\n\n###  簇（B+树，聚簇索引）\n\n![img](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png)\n\n- 整个树有序，结构类似于跳表。\n- 分为非叶子节点、叶子节点\n- 非叶子节点，存主键+下一级指针。叶子节点存主键+数据\n- 行是有序的，根据主键排序，所以支持2分查找\n- 数据有冗余，有未分配空间，有已删除空间。所以数据主键要保递增，减少碎片化。\n\n\n\n### 页(Page)\n\n\n\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210730224756.png\" alt=\"image-20210730224756023\" style=\"zoom:40%;\" />\n\n\n\n- 默认1页为16kb\n- 页头，本页基本信息\n- 虚记录，本页最小主键，本页最大主键。\n- 【行】记录堆，行记录存储区，分为有效记录和已删除记录\n- 未分配空间，页中未使用的空间\n- 页尾，占8字节，主键存页面的校验信息\n\n\n\n## mysql innodb 内存管理\n\n\n\ntodo\n\n\n\n\n\n\n\n## mysql innodb 事务实现原理\n\n\n\n### 事务特性：\n\n- A（atomicity 原子性）：全部成功，全部失败。不允许中间状态\n- I （isolation 隔离性）：并行事务不干扰\n- D（Durability 持久性）：提交事务后，数据不能丢\n- C（consistency 一致性）：凑数的\n\n\n\n### 并发问题：\n\n- 脏读（dirty read）： 读取到其他事务，没有提交的数据\n- 不可重复读（non-repeatable read）：查询同一条数据两次，有可能结果不一样\n- 幻读（phantom read）：select 出来的结果，可能是不存在的。<br>被其他事务插入后又删了，但中间存在期间，本事务恰好扫描到他了\n\n\n\n### 隔离级别：\n\n- Read Uncommitted（读取未提交内容）: 最低隔离级别，会读取到其他事务未提交的数据，\n\n  出现的问题：**脏读**\n\n- Read Committed（读取提交内容）: 事务过程中可以读取到其他事务已提交的数据，\n\n  出现的问：**不可重复读**\n\n- Repeatable Read（可重复读）: 每次读取相同结果集，不管其他事务是否提交，\n\n  出现的问题：**幻读**\n\n- Serializable （串行化）: 事务排队，隔离级别最高，性能最差;\n\n  出现的问题：**性能差**\n\n- 总结：\n\n  1. 一般使用 RR （可重复读），但写事务的时候，尽量避免 select 范围修改。<br>如果有范围修改，则思考一下，有没有可能出现幻读，如果出现了是否有影响。\n  2. 对于innodb，mvcc 并没有完全解决幻读问题。\n\n\n\n## innodb - mvcc\n\n\n\n### 两种查询模式\n\n- 当前读：永远查询某一行数据的最新的版本\n- 读快照：假设当前事务为A，根据事务A的 trx id（事务id）总能查到，A事务开启的那一刻， <br>数据的历史版本快照。这个快照是永远不会发生改变的。\n\n\n\n### 可见性逻辑\n\n- trx id 指的是事务id，是一个自增的序列。id 大，证明事务发生的时间靠后\n- innodb 维护一个事务活跃列表，即 select * from information_schema.INNODB_TRX 查出来的数据。\n- 可见性逻辑：\n  1. 事务开始的那一刻，查询所有当前事务。tmp_trx = [当前所有事务id]\n  2. tmp_trx_max = [时间轴最靠后的事务]，tmp_trx_min = [时间轴最靠前的事务]\n  3. 搜索出来的数据，需要满足2个条件其中之一即可。\n     - 事务id，比tmp_trx_min 的id要小（查出来的记录，在事务创建之前，就提交了）\n     - 不在事务活跃列表里面。（这个事务跑得快，已经先一步提交）\n  4. 如果不满足，则通过历史版本指针，找到该行数据的历史快照，正常使用即可\n\n\n\n## mysql 锁实现原理\n\n\n\n### **需要加锁的语句**\n\nselect for update 、update、delete ，其他语句不用加锁。\n\n\n\n### **分析锁的几个重要前提**\n\n- 索引：唯一索引 、 非唯一索引\n- 事务隔离级别：RC 、 RR\n\n\n\n### **根据颗粒度划分**\n\n- 行级，锁1行\n\n  - RC下，唯一索引，非唯一索引，使用该级别锁。\n\n    RR下，唯一索引，使用该级别\n\n  - 作用在索引上\n\n  - 聚簇索引 & 二级索引\n\n    \n\n- 间隙，锁一部分\n\n  - RR下，唯一索引，才使用这个锁类型\n\n  - 索引是有序的，新的记录插入，只能插入到GAP区间内；<br>GAP锁，是计算出两条记录之间的GAP；<br>一旦锁住这个GAP。就封住了新纪录插入的可能性；<br>就能保证2次当前读返回的数据是一致的。\n\n  - GAP锁的问题：查询where条件没有索引的时候，没法加GAP锁，很容易锁升级为表锁。\n\n    \n\n- 表级，锁1个表\n\n  - **没有命中索引的时候，有概率锁表，概率还不小。**\n  - 所以，事务中，加锁的语句中的where条件一定要加索引。\n  - 一般来说，分两个步骤实现修改\n    1. 范围查询，返回主键id\n    2. 根据主键id list 进行 update。\n\n  \n\n### **根据类型划分**\n\n- 共享锁\n  - 读锁，可以被多个事务获取，阻止其他事务对记录的修改\n- 排他锁\n  - 写锁，只能被1个事务获取，只允许获得锁的事务修改数据\n","slug":"mysql/innodb存储实现","published":1,"updated":"2021-07-30T14:15:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmn000acpfy65xj4jj9","content":"<p>本章主要介绍 innodb 引擎的存储实现</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"mysql-innodb-存储磁盘存储结构\"> mysql innodb 存储磁盘存储结构</span></h2>\n<p>innodb 的存储结构分为 5 级：<strong>表空间、段、簇、页、行。</strong></p>\n<h3><span id=\"簇b树聚簇索引\"> 簇（B+树，聚簇索引）</span></h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png\" alt=\"img\"></p>\n<ul>\n<li>整个树有序，结构类似于跳表。</li>\n<li>分为非叶子节点、叶子节点</li>\n<li>非叶子节点，存主键+下一级指针。叶子节点存主键+数据</li>\n<li>行是有序的，根据主键排序，所以支持2分查找</li>\n<li>数据有冗余，有未分配空间，有已删除空间。所以数据主键要保递增，减少碎片化。</li>\n</ul>\n<h3><span id=\"页page\"> 页(Page)</span></h3>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210730224756.png\" alt=\"image-20210730224756023\" style=\"zoom:40%;\">\n<ul>\n<li>默认1页为16kb</li>\n<li>页头，本页基本信息</li>\n<li>虚记录，本页最小主键，本页最大主键。</li>\n<li>【行】记录堆，行记录存储区，分为有效记录和已删除记录</li>\n<li>未分配空间，页中未使用的空间</li>\n<li>页尾，占8字节，主键存页面的校验信息</li>\n</ul>\n<h2><span id=\"mysql-innodb-内存管理\"> mysql innodb 内存管理</span></h2>\n<p>todo</p>\n<h2><span id=\"mysql-innodb-事务实现原理\"> mysql innodb 事务实现原理</span></h2>\n<h3><span id=\"事务特性\"> 事务特性：</span></h3>\n<ul>\n<li>A（atomicity 原子性）：全部成功，全部失败。不允许中间状态</li>\n<li>I （isolation 隔离性）：并行事务不干扰</li>\n<li>D（Durability 持久性）：提交事务后，数据不能丢</li>\n<li>C（consistency 一致性）：凑数的</li>\n</ul>\n<h3><span id=\"并发问题\"> 并发问题：</span></h3>\n<ul>\n<li>脏读（dirty read）： 读取到其他事务，没有提交的数据</li>\n<li>不可重复读（non-repeatable read）：查询同一条数据两次，有可能结果不一样</li>\n<li>幻读（phantom read）：select 出来的结果，可能是不存在的。<br>被其他事务插入后又删了，但中间存在期间，本事务恰好扫描到他了</li>\n</ul>\n<h3><span id=\"隔离级别\"> 隔离级别：</span></h3>\n<ul>\n<li>\n<p>Read Uncommitted（读取未提交内容）: 最低隔离级别，会读取到其他事务未提交的数据，</p>\n<p>出现的问题：<strong>脏读</strong></p>\n</li>\n<li>\n<p>Read Committed（读取提交内容）: 事务过程中可以读取到其他事务已提交的数据，</p>\n<p>出现的问：<strong>不可重复读</strong></p>\n</li>\n<li>\n<p>Repeatable Read（可重复读）: 每次读取相同结果集，不管其他事务是否提交，</p>\n<p>出现的问题：<strong>幻读</strong></p>\n</li>\n<li>\n<p>Serializable （串行化）: 事务排队，隔离级别最高，性能最差;</p>\n<p>出现的问题：<strong>性能差</strong></p>\n</li>\n<li>\n<p>总结：</p>\n<ol>\n<li>一般使用 RR （可重复读），但写事务的时候，尽量避免 select 范围修改。<br>如果有范围修改，则思考一下，有没有可能出现幻读，如果出现了是否有影响。</li>\n<li>对于innodb，mvcc 并没有完全解决幻读问题。</li>\n</ol>\n</li>\n</ul>\n<h2><span id=\"innodb-mvcc\"> innodb - mvcc</span></h2>\n<h3><span id=\"两种查询模式\"> 两种查询模式</span></h3>\n<ul>\n<li>当前读：永远查询某一行数据的最新的版本</li>\n<li>读快照：假设当前事务为A，根据事务A的 trx id（事务id）总能查到，A事务开启的那一刻， <br>数据的历史版本快照。这个快照是永远不会发生改变的。</li>\n</ul>\n<h3><span id=\"可见性逻辑\"> 可见性逻辑</span></h3>\n<ul>\n<li>trx id 指的是事务id，是一个自增的序列。id 大，证明事务发生的时间靠后</li>\n<li>innodb 维护一个事务活跃列表，即 select * from information_schema.INNODB_TRX 查出来的数据。</li>\n<li>可见性逻辑：\n<ol>\n<li>事务开始的那一刻，查询所有当前事务。tmp_trx = [当前所有事务id]</li>\n<li>tmp_trx_max = [时间轴最靠后的事务]，tmp_trx_min = [时间轴最靠前的事务]</li>\n<li>搜索出来的数据，需要满足2个条件其中之一即可。\n<ul>\n<li>事务id，比tmp_trx_min 的id要小（查出来的记录，在事务创建之前，就提交了）</li>\n<li>不在事务活跃列表里面。（这个事务跑得快，已经先一步提交）</li>\n</ul>\n</li>\n<li>如果不满足，则通过历史版本指针，找到该行数据的历史快照，正常使用即可</li>\n</ol>\n</li>\n</ul>\n<h2><span id=\"mysql-锁实现原理\"> mysql 锁实现原理</span></h2>\n<h3><span id=\"需要加锁的语句\"> <strong>需要加锁的语句</strong></span></h3>\n<p>select for update 、update、delete ，其他语句不用加锁。</p>\n<h3><span id=\"分析锁的几个重要前提\"> <strong>分析锁的几个重要前提</strong></span></h3>\n<ul>\n<li>索引：唯一索引 、 非唯一索引</li>\n<li>事务隔离级别：RC 、 RR</li>\n</ul>\n<h3><span id=\"根据颗粒度划分\"> <strong>根据颗粒度划分</strong></span></h3>\n<ul>\n<li>\n<p>行级，锁1行</p>\n<ul>\n<li>\n<p>RC下，唯一索引，非唯一索引，使用该级别锁。</p>\n<p>RR下，唯一索引，使用该级别</p>\n</li>\n<li>\n<p>作用在索引上</p>\n</li>\n<li>\n<p>聚簇索引 &amp; 二级索引</p>\n</li>\n</ul>\n</li>\n<li>\n<p>间隙，锁一部分</p>\n<ul>\n<li>\n<p>RR下，唯一索引，才使用这个锁类型</p>\n</li>\n<li>\n<p>索引是有序的，新的记录插入，只能插入到GAP区间内；<br>GAP锁，是计算出两条记录之间的GAP；<br>一旦锁住这个GAP。就封住了新纪录插入的可能性；<br>就能保证2次当前读返回的数据是一致的。</p>\n</li>\n<li>\n<p>GAP锁的问题：查询where条件没有索引的时候，没法加GAP锁，很容易锁升级为表锁。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>表级，锁1个表</p>\n<ul>\n<li><strong>没有命中索引的时候，有概率锁表，概率还不小。</strong></li>\n<li>所以，事务中，加锁的语句中的where条件一定要加索引。</li>\n<li>一般来说，分两个步骤实现修改\n<ol>\n<li>范围查询，返回主键id</li>\n<li>根据主键id list 进行 update。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"根据类型划分\"> <strong>根据类型划分</strong></span></h3>\n<ul>\n<li>共享锁\n<ul>\n<li>读锁，可以被多个事务获取，阻止其他事务对记录的修改</li>\n</ul>\n</li>\n<li>排他锁\n<ul>\n<li>写锁，只能被1个事务获取，只允许获得锁的事务修改数据</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本章主要介绍 innodb 引擎的存储实现</p>","more":"<hr />\n<h2 id=\"mysql-innodb-存储磁盘存储结构\"><a class=\"markdownIt-Anchor\" href=\"#mysql-innodb-存储磁盘存储结构\"></a> mysql innodb 存储磁盘存储结构</h2>\n<p>innodb 的存储结构分为 5 级：<strong>表空间、段、簇、页、行。</strong></p>\n<h3 id=\"簇b树聚簇索引\"><a class=\"markdownIt-Anchor\" href=\"#簇b树聚簇索引\"></a> 簇（B+树，聚簇索引）</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png\" alt=\"img\" /></p>\n<ul>\n<li>整个树有序，结构类似于跳表。</li>\n<li>分为非叶子节点、叶子节点</li>\n<li>非叶子节点，存主键+下一级指针。叶子节点存主键+数据</li>\n<li>行是有序的，根据主键排序，所以支持2分查找</li>\n<li>数据有冗余，有未分配空间，有已删除空间。所以数据主键要保递增，减少碎片化。</li>\n</ul>\n<h3 id=\"页page\"><a class=\"markdownIt-Anchor\" href=\"#页page\"></a> 页(Page)</h3>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210730224756.png\" alt=\"image-20210730224756023\" style=\"zoom:40%;\" />\n<ul>\n<li>默认1页为16kb</li>\n<li>页头，本页基本信息</li>\n<li>虚记录，本页最小主键，本页最大主键。</li>\n<li>【行】记录堆，行记录存储区，分为有效记录和已删除记录</li>\n<li>未分配空间，页中未使用的空间</li>\n<li>页尾，占8字节，主键存页面的校验信息</li>\n</ul>\n<h2 id=\"mysql-innodb-内存管理\"><a class=\"markdownIt-Anchor\" href=\"#mysql-innodb-内存管理\"></a> mysql innodb 内存管理</h2>\n<p>todo</p>\n<h2 id=\"mysql-innodb-事务实现原理\"><a class=\"markdownIt-Anchor\" href=\"#mysql-innodb-事务实现原理\"></a> mysql innodb 事务实现原理</h2>\n<h3 id=\"事务特性\"><a class=\"markdownIt-Anchor\" href=\"#事务特性\"></a> 事务特性：</h3>\n<ul>\n<li>A（atomicity 原子性）：全部成功，全部失败。不允许中间状态</li>\n<li>I （isolation 隔离性）：并行事务不干扰</li>\n<li>D（Durability 持久性）：提交事务后，数据不能丢</li>\n<li>C（consistency 一致性）：凑数的</li>\n</ul>\n<h3 id=\"并发问题\"><a class=\"markdownIt-Anchor\" href=\"#并发问题\"></a> 并发问题：</h3>\n<ul>\n<li>脏读（dirty read）： 读取到其他事务，没有提交的数据</li>\n<li>不可重复读（non-repeatable read）：查询同一条数据两次，有可能结果不一样</li>\n<li>幻读（phantom read）：select 出来的结果，可能是不存在的。<br>被其他事务插入后又删了，但中间存在期间，本事务恰好扫描到他了</li>\n</ul>\n<h3 id=\"隔离级别\"><a class=\"markdownIt-Anchor\" href=\"#隔离级别\"></a> 隔离级别：</h3>\n<ul>\n<li>\n<p>Read Uncommitted（读取未提交内容）: 最低隔离级别，会读取到其他事务未提交的数据，</p>\n<p>出现的问题：<strong>脏读</strong></p>\n</li>\n<li>\n<p>Read Committed（读取提交内容）: 事务过程中可以读取到其他事务已提交的数据，</p>\n<p>出现的问：<strong>不可重复读</strong></p>\n</li>\n<li>\n<p>Repeatable Read（可重复读）: 每次读取相同结果集，不管其他事务是否提交，</p>\n<p>出现的问题：<strong>幻读</strong></p>\n</li>\n<li>\n<p>Serializable （串行化）: 事务排队，隔离级别最高，性能最差;</p>\n<p>出现的问题：<strong>性能差</strong></p>\n</li>\n<li>\n<p>总结：</p>\n<ol>\n<li>一般使用 RR （可重复读），但写事务的时候，尽量避免 select 范围修改。<br>如果有范围修改，则思考一下，有没有可能出现幻读，如果出现了是否有影响。</li>\n<li>对于innodb，mvcc 并没有完全解决幻读问题。</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"innodb-mvcc\"><a class=\"markdownIt-Anchor\" href=\"#innodb-mvcc\"></a> innodb - mvcc</h2>\n<h3 id=\"两种查询模式\"><a class=\"markdownIt-Anchor\" href=\"#两种查询模式\"></a> 两种查询模式</h3>\n<ul>\n<li>当前读：永远查询某一行数据的最新的版本</li>\n<li>读快照：假设当前事务为A，根据事务A的 trx id（事务id）总能查到，A事务开启的那一刻， <br>数据的历史版本快照。这个快照是永远不会发生改变的。</li>\n</ul>\n<h3 id=\"可见性逻辑\"><a class=\"markdownIt-Anchor\" href=\"#可见性逻辑\"></a> 可见性逻辑</h3>\n<ul>\n<li>trx id 指的是事务id，是一个自增的序列。id 大，证明事务发生的时间靠后</li>\n<li>innodb 维护一个事务活跃列表，即 select * from information_schema.INNODB_TRX 查出来的数据。</li>\n<li>可见性逻辑：\n<ol>\n<li>事务开始的那一刻，查询所有当前事务。tmp_trx = [当前所有事务id]</li>\n<li>tmp_trx_max = [时间轴最靠后的事务]，tmp_trx_min = [时间轴最靠前的事务]</li>\n<li>搜索出来的数据，需要满足2个条件其中之一即可。\n<ul>\n<li>事务id，比tmp_trx_min 的id要小（查出来的记录，在事务创建之前，就提交了）</li>\n<li>不在事务活跃列表里面。（这个事务跑得快，已经先一步提交）</li>\n</ul>\n</li>\n<li>如果不满足，则通过历史版本指针，找到该行数据的历史快照，正常使用即可</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"mysql-锁实现原理\"><a class=\"markdownIt-Anchor\" href=\"#mysql-锁实现原理\"></a> mysql 锁实现原理</h2>\n<h3 id=\"需要加锁的语句\"><a class=\"markdownIt-Anchor\" href=\"#需要加锁的语句\"></a> <strong>需要加锁的语句</strong></h3>\n<p>select for update 、update、delete ，其他语句不用加锁。</p>\n<h3 id=\"分析锁的几个重要前提\"><a class=\"markdownIt-Anchor\" href=\"#分析锁的几个重要前提\"></a> <strong>分析锁的几个重要前提</strong></h3>\n<ul>\n<li>索引：唯一索引 、 非唯一索引</li>\n<li>事务隔离级别：RC 、 RR</li>\n</ul>\n<h3 id=\"根据颗粒度划分\"><a class=\"markdownIt-Anchor\" href=\"#根据颗粒度划分\"></a> <strong>根据颗粒度划分</strong></h3>\n<ul>\n<li>\n<p>行级，锁1行</p>\n<ul>\n<li>\n<p>RC下，唯一索引，非唯一索引，使用该级别锁。</p>\n<p>RR下，唯一索引，使用该级别</p>\n</li>\n<li>\n<p>作用在索引上</p>\n</li>\n<li>\n<p>聚簇索引 &amp; 二级索引</p>\n</li>\n</ul>\n</li>\n<li>\n<p>间隙，锁一部分</p>\n<ul>\n<li>\n<p>RR下，唯一索引，才使用这个锁类型</p>\n</li>\n<li>\n<p>索引是有序的，新的记录插入，只能插入到GAP区间内；<br>GAP锁，是计算出两条记录之间的GAP；<br>一旦锁住这个GAP。就封住了新纪录插入的可能性；<br>就能保证2次当前读返回的数据是一致的。</p>\n</li>\n<li>\n<p>GAP锁的问题：查询where条件没有索引的时候，没法加GAP锁，很容易锁升级为表锁。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>表级，锁1个表</p>\n<ul>\n<li><strong>没有命中索引的时候，有概率锁表，概率还不小。</strong></li>\n<li>所以，事务中，加锁的语句中的where条件一定要加索引。</li>\n<li>一般来说，分两个步骤实现修改\n<ol>\n<li>范围查询，返回主键id</li>\n<li>根据主键id list 进行 update。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"根据类型划分\"><a class=\"markdownIt-Anchor\" href=\"#根据类型划分\"></a> <strong>根据类型划分</strong></h3>\n<ul>\n<li>共享锁\n<ul>\n<li>读锁，可以被多个事务获取，阻止其他事务对记录的修改</li>\n</ul>\n</li>\n<li>排他锁\n<ul>\n<li>写锁，只能被1个事务获取，只允许获得锁的事务修改数据</li>\n</ul>\n</li>\n</ul>"},{"title":"mycat【6】一次mycat在线分库记录","toc":true,"hide":false,"sortn":60,"date":"2021-08-01T08:41:56.000Z","_content":"\n这是一次 使用mycat 不停机扩容的纪录片\n\n<!-- more -->\n\n------\n\n\n\n# 一次mycat在线分库记录\n\n\n\n## 分发服务分表方案\n\n\n\n### 目标：\n\n1. （核心目标）解决分发服务的数据库性能问题；\n\n2. （非核心目标） 输出相对通用的分库分表技术方案；\n\n3. （非核心目标） 了解学习本地技术架构与业务实现方案；\n\n   \n\n### 验收条件：\n\n1. （强约束） 控制表规模；\n2. （强） 整体稳定可靠，出问题可监控可排查；\n3. （弱） 方案及经验可推广到别的项目；\n\n\n\n### 下面有三个分表策略\n\n1. 根据日期（月份） 进行哈希，确定取模天数 tran_1  、trans_2 、 tran_3 等\n2. 根据近期时间范围，近n个月的在一张表里面， 其他的在另一个表里面。 trans_1(30天内数据),、trans_2(30天外的数据，1号冷库)、trans_2(30天外的数据，2号冷库)\n3. 按照日期进行枚举拆分，比如 trans_2019_01 、trans_2019_02 、trans_2019_01 等\n\n下面对比：\n\n| 对比项                           | 方案1                  | 方案2                                                        | 方案3                      |\n| -------------------------------- | ---------------------- | ------------------------------------------------------------ | -------------------------- |\n| 拆分逻辑                         | 日期取模（取模天数>2） | 近期、远期拆分<br>（热数据单独一个库，<br>冷数据进行日期范围分库） | 日期范围拆分               |\n| 数据平均程度                     | 平均                   | 不平均                                                       | 平均                       |\n| 冷热数据隔离性                   | 一般                   | 好                                                           | 好                         |\n| 清理热数据是否方便               | 不方便                 | 方便                                                         | 方便                       |\n| 清理冷数据是否方便               | 不方便                 | 方便                                                         | 方便                       |\n| 随着数据规模<br>后续是否需要扩容 | 需要                   | 几乎不需要                                                   | 不需要                     |\n| 优点                             | 通用套路               | 冷热数据分离性强，<br>在冷数据数据查询极少的情况下，<br>可以有效降低负载 | 隔离性强<br>               |\n| 缺点                             | 无法做到冷热数据分离   | 操作简单，维护容易<br>但要解决冷热数据的迁移问题             | 需要滚动建表，维护起来麻烦 |\n\n#### 方案选型总结：\n\n- 方案一：取模法，通用，简单。\n- 方案二：可以冷热分离，但需要解决数据迁移问题\n- 方案三：拆分粒度细，需要提前建表\n\n最终选择，取模法。\n\n\n\n#### 实施步骤记录：\n\n1. 分发服务，目前没有日期枚举字段，下一个迭代：\n\n   1. 需要加上日期的枚举字段。并修改 select 语句 ，update by id 的时候 加上 日期条件。（评估业务可行性）\n   2. 实现双写，单读 （读写trans，写trans_side）\n   3. 进行mycat 配置。\n   4. 开始数据拷贝作业，使用data-x 同步数据，将旧数据拷贝至新的两个子库。\n2. 迭代 app->app_v2，读写旧库，写新库。\n3. 观察mycat 写入双写数据的情况，尤其是看双写，是否会带来数据不一致，比如旧库成功，新库失败\n4. 迭代 mycat -> mycat_v3 ，将 trans_side，和trans 改名，app_v2的数据源就无需改变\n5. 观察读取情况，开是否有数据不一致产生\n6. 迭代app -> app_v3，此时将 trans_side 数据源的旁写逻辑去除即可。\n\n\n\n![步骤2，迭代app](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170823.png)\n\n![步骤4，迭代mycat](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170841.png)\n\n![步骤6，迭代app](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170851.png)\n","source":"_posts/mycat/mycat【6】一次mycat在线分库记录.md","raw":"---\ntitle: mycat【6】一次mycat在线分库记录\ntoc: true\ncategories:\n  - 数据库\n  - mycat \ntags:\n  - 中间件\n  - 分库分表\n  - mycat\nhide: false\nsortn: 60\ndate: 2021-08-01 16:41:56\n---\n\n这是一次 使用mycat 不停机扩容的纪录片\n\n<!-- more -->\n\n------\n\n\n\n# 一次mycat在线分库记录\n\n\n\n## 分发服务分表方案\n\n\n\n### 目标：\n\n1. （核心目标）解决分发服务的数据库性能问题；\n\n2. （非核心目标） 输出相对通用的分库分表技术方案；\n\n3. （非核心目标） 了解学习本地技术架构与业务实现方案；\n\n   \n\n### 验收条件：\n\n1. （强约束） 控制表规模；\n2. （强） 整体稳定可靠，出问题可监控可排查；\n3. （弱） 方案及经验可推广到别的项目；\n\n\n\n### 下面有三个分表策略\n\n1. 根据日期（月份） 进行哈希，确定取模天数 tran_1  、trans_2 、 tran_3 等\n2. 根据近期时间范围，近n个月的在一张表里面， 其他的在另一个表里面。 trans_1(30天内数据),、trans_2(30天外的数据，1号冷库)、trans_2(30天外的数据，2号冷库)\n3. 按照日期进行枚举拆分，比如 trans_2019_01 、trans_2019_02 、trans_2019_01 等\n\n下面对比：\n\n| 对比项                           | 方案1                  | 方案2                                                        | 方案3                      |\n| -------------------------------- | ---------------------- | ------------------------------------------------------------ | -------------------------- |\n| 拆分逻辑                         | 日期取模（取模天数>2） | 近期、远期拆分<br>（热数据单独一个库，<br>冷数据进行日期范围分库） | 日期范围拆分               |\n| 数据平均程度                     | 平均                   | 不平均                                                       | 平均                       |\n| 冷热数据隔离性                   | 一般                   | 好                                                           | 好                         |\n| 清理热数据是否方便               | 不方便                 | 方便                                                         | 方便                       |\n| 清理冷数据是否方便               | 不方便                 | 方便                                                         | 方便                       |\n| 随着数据规模<br>后续是否需要扩容 | 需要                   | 几乎不需要                                                   | 不需要                     |\n| 优点                             | 通用套路               | 冷热数据分离性强，<br>在冷数据数据查询极少的情况下，<br>可以有效降低负载 | 隔离性强<br>               |\n| 缺点                             | 无法做到冷热数据分离   | 操作简单，维护容易<br>但要解决冷热数据的迁移问题             | 需要滚动建表，维护起来麻烦 |\n\n#### 方案选型总结：\n\n- 方案一：取模法，通用，简单。\n- 方案二：可以冷热分离，但需要解决数据迁移问题\n- 方案三：拆分粒度细，需要提前建表\n\n最终选择，取模法。\n\n\n\n#### 实施步骤记录：\n\n1. 分发服务，目前没有日期枚举字段，下一个迭代：\n\n   1. 需要加上日期的枚举字段。并修改 select 语句 ，update by id 的时候 加上 日期条件。（评估业务可行性）\n   2. 实现双写，单读 （读写trans，写trans_side）\n   3. 进行mycat 配置。\n   4. 开始数据拷贝作业，使用data-x 同步数据，将旧数据拷贝至新的两个子库。\n2. 迭代 app->app_v2，读写旧库，写新库。\n3. 观察mycat 写入双写数据的情况，尤其是看双写，是否会带来数据不一致，比如旧库成功，新库失败\n4. 迭代 mycat -> mycat_v3 ，将 trans_side，和trans 改名，app_v2的数据源就无需改变\n5. 观察读取情况，开是否有数据不一致产生\n6. 迭代app -> app_v3，此时将 trans_side 数据源的旁写逻辑去除即可。\n\n\n\n![步骤2，迭代app](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170823.png)\n\n![步骤4，迭代mycat](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170841.png)\n\n![步骤6，迭代app](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170851.png)\n","slug":"mycat/mycat【6】一次mycat在线分库记录","published":1,"updated":"2021-08-01T08:41:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmo000bcpfy2ve0dvea","content":"<p>这是一次 使用mycat 不停机扩容的纪录片</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"一次mycat在线分库记录\"> 一次mycat在线分库记录</span></h1>\n<h2><span id=\"分发服务分表方案\"> 分发服务分表方案</span></h2>\n<h3><span id=\"目标\"> 目标：</span></h3>\n<ol>\n<li>\n<p>（核心目标）解决分发服务的数据库性能问题；</p>\n</li>\n<li>\n<p>（非核心目标） 输出相对通用的分库分表技术方案；</p>\n</li>\n<li>\n<p>（非核心目标） 了解学习本地技术架构与业务实现方案；</p>\n</li>\n</ol>\n<h3><span id=\"验收条件\"> 验收条件：</span></h3>\n<ol>\n<li>（强约束） 控制表规模；</li>\n<li>（强） 整体稳定可靠，出问题可监控可排查；</li>\n<li>（弱） 方案及经验可推广到别的项目；</li>\n</ol>\n<h3><span id=\"下面有三个分表策略\"> 下面有三个分表策略</span></h3>\n<ol>\n<li>根据日期（月份） 进行哈希，确定取模天数 tran_1  、trans_2 、 tran_3 等</li>\n<li>根据近期时间范围，近n个月的在一张表里面， 其他的在另一个表里面。 trans_1(30天内数据),、trans_2(30天外的数据，1号冷库)、trans_2(30天外的数据，2号冷库)</li>\n<li>按照日期进行枚举拆分，比如 trans_2019_01 、trans_2019_02 、trans_2019_01 等</li>\n</ol>\n<p>下面对比：</p>\n<table>\n<thead>\n<tr>\n<th>对比项</th>\n<th>方案1</th>\n<th>方案2</th>\n<th>方案3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>拆分逻辑</td>\n<td>日期取模（取模天数&gt;2）</td>\n<td>近期、远期拆分<br>（热数据单独一个库，<br>冷数据进行日期范围分库）</td>\n<td>日期范围拆分</td>\n</tr>\n<tr>\n<td>数据平均程度</td>\n<td>平均</td>\n<td>不平均</td>\n<td>平均</td>\n</tr>\n<tr>\n<td>冷热数据隔离性</td>\n<td>一般</td>\n<td>好</td>\n<td>好</td>\n</tr>\n<tr>\n<td>清理热数据是否方便</td>\n<td>不方便</td>\n<td>方便</td>\n<td>方便</td>\n</tr>\n<tr>\n<td>清理冷数据是否方便</td>\n<td>不方便</td>\n<td>方便</td>\n<td>方便</td>\n</tr>\n<tr>\n<td>随着数据规模<br>后续是否需要扩容</td>\n<td>需要</td>\n<td>几乎不需要</td>\n<td>不需要</td>\n</tr>\n<tr>\n<td>优点</td>\n<td>通用套路</td>\n<td>冷热数据分离性强，<br>在冷数据数据查询极少的情况下，<br>可以有效降低负载</td>\n<td>隔离性强<br></td>\n</tr>\n<tr>\n<td>缺点</td>\n<td>无法做到冷热数据分离</td>\n<td>操作简单，维护容易<br>但要解决冷热数据的迁移问题</td>\n<td>需要滚动建表，维护起来麻烦</td>\n</tr>\n</tbody>\n</table>\n<h4><span id=\"方案选型总结\"> 方案选型总结：</span></h4>\n<ul>\n<li>方案一：取模法，通用，简单。</li>\n<li>方案二：可以冷热分离，但需要解决数据迁移问题</li>\n<li>方案三：拆分粒度细，需要提前建表</li>\n</ul>\n<p>最终选择，取模法。</p>\n<h4><span id=\"实施步骤记录\"> 实施步骤记录：</span></h4>\n<ol>\n<li>\n<p>分发服务，目前没有日期枚举字段，下一个迭代：</p>\n<ol>\n<li>需要加上日期的枚举字段。并修改 select 语句 ，update by id 的时候 加上 日期条件。（评估业务可行性）</li>\n<li>实现双写，单读 （读写trans，写trans_side）</li>\n<li>进行mycat 配置。</li>\n<li>开始数据拷贝作业，使用data-x 同步数据，将旧数据拷贝至新的两个子库。</li>\n</ol>\n</li>\n<li>\n<p>迭代 app-&gt;app_v2，读写旧库，写新库。</p>\n</li>\n<li>\n<p>观察mycat 写入双写数据的情况，尤其是看双写，是否会带来数据不一致，比如旧库成功，新库失败</p>\n</li>\n<li>\n<p>迭代 mycat -&gt; mycat_v3 ，将 trans_side，和trans 改名，app_v2的数据源就无需改变</p>\n</li>\n<li>\n<p>观察读取情况，开是否有数据不一致产生</p>\n</li>\n<li>\n<p>迭代app -&gt; app_v3，此时将 trans_side 数据源的旁写逻辑去除即可。</p>\n</li>\n</ol>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170823.png\" alt=\"步骤2，迭代app\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170841.png\" alt=\"步骤4，迭代mycat\"></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170851.png\" alt=\"步骤6，迭代app\"></p>\n","site":{"data":{}},"excerpt":"<p>这是一次 使用mycat 不停机扩容的纪录片</p>","more":"<hr />\n<h1 id=\"一次mycat在线分库记录\"><a class=\"markdownIt-Anchor\" href=\"#一次mycat在线分库记录\"></a> 一次mycat在线分库记录</h1>\n<h2 id=\"分发服务分表方案\"><a class=\"markdownIt-Anchor\" href=\"#分发服务分表方案\"></a> 分发服务分表方案</h2>\n<h3 id=\"目标\"><a class=\"markdownIt-Anchor\" href=\"#目标\"></a> 目标：</h3>\n<ol>\n<li>\n<p>（核心目标）解决分发服务的数据库性能问题；</p>\n</li>\n<li>\n<p>（非核心目标） 输出相对通用的分库分表技术方案；</p>\n</li>\n<li>\n<p>（非核心目标） 了解学习本地技术架构与业务实现方案；</p>\n</li>\n</ol>\n<h3 id=\"验收条件\"><a class=\"markdownIt-Anchor\" href=\"#验收条件\"></a> 验收条件：</h3>\n<ol>\n<li>（强约束） 控制表规模；</li>\n<li>（强） 整体稳定可靠，出问题可监控可排查；</li>\n<li>（弱） 方案及经验可推广到别的项目；</li>\n</ol>\n<h3 id=\"下面有三个分表策略\"><a class=\"markdownIt-Anchor\" href=\"#下面有三个分表策略\"></a> 下面有三个分表策略</h3>\n<ol>\n<li>根据日期（月份） 进行哈希，确定取模天数 tran_1  、trans_2 、 tran_3 等</li>\n<li>根据近期时间范围，近n个月的在一张表里面， 其他的在另一个表里面。 trans_1(30天内数据),、trans_2(30天外的数据，1号冷库)、trans_2(30天外的数据，2号冷库)</li>\n<li>按照日期进行枚举拆分，比如 trans_2019_01 、trans_2019_02 、trans_2019_01 等</li>\n</ol>\n<p>下面对比：</p>\n<table>\n<thead>\n<tr>\n<th>对比项</th>\n<th>方案1</th>\n<th>方案2</th>\n<th>方案3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>拆分逻辑</td>\n<td>日期取模（取模天数&gt;2）</td>\n<td>近期、远期拆分<br>（热数据单独一个库，<br>冷数据进行日期范围分库）</td>\n<td>日期范围拆分</td>\n</tr>\n<tr>\n<td>数据平均程度</td>\n<td>平均</td>\n<td>不平均</td>\n<td>平均</td>\n</tr>\n<tr>\n<td>冷热数据隔离性</td>\n<td>一般</td>\n<td>好</td>\n<td>好</td>\n</tr>\n<tr>\n<td>清理热数据是否方便</td>\n<td>不方便</td>\n<td>方便</td>\n<td>方便</td>\n</tr>\n<tr>\n<td>清理冷数据是否方便</td>\n<td>不方便</td>\n<td>方便</td>\n<td>方便</td>\n</tr>\n<tr>\n<td>随着数据规模<br>后续是否需要扩容</td>\n<td>需要</td>\n<td>几乎不需要</td>\n<td>不需要</td>\n</tr>\n<tr>\n<td>优点</td>\n<td>通用套路</td>\n<td>冷热数据分离性强，<br>在冷数据数据查询极少的情况下，<br>可以有效降低负载</td>\n<td>隔离性强<br></td>\n</tr>\n<tr>\n<td>缺点</td>\n<td>无法做到冷热数据分离</td>\n<td>操作简单，维护容易<br>但要解决冷热数据的迁移问题</td>\n<td>需要滚动建表，维护起来麻烦</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"方案选型总结\"><a class=\"markdownIt-Anchor\" href=\"#方案选型总结\"></a> 方案选型总结：</h4>\n<ul>\n<li>方案一：取模法，通用，简单。</li>\n<li>方案二：可以冷热分离，但需要解决数据迁移问题</li>\n<li>方案三：拆分粒度细，需要提前建表</li>\n</ul>\n<p>最终选择，取模法。</p>\n<h4 id=\"实施步骤记录\"><a class=\"markdownIt-Anchor\" href=\"#实施步骤记录\"></a> 实施步骤记录：</h4>\n<ol>\n<li>\n<p>分发服务，目前没有日期枚举字段，下一个迭代：</p>\n<ol>\n<li>需要加上日期的枚举字段。并修改 select 语句 ，update by id 的时候 加上 日期条件。（评估业务可行性）</li>\n<li>实现双写，单读 （读写trans，写trans_side）</li>\n<li>进行mycat 配置。</li>\n<li>开始数据拷贝作业，使用data-x 同步数据，将旧数据拷贝至新的两个子库。</li>\n</ol>\n</li>\n<li>\n<p>迭代 app-&gt;app_v2，读写旧库，写新库。</p>\n</li>\n<li>\n<p>观察mycat 写入双写数据的情况，尤其是看双写，是否会带来数据不一致，比如旧库成功，新库失败</p>\n</li>\n<li>\n<p>迭代 mycat -&gt; mycat_v3 ，将 trans_side，和trans 改名，app_v2的数据源就无需改变</p>\n</li>\n<li>\n<p>观察读取情况，开是否有数据不一致产生</p>\n</li>\n<li>\n<p>迭代app -&gt; app_v3，此时将 trans_side 数据源的旁写逻辑去除即可。</p>\n</li>\n</ol>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170823.png\" alt=\"步骤2，迭代app\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170841.png\" alt=\"步骤4，迭代mycat\" /></p>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801170851.png\" alt=\"步骤6，迭代app\" /></p>"},{"title":"innodb索引优化","toc":true,"hide":false,"date":"2021-07-31T06:34:09.000Z","sortn":20,"_content":"\n本章主要介绍 innodb 引擎的大量数据索引优化\n\n<!-- more -->\n\n------\n\n\n\n## 索引原理\n\n\n\n### 聚簇索引\n\n![img](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png)\n\n- 数据存储在主键索引中 \n- 数据按主键顺序存储\n\n\n\n### 二级索引\n\n![image-20210731151934246](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731151934.png)\n\n- 除了主键索引以外的所有，都是二级索引\n\n- 叶子中，存的是主键的值\n\n- 一次查询，需要经过2次的查询操作，2logN 复杂度。\n\n- 主键的大小，会影响索引的大小。\n\n- 对于叶子节点，存【主键值】，还是存【数据地址】的取舍：\n\n  innodb可能需要回表查询，即在聚簇索引中进一步查找对应的数据行。这样可以避免在行移动或者插入新数据时出现的页分裂问题。\n\n  MyISAM中无论是主键索引还是二级索引，索引的叶子节点存放的都是指向数据行的指针，保证可以通过索引进而查找到对应的数据行，只需要对索引进行一遍查找。但这样会存在页分裂问题。\n\n  \n\n### 联合索引\n\n![image-20210731153830652](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731153830.png)\n\n- 一个索引只创造1课树\n- 假设有2列，就把量列拼接起来，(A:B) 形成一个长的组合索引\n- 先通过A查找，找到后再通过B查找\n- **总结：**\n  - 如果不是按照最左开始查找，则无法使用索引，比如本例无法直接通过B查找\n  - 如果是范围查找，则后面的列，无法使用索引。\n\n\n\n## 索引优化分析\n\n\n\n### 存储空间 （数据量与B+树的层高关系）\n\n- 每个 page 都有一个 level，leaf page 的 level 是 0，root page 的 level 取决于整个 B+Tree 的高度。\n- 因为页存储有 「空洞」 现象，所以不是非常固定的\n- 一般来说 当数据为理论值的 2/3 时， 树就开始加一层了。\n\n已知：\n\n- Int 类型主键，每页可以存 1203 个子节点指针。\n\n- bigint 类型主键，每页可以存 900 个子节点指针。\n\n- 对于最下面一层的叶子节点：\n\n  - 单行数据为 n byte ，每个page存 (16000  / n ) 条记录<br> 假如 1 行数据 300 byte，每个page 存 (16000  / n = 50）行数据。\n\n  \n\n**层高计算公式 ：**\n\n**总行数 = （每页指针数） ^（几层）* 每页行数** \n\n\n\n当主键为 int (4 byte) 类型时，极限值为\n\n| 高度     | 多少个<br/>索引页<br/>（非叶子） | 多少个<br/>数据页<br/>（叶子） | 每页能存<br>几个记录 | 得到的行数 | 数据大小大小 |\n| -------- | -------------------------------- | ------------------------------ | -------------------- | ---------- | ------------ |\n| 1（0+1） | 0                                | 1                              | 50                   | 50         | 16k          |\n| 2（1+1） | 1                                | 1203                           | 50                   | 6万        | 18MB         |\n| 3（2+1） | 1204                             | 1,447,209                      | 50                   | 7亿        | 22G          |\n| 4（3+1） | 1,447,209                        | 17亿                           | 50                   | 850亿      | 25T          |\n\n\n\n当主键为 bigint (8 byte) 类型时，极限值为\n\n| 高度     | 多少个<br/>索引页<br/>（非叶子） | 多少个<br/>数据页<br/>（叶子） | 每页能存<br/>几个记录 | 得到的行数 | 数据大小大小 |\n| -------- | -------------------------------- | ------------------------------ | --------------------- | ---------- | ------------ |\n| 1（0+1） | 0                                | 1                              | 50                    | 50         | 16k          |\n| 2（1+1） | 1                                | 928                            | 50                    | 46400      | 18MB         |\n| 3（2+1） | 928                              | 861,184                        | 50                    | 4000万     | 22G          |\n| 4（3+1） | 861,184                          | 8亿                            | 50                    | 40亿       | 25T          |\n\n参考：https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/\n\n\n\n### 主键选择\n\n\n\n- 自增主键\n\n  - 顺序写入，效率高\n  - 每次查询都走2级索引\n\n- 随机主键\n\n  - 节点分裂，数据移动，效率比较低\n  - 有可能查询走2级索引\n\n- 业务主键，比如订单号，用户id，商品id，等\n\n  - 需要保证值是递增，一般情况下使用雪花算法即可\n  - 写入，查询磁盘利用率都高，可以使用一级索引\n\n- 联合主键\n\n  - 影响索引列大小，不容易维护，不建议使用\n\n  \n\n### 联合索引使用\n\n\n\n- 按索引区分度排序，区分度越高的放在前面。<br>比如主键，时间，外键，手机号，身份证号等。<br>索引区分度低的有，类型，状态等\n- 覆盖索引，我们要查询的数据，正好在索引中，那么就不用回表了<br>比如一个索引 （id,phone,addr），在执行 `select phone，addr from user where id = 8;` 时<br>可以不用回表，直接返回结果集，又称三星索引。 \n- 索引下推，mysql 5.6推出的性能改进，减少回表的次数，本该如此，不必细聊。\n\n\n\n### 索引避坑指南\n\n\n\n- 设置合理的长度\n\n  - 前10个字符建索引就行，如果前10个字符都体现不出区分度，那么这个数据本身也有点问题<br>\n\n  - 解决方案，对于区分度不大的列，再建立一个 hash 值列，通过索引（hash(addr),addr）查找就快了\n\n    \n\n- 索引失效的情况\n\n  - A = XX or B=xx 索引会失效么？<br>不会失效，<br> mysql 5.1 引入了Index merge 技术，已经可以同时对 1个表使用多个索引分别扫描，1次出结果\n\n    \n\n  - 在联合索引中使用第二列，比如（phone，id_card_num）<br>使用`select * from user where id_card_num= 3701xxxxxx` 就不走索引\n\n  \n\n  - 隐式类型转换，不走索引<br>\n\n    ```mysql\n    -- type moblie Long\n    -- 就不走索引\n    select * from user where moblie= '186123232222'\n    ```\n\n    类型转换的时候，不使用索引。<br>上线前跑一遍查询计划，看看有没有这事，这个事很容易发生，但不容易发现。\n\n    \n\n  -  索引列包含计算，不走索引\n\n    ```mysql\n    select * from user where age-20 = 30;\n    -- 没有人会这么干，如果有人这么干，必须请大家吃饭\n    ```\n\n    \n\n  - 索引区分度低，有时候也不走索引<br>当索引的区分度过低，比如 sex ，if_old , sell_status 列，使用sql语句<br>`select * from user where sex=1 and phone=18678922342`<br>通过 sex 索引查询，要频繁的回表，这时候使用索引查询，还不如直接使用全表扫描更快。<br>\n\n    \n\n  - 查询条件，覆盖所有的索引值。也不会走本列索引<br>比如，有个 age 字段，使用sql语句，`select * from user where age < 200`<br>的时候，因为查询语句中的条件已经全部覆盖了整个数据集。<br>所以mysql也不会使用该索引。\n\n\n\n### column类型最佳实践\n\n- 数据库字符集使用 utf8mb4\n- VARCHAR 按实际需要分配长度 ，255以上，需要更多的而空间描述长度，浪费空间\n- 文本字段建议使用 VARCHAR\n- 时间 字段使用 long，兼容性好，要不然迁移的时候，time类型有时区概念，容易出现bug\n- bool字段使用tinyint\n- 枚举字段建议使用 tinyint\n- 交易金额 建议使用 long，存成分已足够，￥1.01存成 101\n- 禁止使用 “%” 前导的查询\n- 禁止在索引列进行数学运算，会导致索引失效\n\n\n\n### 索引类型最佳实践\n\n- 表必须有主键，建议使用业务主键，使用雪花算法保证自增。\n- 单张表中索引数量不超过5个\n- 单个索引字段数不超过5个\n- 字符串索引使用前缀索引，前缀长度不超过10个字符\n\n\n\n","source":"_posts/mysql/innodb索引优化.md","raw":"---\ntitle: 'innodb索引优化'\ntoc: true\ncategories:\n  - 数据库\n  - mysql\ntags:\n  - innodb\nhide: false\ndate: 2021-07-31 14:34:09\nsortn: 20\n---\n\n本章主要介绍 innodb 引擎的大量数据索引优化\n\n<!-- more -->\n\n------\n\n\n\n## 索引原理\n\n\n\n### 聚簇索引\n\n![img](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png)\n\n- 数据存储在主键索引中 \n- 数据按主键顺序存储\n\n\n\n### 二级索引\n\n![image-20210731151934246](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731151934.png)\n\n- 除了主键索引以外的所有，都是二级索引\n\n- 叶子中，存的是主键的值\n\n- 一次查询，需要经过2次的查询操作，2logN 复杂度。\n\n- 主键的大小，会影响索引的大小。\n\n- 对于叶子节点，存【主键值】，还是存【数据地址】的取舍：\n\n  innodb可能需要回表查询，即在聚簇索引中进一步查找对应的数据行。这样可以避免在行移动或者插入新数据时出现的页分裂问题。\n\n  MyISAM中无论是主键索引还是二级索引，索引的叶子节点存放的都是指向数据行的指针，保证可以通过索引进而查找到对应的数据行，只需要对索引进行一遍查找。但这样会存在页分裂问题。\n\n  \n\n### 联合索引\n\n![image-20210731153830652](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731153830.png)\n\n- 一个索引只创造1课树\n- 假设有2列，就把量列拼接起来，(A:B) 形成一个长的组合索引\n- 先通过A查找，找到后再通过B查找\n- **总结：**\n  - 如果不是按照最左开始查找，则无法使用索引，比如本例无法直接通过B查找\n  - 如果是范围查找，则后面的列，无法使用索引。\n\n\n\n## 索引优化分析\n\n\n\n### 存储空间 （数据量与B+树的层高关系）\n\n- 每个 page 都有一个 level，leaf page 的 level 是 0，root page 的 level 取决于整个 B+Tree 的高度。\n- 因为页存储有 「空洞」 现象，所以不是非常固定的\n- 一般来说 当数据为理论值的 2/3 时， 树就开始加一层了。\n\n已知：\n\n- Int 类型主键，每页可以存 1203 个子节点指针。\n\n- bigint 类型主键，每页可以存 900 个子节点指针。\n\n- 对于最下面一层的叶子节点：\n\n  - 单行数据为 n byte ，每个page存 (16000  / n ) 条记录<br> 假如 1 行数据 300 byte，每个page 存 (16000  / n = 50）行数据。\n\n  \n\n**层高计算公式 ：**\n\n**总行数 = （每页指针数） ^（几层）* 每页行数** \n\n\n\n当主键为 int (4 byte) 类型时，极限值为\n\n| 高度     | 多少个<br/>索引页<br/>（非叶子） | 多少个<br/>数据页<br/>（叶子） | 每页能存<br>几个记录 | 得到的行数 | 数据大小大小 |\n| -------- | -------------------------------- | ------------------------------ | -------------------- | ---------- | ------------ |\n| 1（0+1） | 0                                | 1                              | 50                   | 50         | 16k          |\n| 2（1+1） | 1                                | 1203                           | 50                   | 6万        | 18MB         |\n| 3（2+1） | 1204                             | 1,447,209                      | 50                   | 7亿        | 22G          |\n| 4（3+1） | 1,447,209                        | 17亿                           | 50                   | 850亿      | 25T          |\n\n\n\n当主键为 bigint (8 byte) 类型时，极限值为\n\n| 高度     | 多少个<br/>索引页<br/>（非叶子） | 多少个<br/>数据页<br/>（叶子） | 每页能存<br/>几个记录 | 得到的行数 | 数据大小大小 |\n| -------- | -------------------------------- | ------------------------------ | --------------------- | ---------- | ------------ |\n| 1（0+1） | 0                                | 1                              | 50                    | 50         | 16k          |\n| 2（1+1） | 1                                | 928                            | 50                    | 46400      | 18MB         |\n| 3（2+1） | 928                              | 861,184                        | 50                    | 4000万     | 22G          |\n| 4（3+1） | 861,184                          | 8亿                            | 50                    | 40亿       | 25T          |\n\n参考：https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/\n\n\n\n### 主键选择\n\n\n\n- 自增主键\n\n  - 顺序写入，效率高\n  - 每次查询都走2级索引\n\n- 随机主键\n\n  - 节点分裂，数据移动，效率比较低\n  - 有可能查询走2级索引\n\n- 业务主键，比如订单号，用户id，商品id，等\n\n  - 需要保证值是递增，一般情况下使用雪花算法即可\n  - 写入，查询磁盘利用率都高，可以使用一级索引\n\n- 联合主键\n\n  - 影响索引列大小，不容易维护，不建议使用\n\n  \n\n### 联合索引使用\n\n\n\n- 按索引区分度排序，区分度越高的放在前面。<br>比如主键，时间，外键，手机号，身份证号等。<br>索引区分度低的有，类型，状态等\n- 覆盖索引，我们要查询的数据，正好在索引中，那么就不用回表了<br>比如一个索引 （id,phone,addr），在执行 `select phone，addr from user where id = 8;` 时<br>可以不用回表，直接返回结果集，又称三星索引。 \n- 索引下推，mysql 5.6推出的性能改进，减少回表的次数，本该如此，不必细聊。\n\n\n\n### 索引避坑指南\n\n\n\n- 设置合理的长度\n\n  - 前10个字符建索引就行，如果前10个字符都体现不出区分度，那么这个数据本身也有点问题<br>\n\n  - 解决方案，对于区分度不大的列，再建立一个 hash 值列，通过索引（hash(addr),addr）查找就快了\n\n    \n\n- 索引失效的情况\n\n  - A = XX or B=xx 索引会失效么？<br>不会失效，<br> mysql 5.1 引入了Index merge 技术，已经可以同时对 1个表使用多个索引分别扫描，1次出结果\n\n    \n\n  - 在联合索引中使用第二列，比如（phone，id_card_num）<br>使用`select * from user where id_card_num= 3701xxxxxx` 就不走索引\n\n  \n\n  - 隐式类型转换，不走索引<br>\n\n    ```mysql\n    -- type moblie Long\n    -- 就不走索引\n    select * from user where moblie= '186123232222'\n    ```\n\n    类型转换的时候，不使用索引。<br>上线前跑一遍查询计划，看看有没有这事，这个事很容易发生，但不容易发现。\n\n    \n\n  -  索引列包含计算，不走索引\n\n    ```mysql\n    select * from user where age-20 = 30;\n    -- 没有人会这么干，如果有人这么干，必须请大家吃饭\n    ```\n\n    \n\n  - 索引区分度低，有时候也不走索引<br>当索引的区分度过低，比如 sex ，if_old , sell_status 列，使用sql语句<br>`select * from user where sex=1 and phone=18678922342`<br>通过 sex 索引查询，要频繁的回表，这时候使用索引查询，还不如直接使用全表扫描更快。<br>\n\n    \n\n  - 查询条件，覆盖所有的索引值。也不会走本列索引<br>比如，有个 age 字段，使用sql语句，`select * from user where age < 200`<br>的时候，因为查询语句中的条件已经全部覆盖了整个数据集。<br>所以mysql也不会使用该索引。\n\n\n\n### column类型最佳实践\n\n- 数据库字符集使用 utf8mb4\n- VARCHAR 按实际需要分配长度 ，255以上，需要更多的而空间描述长度，浪费空间\n- 文本字段建议使用 VARCHAR\n- 时间 字段使用 long，兼容性好，要不然迁移的时候，time类型有时区概念，容易出现bug\n- bool字段使用tinyint\n- 枚举字段建议使用 tinyint\n- 交易金额 建议使用 long，存成分已足够，￥1.01存成 101\n- 禁止使用 “%” 前导的查询\n- 禁止在索引列进行数学运算，会导致索引失效\n\n\n\n### 索引类型最佳实践\n\n- 表必须有主键，建议使用业务主键，使用雪花算法保证自增。\n- 单张表中索引数量不超过5个\n- 单个索引字段数不超过5个\n- 字符串索引使用前缀索引，前缀长度不超过10个字符\n\n\n\n","slug":"mysql/innodb索引优化","published":1,"updated":"2021-07-31T06:34:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmp000ecpfy3so7dcxv","content":"<p>本章主要介绍 innodb 引擎的大量数据索引优化</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"索引原理\"> 索引原理</span></h2>\n<h3><span id=\"聚簇索引\"> 聚簇索引</span></h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png\" alt=\"img\"></p>\n<ul>\n<li>数据存储在主键索引中</li>\n<li>数据按主键顺序存储</li>\n</ul>\n<h3><span id=\"二级索引\"> 二级索引</span></h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731151934.png\" alt=\"image-20210731151934246\"></p>\n<ul>\n<li>\n<p>除了主键索引以外的所有，都是二级索引</p>\n</li>\n<li>\n<p>叶子中，存的是主键的值</p>\n</li>\n<li>\n<p>一次查询，需要经过2次的查询操作，2logN 复杂度。</p>\n</li>\n<li>\n<p>主键的大小，会影响索引的大小。</p>\n</li>\n<li>\n<p>对于叶子节点，存【主键值】，还是存【数据地址】的取舍：</p>\n<p>innodb可能需要回表查询，即在聚簇索引中进一步查找对应的数据行。这样可以避免在行移动或者插入新数据时出现的页分裂问题。</p>\n<p>MyISAM中无论是主键索引还是二级索引，索引的叶子节点存放的都是指向数据行的指针，保证可以通过索引进而查找到对应的数据行，只需要对索引进行一遍查找。但这样会存在页分裂问题。</p>\n</li>\n</ul>\n<h3><span id=\"联合索引\"> 联合索引</span></h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731153830.png\" alt=\"image-20210731153830652\"></p>\n<ul>\n<li>一个索引只创造1课树</li>\n<li>假设有2列，就把量列拼接起来，(A:B) 形成一个长的组合索引</li>\n<li>先通过A查找，找到后再通过B查找</li>\n<li><strong>总结：</strong>\n<ul>\n<li>如果不是按照最左开始查找，则无法使用索引，比如本例无法直接通过B查找</li>\n<li>如果是范围查找，则后面的列，无法使用索引。</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"索引优化分析\"> 索引优化分析</span></h2>\n<h3><span id=\"存储空间-数据量与b树的层高关系\"> 存储空间 （数据量与B+树的层高关系）</span></h3>\n<ul>\n<li>每个 page 都有一个 level，leaf page 的 level 是 0，root page 的 level 取决于整个 B+Tree 的高度。</li>\n<li>因为页存储有 「空洞」 现象，所以不是非常固定的</li>\n<li>一般来说 当数据为理论值的 2/3 时， 树就开始加一层了。</li>\n</ul>\n<p>已知：</p>\n<ul>\n<li>\n<p>Int 类型主键，每页可以存 1203 个子节点指针。</p>\n</li>\n<li>\n<p>bigint 类型主键，每页可以存 900 个子节点指针。</p>\n</li>\n<li>\n<p>对于最下面一层的叶子节点：</p>\n<ul>\n<li>单行数据为 n byte ，每个page存 (16000  / n ) 条记录<br> 假如 1 行数据 300 byte，每个page 存 (16000  / n = 50）行数据。</li>\n</ul>\n</li>\n</ul>\n<p><strong>层高计算公式 ：</strong></p>\n<p><em><em>总行数 = （每页指针数） ^（几层）</em> 每页行数</em>*</p>\n<p>当主键为 int (4 byte) 类型时，极限值为</p>\n<table>\n<thead>\n<tr>\n<th>高度</th>\n<th>多少个<br>索引页<br>（非叶子）</th>\n<th>多少个<br>数据页<br>（叶子）</th>\n<th>每页能存<br>几个记录</th>\n<th>得到的行数</th>\n<th>数据大小大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1（0+1）</td>\n<td>0</td>\n<td>1</td>\n<td>50</td>\n<td>50</td>\n<td>16k</td>\n</tr>\n<tr>\n<td>2（1+1）</td>\n<td>1</td>\n<td>1203</td>\n<td>50</td>\n<td>6万</td>\n<td>18MB</td>\n</tr>\n<tr>\n<td>3（2+1）</td>\n<td>1204</td>\n<td>1,447,209</td>\n<td>50</td>\n<td>7亿</td>\n<td>22G</td>\n</tr>\n<tr>\n<td>4（3+1）</td>\n<td>1,447,209</td>\n<td>17亿</td>\n<td>50</td>\n<td>850亿</td>\n<td>25T</td>\n</tr>\n</tbody>\n</table>\n<p>当主键为 bigint (8 byte) 类型时，极限值为</p>\n<table>\n<thead>\n<tr>\n<th>高度</th>\n<th>多少个<br>索引页<br>（非叶子）</th>\n<th>多少个<br>数据页<br>（叶子）</th>\n<th>每页能存<br>几个记录</th>\n<th>得到的行数</th>\n<th>数据大小大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1（0+1）</td>\n<td>0</td>\n<td>1</td>\n<td>50</td>\n<td>50</td>\n<td>16k</td>\n</tr>\n<tr>\n<td>2（1+1）</td>\n<td>1</td>\n<td>928</td>\n<td>50</td>\n<td>46400</td>\n<td>18MB</td>\n</tr>\n<tr>\n<td>3（2+1）</td>\n<td>928</td>\n<td>861,184</td>\n<td>50</td>\n<td>4000万</td>\n<td>22G</td>\n</tr>\n<tr>\n<td>4（3+1）</td>\n<td>861,184</td>\n<td>8亿</td>\n<td>50</td>\n<td>40亿</td>\n<td>25T</td>\n</tr>\n</tbody>\n</table>\n<p>参考：<a href=\"https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/\">https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/</a></p>\n<h3><span id=\"主键选择\"> 主键选择</span></h3>\n<ul>\n<li>\n<p>自增主键</p>\n<ul>\n<li>顺序写入，效率高</li>\n<li>每次查询都走2级索引</li>\n</ul>\n</li>\n<li>\n<p>随机主键</p>\n<ul>\n<li>节点分裂，数据移动，效率比较低</li>\n<li>有可能查询走2级索引</li>\n</ul>\n</li>\n<li>\n<p>业务主键，比如订单号，用户id，商品id，等</p>\n<ul>\n<li>需要保证值是递增，一般情况下使用雪花算法即可</li>\n<li>写入，查询磁盘利用率都高，可以使用一级索引</li>\n</ul>\n</li>\n<li>\n<p>联合主键</p>\n<ul>\n<li>影响索引列大小，不容易维护，不建议使用</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"联合索引使用\"> 联合索引使用</span></h3>\n<ul>\n<li>按索引区分度排序，区分度越高的放在前面。<br>比如主键，时间，外键，手机号，身份证号等。<br>索引区分度低的有，类型，状态等</li>\n<li>覆盖索引，我们要查询的数据，正好在索引中，那么就不用回表了<br>比如一个索引 （id,phone,addr），在执行 <code>select phone，addr from user where id = 8;</code> 时<br>可以不用回表，直接返回结果集，又称三星索引。</li>\n<li>索引下推，mysql 5.6推出的性能改进，减少回表的次数，本该如此，不必细聊。</li>\n</ul>\n<h3><span id=\"索引避坑指南\"> 索引避坑指南</span></h3>\n<ul>\n<li>\n<p>设置合理的长度</p>\n<ul>\n<li>\n<p>前10个字符建索引就行，如果前10个字符都体现不出区分度，那么这个数据本身也有点问题<br></p>\n</li>\n<li>\n<p>解决方案，对于区分度不大的列，再建立一个 hash 值列，通过索引（hash(addr),addr）查找就快了</p>\n</li>\n</ul>\n</li>\n<li>\n<p>索引失效的情况</p>\n<ul>\n<li>\n<p>A = XX or B=xx 索引会失效么？<br>不会失效，<br> mysql 5.1 引入了Index merge 技术，已经可以同时对 1个表使用多个索引分别扫描，1次出结果</p>\n</li>\n<li>\n<p>在联合索引中使用第二列，比如（phone，id_card_num）<br>使用<code>select * from user where id_card_num= 3701xxxxxx</code> 就不走索引</p>\n</li>\n<li>\n<p>隐式类型转换，不走索引<br></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs mysql\">-- type moblie Long<br>-- 就不走索引<br>select * from user where moblie= &#x27;186123232222&#x27;<br></code></pre></div></td></tr></table></figure>\n<p>类型转换的时候，不使用索引。<br>上线前跑一遍查询计划，看看有没有这事，这个事很容易发生，但不容易发现。</p>\n</li>\n<li>\n<p>索引列包含计算，不走索引</p>\n</li>\n</ul>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs mysql\">select * from user where age-20 = 30;<br>-- 没有人会这么干，如果有人这么干，必须请大家吃饭<br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>\n<p>索引区分度低，有时候也不走索引<br>当索引的区分度过低，比如 sex ，if_old , sell_status 列，使用sql语句<br><code>select * from user where sex=1 and phone=18678922342</code><br>通过 sex 索引查询，要频繁的回表，这时候使用索引查询，还不如直接使用全表扫描更快。<br></p>\n</li>\n<li>\n<p>查询条件，覆盖所有的索引值。也不会走本列索引<br>比如，有个 age 字段，使用sql语句，<code>select * from user where age &lt; 200</code><br>的时候，因为查询语句中的条件已经全部覆盖了整个数据集。<br>所以mysql也不会使用该索引。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"column类型最佳实践\"> column类型最佳实践</span></h3>\n<ul>\n<li>数据库字符集使用 utf8mb4</li>\n<li>VARCHAR 按实际需要分配长度 ，255以上，需要更多的而空间描述长度，浪费空间</li>\n<li>文本字段建议使用 VARCHAR</li>\n<li>时间 字段使用 long，兼容性好，要不然迁移的时候，time类型有时区概念，容易出现bug</li>\n<li>bool字段使用tinyint</li>\n<li>枚举字段建议使用 tinyint</li>\n<li>交易金额 建议使用 long，存成分已足够，￥1.01存成 101</li>\n<li>禁止使用 “%” 前导的查询</li>\n<li>禁止在索引列进行数学运算，会导致索引失效</li>\n</ul>\n<h3><span id=\"索引类型最佳实践\"> 索引类型最佳实践</span></h3>\n<ul>\n<li>表必须有主键，建议使用业务主键，使用雪花算法保证自增。</li>\n<li>单张表中索引数量不超过5个</li>\n<li>单个索引字段数不超过5个</li>\n<li>字符串索引使用前缀索引，前缀长度不超过10个字符</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本章主要介绍 innodb 引擎的大量数据索引优化</p>","more":"<hr />\n<h2 id=\"索引原理\"><a class=\"markdownIt-Anchor\" href=\"#索引原理\"></a> 索引原理</h2>\n<h3 id=\"聚簇索引\"><a class=\"markdownIt-Anchor\" href=\"#聚簇索引\"></a> 聚簇索引</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731010412.png\" alt=\"img\" /></p>\n<ul>\n<li>数据存储在主键索引中</li>\n<li>数据按主键顺序存储</li>\n</ul>\n<h3 id=\"二级索引\"><a class=\"markdownIt-Anchor\" href=\"#二级索引\"></a> 二级索引</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731151934.png\" alt=\"image-20210731151934246\" /></p>\n<ul>\n<li>\n<p>除了主键索引以外的所有，都是二级索引</p>\n</li>\n<li>\n<p>叶子中，存的是主键的值</p>\n</li>\n<li>\n<p>一次查询，需要经过2次的查询操作，2logN 复杂度。</p>\n</li>\n<li>\n<p>主键的大小，会影响索引的大小。</p>\n</li>\n<li>\n<p>对于叶子节点，存【主键值】，还是存【数据地址】的取舍：</p>\n<p>innodb可能需要回表查询，即在聚簇索引中进一步查找对应的数据行。这样可以避免在行移动或者插入新数据时出现的页分裂问题。</p>\n<p>MyISAM中无论是主键索引还是二级索引，索引的叶子节点存放的都是指向数据行的指针，保证可以通过索引进而查找到对应的数据行，只需要对索引进行一遍查找。但这样会存在页分裂问题。</p>\n</li>\n</ul>\n<h3 id=\"联合索引\"><a class=\"markdownIt-Anchor\" href=\"#联合索引\"></a> 联合索引</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731153830.png\" alt=\"image-20210731153830652\" /></p>\n<ul>\n<li>一个索引只创造1课树</li>\n<li>假设有2列，就把量列拼接起来，(A:B) 形成一个长的组合索引</li>\n<li>先通过A查找，找到后再通过B查找</li>\n<li><strong>总结：</strong>\n<ul>\n<li>如果不是按照最左开始查找，则无法使用索引，比如本例无法直接通过B查找</li>\n<li>如果是范围查找，则后面的列，无法使用索引。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"索引优化分析\"><a class=\"markdownIt-Anchor\" href=\"#索引优化分析\"></a> 索引优化分析</h2>\n<h3 id=\"存储空间-数据量与b树的层高关系\"><a class=\"markdownIt-Anchor\" href=\"#存储空间-数据量与b树的层高关系\"></a> 存储空间 （数据量与B+树的层高关系）</h3>\n<ul>\n<li>每个 page 都有一个 level，leaf page 的 level 是 0，root page 的 level 取决于整个 B+Tree 的高度。</li>\n<li>因为页存储有 「空洞」 现象，所以不是非常固定的</li>\n<li>一般来说 当数据为理论值的 2/3 时， 树就开始加一层了。</li>\n</ul>\n<p>已知：</p>\n<ul>\n<li>\n<p>Int 类型主键，每页可以存 1203 个子节点指针。</p>\n</li>\n<li>\n<p>bigint 类型主键，每页可以存 900 个子节点指针。</p>\n</li>\n<li>\n<p>对于最下面一层的叶子节点：</p>\n<ul>\n<li>单行数据为 n byte ，每个page存 (16000  / n ) 条记录<br> 假如 1 行数据 300 byte，每个page 存 (16000  / n = 50）行数据。</li>\n</ul>\n</li>\n</ul>\n<p><strong>层高计算公式 ：</strong></p>\n<p><em><em>总行数 = （每页指针数） ^（几层）</em> 每页行数</em>*</p>\n<p>当主键为 int (4 byte) 类型时，极限值为</p>\n<table>\n<thead>\n<tr>\n<th>高度</th>\n<th>多少个<br/>索引页<br/>（非叶子）</th>\n<th>多少个<br/>数据页<br/>（叶子）</th>\n<th>每页能存<br>几个记录</th>\n<th>得到的行数</th>\n<th>数据大小大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1（0+1）</td>\n<td>0</td>\n<td>1</td>\n<td>50</td>\n<td>50</td>\n<td>16k</td>\n</tr>\n<tr>\n<td>2（1+1）</td>\n<td>1</td>\n<td>1203</td>\n<td>50</td>\n<td>6万</td>\n<td>18MB</td>\n</tr>\n<tr>\n<td>3（2+1）</td>\n<td>1204</td>\n<td>1,447,209</td>\n<td>50</td>\n<td>7亿</td>\n<td>22G</td>\n</tr>\n<tr>\n<td>4（3+1）</td>\n<td>1,447,209</td>\n<td>17亿</td>\n<td>50</td>\n<td>850亿</td>\n<td>25T</td>\n</tr>\n</tbody>\n</table>\n<p>当主键为 bigint (8 byte) 类型时，极限值为</p>\n<table>\n<thead>\n<tr>\n<th>高度</th>\n<th>多少个<br/>索引页<br/>（非叶子）</th>\n<th>多少个<br/>数据页<br/>（叶子）</th>\n<th>每页能存<br/>几个记录</th>\n<th>得到的行数</th>\n<th>数据大小大小</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1（0+1）</td>\n<td>0</td>\n<td>1</td>\n<td>50</td>\n<td>50</td>\n<td>16k</td>\n</tr>\n<tr>\n<td>2（1+1）</td>\n<td>1</td>\n<td>928</td>\n<td>50</td>\n<td>46400</td>\n<td>18MB</td>\n</tr>\n<tr>\n<td>3（2+1）</td>\n<td>928</td>\n<td>861,184</td>\n<td>50</td>\n<td>4000万</td>\n<td>22G</td>\n</tr>\n<tr>\n<td>4（3+1）</td>\n<td>861,184</td>\n<td>8亿</td>\n<td>50</td>\n<td>40亿</td>\n<td>25T</td>\n</tr>\n</tbody>\n</table>\n<p>参考：<a href=\"https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/\">https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/</a></p>\n<h3 id=\"主键选择\"><a class=\"markdownIt-Anchor\" href=\"#主键选择\"></a> 主键选择</h3>\n<ul>\n<li>\n<p>自增主键</p>\n<ul>\n<li>顺序写入，效率高</li>\n<li>每次查询都走2级索引</li>\n</ul>\n</li>\n<li>\n<p>随机主键</p>\n<ul>\n<li>节点分裂，数据移动，效率比较低</li>\n<li>有可能查询走2级索引</li>\n</ul>\n</li>\n<li>\n<p>业务主键，比如订单号，用户id，商品id，等</p>\n<ul>\n<li>需要保证值是递增，一般情况下使用雪花算法即可</li>\n<li>写入，查询磁盘利用率都高，可以使用一级索引</li>\n</ul>\n</li>\n<li>\n<p>联合主键</p>\n<ul>\n<li>影响索引列大小，不容易维护，不建议使用</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"联合索引使用\"><a class=\"markdownIt-Anchor\" href=\"#联合索引使用\"></a> 联合索引使用</h3>\n<ul>\n<li>按索引区分度排序，区分度越高的放在前面。<br>比如主键，时间，外键，手机号，身份证号等。<br>索引区分度低的有，类型，状态等</li>\n<li>覆盖索引，我们要查询的数据，正好在索引中，那么就不用回表了<br>比如一个索引 （id,phone,addr），在执行 <code>select phone，addr from user where id = 8;</code> 时<br>可以不用回表，直接返回结果集，又称三星索引。</li>\n<li>索引下推，mysql 5.6推出的性能改进，减少回表的次数，本该如此，不必细聊。</li>\n</ul>\n<h3 id=\"索引避坑指南\"><a class=\"markdownIt-Anchor\" href=\"#索引避坑指南\"></a> 索引避坑指南</h3>\n<ul>\n<li>\n<p>设置合理的长度</p>\n<ul>\n<li>\n<p>前10个字符建索引就行，如果前10个字符都体现不出区分度，那么这个数据本身也有点问题<br></p>\n</li>\n<li>\n<p>解决方案，对于区分度不大的列，再建立一个 hash 值列，通过索引（hash(addr),addr）查找就快了</p>\n</li>\n</ul>\n</li>\n<li>\n<p>索引失效的情况</p>\n<ul>\n<li>\n<p>A = XX or B=xx 索引会失效么？<br>不会失效，<br> mysql 5.1 引入了Index merge 技术，已经可以同时对 1个表使用多个索引分别扫描，1次出结果</p>\n</li>\n<li>\n<p>在联合索引中使用第二列，比如（phone，id_card_num）<br>使用<code>select * from user where id_card_num= 3701xxxxxx</code> 就不走索引</p>\n</li>\n<li>\n<p>隐式类型转换，不走索引<br></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">-- type moblie Long<br>-- 就不走索引<br>select * from user where moblie= &#x27;186123232222&#x27;<br></code></pre></td></tr></table></figure>\n<p>类型转换的时候，不使用索引。<br>上线前跑一遍查询计划，看看有没有这事，这个事很容易发生，但不容易发现。</p>\n</li>\n<li>\n<p>索引列包含计算，不走索引</p>\n</li>\n</ul>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mysql\">select * from user where age-20 = 30;<br>-- 没有人会这么干，如果有人这么干，必须请大家吃饭<br></code></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>索引区分度低，有时候也不走索引<br>当索引的区分度过低，比如 sex ，if_old , sell_status 列，使用sql语句<br><code>select * from user where sex=1 and phone=18678922342</code><br>通过 sex 索引查询，要频繁的回表，这时候使用索引查询，还不如直接使用全表扫描更快。<br></p>\n</li>\n<li>\n<p>查询条件，覆盖所有的索引值。也不会走本列索引<br>比如，有个 age 字段，使用sql语句，<code>select * from user where age &lt; 200</code><br>的时候，因为查询语句中的条件已经全部覆盖了整个数据集。<br>所以mysql也不会使用该索引。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"column类型最佳实践\"><a class=\"markdownIt-Anchor\" href=\"#column类型最佳实践\"></a> column类型最佳实践</h3>\n<ul>\n<li>数据库字符集使用 utf8mb4</li>\n<li>VARCHAR 按实际需要分配长度 ，255以上，需要更多的而空间描述长度，浪费空间</li>\n<li>文本字段建议使用 VARCHAR</li>\n<li>时间 字段使用 long，兼容性好，要不然迁移的时候，time类型有时区概念，容易出现bug</li>\n<li>bool字段使用tinyint</li>\n<li>枚举字段建议使用 tinyint</li>\n<li>交易金额 建议使用 long，存成分已足够，￥1.01存成 101</li>\n<li>禁止使用 “%” 前导的查询</li>\n<li>禁止在索引列进行数学运算，会导致索引失效</li>\n</ul>\n<h3 id=\"索引类型最佳实践\"><a class=\"markdownIt-Anchor\" href=\"#索引类型最佳实践\"></a> 索引类型最佳实践</h3>\n<ul>\n<li>表必须有主键，建议使用业务主键，使用雪花算法保证自增。</li>\n<li>单张表中索引数量不超过5个</li>\n<li>单个索引字段数不超过5个</li>\n<li>字符串索引使用前缀索引，前缀长度不超过10个字符</li>\n</ul>"},{"title":"分布式事务解决方案","toc":true,"hide":false,"date":"2021-07-31T14:02:41.000Z","sortn":40,"_content":"\n这是摘要\n<!-- more -->\n\n------\n\n\n\n## 分布式事务常见解决方案\n\n\n\n### 强一致协议\n\n- 两阶段提交 2PC、三阶段提交 3PC\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731230311.png\" style=\"zoom:33%;\" />\n\n- 落地方案：\n\n  - XA规范，是对两阶段提交的实现方案<br>资源管理器 - 事务参与者<br>事务管理器 - 事务协调者\n\n  - XA规范，有十倍的性能衰减。\n\n    - 有写锁，提交周期比较长\n\n    - 要求事务管理器，需要本地记录事务状态，机器挂了后，就不支持异地恢复。\n\n      \n\n### 柔性事务\n\n\n\n- TCC 规范 （Try - Confirm - Cancel）\n  - 尝试执行业务，预留资源<br>确认执行业务，使用Try阶段资源<br>取消执行业务，释放Try阶段预留的资源\n  - 缺点：\n    - 业务逻辑复杂，新手不会写，老人写出来不能保证没bug。\n    - 这种东西，测试也不太好测试，线上风险太大。\n    - 业务逻辑写出bug的风险，比不同分布式事务，出问题的概率还要大得多\n  - TCC协议中，没有给出机器Try后，机器掉电的异常情况的处理方案，<br>本质上是个有缺陷的协议\n- SAGA模型\n  - 一个分布式事务拆分为多个本地事务<br>本地事务都有相应的执行模块和补偿模块<br>事务管理器负责在事务失败时调度执行补偿逻辑;\n  - 缺点：\n    - 一个业务及要写正向业务逻辑，也要写出现异常的业务逻辑，工作量翻倍\n    - 即使有事务协调器，不能保证异常恢复逻辑，被精确一次执行，比如事务管理器，收到的异常执行结果为超时。\n    - 需要保证反向业务的幂等性，工作量也翻倍。\n    - 当异常回滚逻辑，第一次执行失败后，依然免不了人工介入。\n\n\n\n### 事务消息\n\n- 简化了分布式事务的模型，对业务友好\n\n- rocketMQ就有事务消息，可以拿来即用。\n\n  \n\n### Seata 分布式事务流程\n\n- **Seata 2PC模型**\n\n![image-20210731232847753](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731232847.png)\n\n\n\n- **seata AT模型**\n\n  - 介绍\n    - 一种无侵入的分布式事务解决方案，2PC的广义实现。 \n    - 源自阿里云GTS AT模式的开源版。\n  - 核心价值\n    - 低成本 : 编程模型不变，轻依赖不需要为分布式事务场景做特定设计。\n    - 高性能 : 一阶段提交，不阻塞;连接释放，保证整个系统的吞吐。\n    - 高可用 : 极端的异常情况下，可以暂时跳过异常事务，保证系统可用。\n  - 实现方案\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233319.png\" alt=\"image-20210731233319236\" style=\"zoom:50%;\" />\n\n![image-20210731233418204](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233418.png)\n\n","source":"_posts/mysql/分布式事务解决方案.md","raw":"---\ntitle: '分布式事务解决方案'\ntoc: true\ncategories:\n  - 数据库\n  - mysql\ntags:\n  - 分库分表\n  - 分布式事务\nhide: false\ndate: 2021-07-31 22:02:41\nsortn: 40\n---\n\n这是摘要\n<!-- more -->\n\n------\n\n\n\n## 分布式事务常见解决方案\n\n\n\n### 强一致协议\n\n- 两阶段提交 2PC、三阶段提交 3PC\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731230311.png\" style=\"zoom:33%;\" />\n\n- 落地方案：\n\n  - XA规范，是对两阶段提交的实现方案<br>资源管理器 - 事务参与者<br>事务管理器 - 事务协调者\n\n  - XA规范，有十倍的性能衰减。\n\n    - 有写锁，提交周期比较长\n\n    - 要求事务管理器，需要本地记录事务状态，机器挂了后，就不支持异地恢复。\n\n      \n\n### 柔性事务\n\n\n\n- TCC 规范 （Try - Confirm - Cancel）\n  - 尝试执行业务，预留资源<br>确认执行业务，使用Try阶段资源<br>取消执行业务，释放Try阶段预留的资源\n  - 缺点：\n    - 业务逻辑复杂，新手不会写，老人写出来不能保证没bug。\n    - 这种东西，测试也不太好测试，线上风险太大。\n    - 业务逻辑写出bug的风险，比不同分布式事务，出问题的概率还要大得多\n  - TCC协议中，没有给出机器Try后，机器掉电的异常情况的处理方案，<br>本质上是个有缺陷的协议\n- SAGA模型\n  - 一个分布式事务拆分为多个本地事务<br>本地事务都有相应的执行模块和补偿模块<br>事务管理器负责在事务失败时调度执行补偿逻辑;\n  - 缺点：\n    - 一个业务及要写正向业务逻辑，也要写出现异常的业务逻辑，工作量翻倍\n    - 即使有事务协调器，不能保证异常恢复逻辑，被精确一次执行，比如事务管理器，收到的异常执行结果为超时。\n    - 需要保证反向业务的幂等性，工作量也翻倍。\n    - 当异常回滚逻辑，第一次执行失败后，依然免不了人工介入。\n\n\n\n### 事务消息\n\n- 简化了分布式事务的模型，对业务友好\n\n- rocketMQ就有事务消息，可以拿来即用。\n\n  \n\n### Seata 分布式事务流程\n\n- **Seata 2PC模型**\n\n![image-20210731232847753](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731232847.png)\n\n\n\n- **seata AT模型**\n\n  - 介绍\n    - 一种无侵入的分布式事务解决方案，2PC的广义实现。 \n    - 源自阿里云GTS AT模式的开源版。\n  - 核心价值\n    - 低成本 : 编程模型不变，轻依赖不需要为分布式事务场景做特定设计。\n    - 高性能 : 一阶段提交，不阻塞;连接释放，保证整个系统的吞吐。\n    - 高可用 : 极端的异常情况下，可以暂时跳过异常事务，保证系统可用。\n  - 实现方案\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233319.png\" alt=\"image-20210731233319236\" style=\"zoom:50%;\" />\n\n![image-20210731233418204](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233418.png)\n\n","slug":"mysql/分布式事务解决方案","published":1,"updated":"2021-07-31T14:02:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmr000fcpfy12d2hmg6","content":"<p>这是摘要</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"分布式事务常见解决方案\"> 分布式事务常见解决方案</span></h2>\n<h3><span id=\"强一致协议\"> 强一致协议</span></h3>\n<ul>\n<li>\n<p>两阶段提交 2PC、三阶段提交 3PC</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731230311.png\" style=\"zoom:33%;\">\n</li>\n<li>\n<p>落地方案：</p>\n<ul>\n<li>\n<p>XA规范，是对两阶段提交的实现方案<br>资源管理器 - 事务参与者<br>事务管理器 - 事务协调者</p>\n</li>\n<li>\n<p>XA规范，有十倍的性能衰减。</p>\n<ul>\n<li>\n<p>有写锁，提交周期比较长</p>\n</li>\n<li>\n<p>要求事务管理器，需要本地记录事务状态，机器挂了后，就不支持异地恢复。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"柔性事务\"> 柔性事务</span></h3>\n<ul>\n<li>TCC 规范 （Try - Confirm - Cancel）\n<ul>\n<li>尝试执行业务，预留资源<br>确认执行业务，使用Try阶段资源<br>取消执行业务，释放Try阶段预留的资源</li>\n<li>缺点：\n<ul>\n<li>业务逻辑复杂，新手不会写，老人写出来不能保证没bug。</li>\n<li>这种东西，测试也不太好测试，线上风险太大。</li>\n<li>业务逻辑写出bug的风险，比不同分布式事务，出问题的概率还要大得多</li>\n</ul>\n</li>\n<li>TCC协议中，没有给出机器Try后，机器掉电的异常情况的处理方案，<br>本质上是个有缺陷的协议</li>\n</ul>\n</li>\n<li>SAGA模型\n<ul>\n<li>一个分布式事务拆分为多个本地事务<br>本地事务都有相应的执行模块和补偿模块<br>事务管理器负责在事务失败时调度执行补偿逻辑;</li>\n<li>缺点：\n<ul>\n<li>一个业务及要写正向业务逻辑，也要写出现异常的业务逻辑，工作量翻倍</li>\n<li>即使有事务协调器，不能保证异常恢复逻辑，被精确一次执行，比如事务管理器，收到的异常执行结果为超时。</li>\n<li>需要保证反向业务的幂等性，工作量也翻倍。</li>\n<li>当异常回滚逻辑，第一次执行失败后，依然免不了人工介入。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"事务消息\"> 事务消息</span></h3>\n<ul>\n<li>\n<p>简化了分布式事务的模型，对业务友好</p>\n</li>\n<li>\n<p>rocketMQ就有事务消息，可以拿来即用。</p>\n</li>\n</ul>\n<h3><span id=\"seata-分布式事务流程\"> Seata 分布式事务流程</span></h3>\n<ul>\n<li><strong>Seata 2PC模型</strong></li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731232847.png\" alt=\"image-20210731232847753\"></p>\n<ul>\n<li>\n<p><strong>seata AT模型</strong></p>\n<ul>\n<li>介绍\n<ul>\n<li>一种无侵入的分布式事务解决方案，2PC的广义实现。</li>\n<li>源自阿里云GTS AT模式的开源版。</li>\n</ul>\n</li>\n<li>核心价值\n<ul>\n<li>低成本 : 编程模型不变，轻依赖不需要为分布式事务场景做特定设计。</li>\n<li>高性能 : 一阶段提交，不阻塞;连接释放，保证整个系统的吞吐。</li>\n<li>高可用 : 极端的异常情况下，可以暂时跳过异常事务，保证系统可用。</li>\n</ul>\n</li>\n<li>实现方案</li>\n</ul>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233319.png\" alt=\"image-20210731233319236\" style=\"zoom:50%;\">\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233418.png\" alt=\"image-20210731233418204\"></p>\n","site":{"data":{}},"excerpt":"<p>这是摘要</p>","more":"<hr />\n<h2 id=\"分布式事务常见解决方案\"><a class=\"markdownIt-Anchor\" href=\"#分布式事务常见解决方案\"></a> 分布式事务常见解决方案</h2>\n<h3 id=\"强一致协议\"><a class=\"markdownIt-Anchor\" href=\"#强一致协议\"></a> 强一致协议</h3>\n<ul>\n<li>\n<p>两阶段提交 2PC、三阶段提交 3PC</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731230311.png\" style=\"zoom:33%;\" />\n</li>\n<li>\n<p>落地方案：</p>\n<ul>\n<li>\n<p>XA规范，是对两阶段提交的实现方案<br>资源管理器 - 事务参与者<br>事务管理器 - 事务协调者</p>\n</li>\n<li>\n<p>XA规范，有十倍的性能衰减。</p>\n<ul>\n<li>\n<p>有写锁，提交周期比较长</p>\n</li>\n<li>\n<p>要求事务管理器，需要本地记录事务状态，机器挂了后，就不支持异地恢复。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"柔性事务\"><a class=\"markdownIt-Anchor\" href=\"#柔性事务\"></a> 柔性事务</h3>\n<ul>\n<li>TCC 规范 （Try - Confirm - Cancel）\n<ul>\n<li>尝试执行业务，预留资源<br>确认执行业务，使用Try阶段资源<br>取消执行业务，释放Try阶段预留的资源</li>\n<li>缺点：\n<ul>\n<li>业务逻辑复杂，新手不会写，老人写出来不能保证没bug。</li>\n<li>这种东西，测试也不太好测试，线上风险太大。</li>\n<li>业务逻辑写出bug的风险，比不同分布式事务，出问题的概率还要大得多</li>\n</ul>\n</li>\n<li>TCC协议中，没有给出机器Try后，机器掉电的异常情况的处理方案，<br>本质上是个有缺陷的协议</li>\n</ul>\n</li>\n<li>SAGA模型\n<ul>\n<li>一个分布式事务拆分为多个本地事务<br>本地事务都有相应的执行模块和补偿模块<br>事务管理器负责在事务失败时调度执行补偿逻辑;</li>\n<li>缺点：\n<ul>\n<li>一个业务及要写正向业务逻辑，也要写出现异常的业务逻辑，工作量翻倍</li>\n<li>即使有事务协调器，不能保证异常恢复逻辑，被精确一次执行，比如事务管理器，收到的异常执行结果为超时。</li>\n<li>需要保证反向业务的幂等性，工作量也翻倍。</li>\n<li>当异常回滚逻辑，第一次执行失败后，依然免不了人工介入。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"事务消息\"><a class=\"markdownIt-Anchor\" href=\"#事务消息\"></a> 事务消息</h3>\n<ul>\n<li>\n<p>简化了分布式事务的模型，对业务友好</p>\n</li>\n<li>\n<p>rocketMQ就有事务消息，可以拿来即用。</p>\n</li>\n</ul>\n<h3 id=\"seata-分布式事务流程\"><a class=\"markdownIt-Anchor\" href=\"#seata-分布式事务流程\"></a> Seata 分布式事务流程</h3>\n<ul>\n<li><strong>Seata 2PC模型</strong></li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731232847.png\" alt=\"image-20210731232847753\" /></p>\n<ul>\n<li>\n<p><strong>seata AT模型</strong></p>\n<ul>\n<li>介绍\n<ul>\n<li>一种无侵入的分布式事务解决方案，2PC的广义实现。</li>\n<li>源自阿里云GTS AT模式的开源版。</li>\n</ul>\n</li>\n<li>核心价值\n<ul>\n<li>低成本 : 编程模型不变，轻依赖不需要为分布式事务场景做特定设计。</li>\n<li>高性能 : 一阶段提交，不阻塞;连接释放，保证整个系统的吞吐。</li>\n<li>高可用 : 极端的异常情况下，可以暂时跳过异常事务，保证系统可用。</li>\n</ul>\n</li>\n<li>实现方案</li>\n</ul>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233319.png\" alt=\"image-20210731233319236\" style=\"zoom:50%;\" />\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731233418.png\" alt=\"image-20210731233418204\" /></p>"},{"title":"分库分表策略概述","toc":true,"hide":false,"date":"2021-07-31T13:36:16.000Z","sortn":30,"_content":"\n本章主要讲大量数据的分库分表\n<!-- more -->\n\n------\n\n\n\n## 什么时候考虑分表\n\n- 在线服务，单表超过1000万，考虑分表 \n\n\n\n## 分库分表的方式\n\n\n\n### 分表方式\n\n- 取模：存储相对均匀，访问也均匀，用户数据一般这样分，\n\n- 宽表拆成窄表，假如有一个宽表，有的列需要频繁改动，则拆出去。<br>比如 user `uid , nickname, img_url, userswitch` 其中userswitch 是一个64位Long类型，<br>描述了用户的很多开关，比如是否允许被加好友，是否允许被搜索到，是否允许xxx等<br>可以拆成 user_extra 来单拎出来，进行查询 or 修改\n\n- 按时间：冷热库拆分，订单场景。\n\n  \n\n### 分库的方式\n\n- 按业务垂直分，用户库，商品库，订单库。防止某个业务把整个数据库压垮\n- 水平分成多个库，一般伴随着分表进行，<br>比如一个表分成128个表，再分成4个库进行存储。\n\n\n\n## 分表最佳实践\n\n\n\n### 用户库分表\n\n- 选择合适的分片键， 一般通过uid分片\n\n\n\n### 商品库分表\n\n- 基因注入法 【todo】\n\n \n\n### 系统消息分表\n\n- 冷热数据分表<br>假如系统消息有效期为30天，按月分库。msg_1901，msg_1902，msg_1903。。。。<br>如果查询的时候30天的数据，则需要查询2个表，不舒服。<br>可用用双写的方案，当月数据也写到下月的数据表中。<br>查询的时候，则查询本月数据表，本月数据表中，自然携带上月的数据。\n\n\n\n## Sharding Sphere应用实践\n\n### 分库分表带来的问题\n\n- 查询路由问题\n\n  - 分表规则\n  - 写入路由\n  - 查询路由\n  - 分页查询方案\n\n  \n\n- Sharding Sphere 选型\n\n  - sharding sphere ，从业务进程内，对sql进行改写。\n\n  - sharding proxy，代理访问数据库，使得访问变得透明。\n\n    | 对比项                      | sharding-jdbc                         | sharding-proxy |\n    | --------------------------- | ------------------------------------- | -------------- |\n    | 数据库                      | 任意<br>只要JDBC支持的库<br/>他都支持 | 仅mysql        |\n    | 异构语言                    | 仅支持java                            | 任意语言       |\n    | 连接数                      | 高                                    | 低             |\n    | 性能                        | 损耗低                                | 损耗略高       |\n    | 去中心化                    | 是                                    | 否             |\n    | 静态入口<br>Navicat直接访问 | 无                                    | 有             |\n\n  \n\n- 最终选型，全家桶方案\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731215348.png\" style=\"zoom:50%;\" />\n","source":"_posts/mysql/分库分表策略概述.md","raw":"---\ntitle: '分库分表策略概述'\ntoc: true\ncategories:\n  - 数据库\n  - mysql\ntags:\n  - 分库分表\nhide: false\ndate: 2021-07-31 21:36:16\nsortn: 30\n---\n\n本章主要讲大量数据的分库分表\n<!-- more -->\n\n------\n\n\n\n## 什么时候考虑分表\n\n- 在线服务，单表超过1000万，考虑分表 \n\n\n\n## 分库分表的方式\n\n\n\n### 分表方式\n\n- 取模：存储相对均匀，访问也均匀，用户数据一般这样分，\n\n- 宽表拆成窄表，假如有一个宽表，有的列需要频繁改动，则拆出去。<br>比如 user `uid , nickname, img_url, userswitch` 其中userswitch 是一个64位Long类型，<br>描述了用户的很多开关，比如是否允许被加好友，是否允许被搜索到，是否允许xxx等<br>可以拆成 user_extra 来单拎出来，进行查询 or 修改\n\n- 按时间：冷热库拆分，订单场景。\n\n  \n\n### 分库的方式\n\n- 按业务垂直分，用户库，商品库，订单库。防止某个业务把整个数据库压垮\n- 水平分成多个库，一般伴随着分表进行，<br>比如一个表分成128个表，再分成4个库进行存储。\n\n\n\n## 分表最佳实践\n\n\n\n### 用户库分表\n\n- 选择合适的分片键， 一般通过uid分片\n\n\n\n### 商品库分表\n\n- 基因注入法 【todo】\n\n \n\n### 系统消息分表\n\n- 冷热数据分表<br>假如系统消息有效期为30天，按月分库。msg_1901，msg_1902，msg_1903。。。。<br>如果查询的时候30天的数据，则需要查询2个表，不舒服。<br>可用用双写的方案，当月数据也写到下月的数据表中。<br>查询的时候，则查询本月数据表，本月数据表中，自然携带上月的数据。\n\n\n\n## Sharding Sphere应用实践\n\n### 分库分表带来的问题\n\n- 查询路由问题\n\n  - 分表规则\n  - 写入路由\n  - 查询路由\n  - 分页查询方案\n\n  \n\n- Sharding Sphere 选型\n\n  - sharding sphere ，从业务进程内，对sql进行改写。\n\n  - sharding proxy，代理访问数据库，使得访问变得透明。\n\n    | 对比项                      | sharding-jdbc                         | sharding-proxy |\n    | --------------------------- | ------------------------------------- | -------------- |\n    | 数据库                      | 任意<br>只要JDBC支持的库<br/>他都支持 | 仅mysql        |\n    | 异构语言                    | 仅支持java                            | 任意语言       |\n    | 连接数                      | 高                                    | 低             |\n    | 性能                        | 损耗低                                | 损耗略高       |\n    | 去中心化                    | 是                                    | 否             |\n    | 静态入口<br>Navicat直接访问 | 无                                    | 有             |\n\n  \n\n- 最终选型，全家桶方案\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731215348.png\" style=\"zoom:50%;\" />\n","slug":"mysql/分库分表策略概述","published":1,"updated":"2021-07-31T13:36:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxms000icpfyarnne0v4","content":"<p>本章主要讲大量数据的分库分表</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"什么时候考虑分表\"> 什么时候考虑分表</span></h2>\n<ul>\n<li>在线服务，单表超过1000万，考虑分表</li>\n</ul>\n<h2><span id=\"分库分表的方式\"> 分库分表的方式</span></h2>\n<h3><span id=\"分表方式\"> 分表方式</span></h3>\n<ul>\n<li>\n<p>取模：存储相对均匀，访问也均匀，用户数据一般这样分，</p>\n</li>\n<li>\n<p>宽表拆成窄表，假如有一个宽表，有的列需要频繁改动，则拆出去。<br>比如 user <code>uid , nickname, img_url, userswitch</code> 其中userswitch 是一个64位Long类型，<br>描述了用户的很多开关，比如是否允许被加好友，是否允许被搜索到，是否允许xxx等<br>可以拆成 user_extra 来单拎出来，进行查询 or 修改</p>\n</li>\n<li>\n<p>按时间：冷热库拆分，订单场景。</p>\n</li>\n</ul>\n<h3><span id=\"分库的方式\"> 分库的方式</span></h3>\n<ul>\n<li>按业务垂直分，用户库，商品库，订单库。防止某个业务把整个数据库压垮</li>\n<li>水平分成多个库，一般伴随着分表进行，<br>比如一个表分成128个表，再分成4个库进行存储。</li>\n</ul>\n<h2><span id=\"分表最佳实践\"> 分表最佳实践</span></h2>\n<h3><span id=\"用户库分表\"> 用户库分表</span></h3>\n<ul>\n<li>选择合适的分片键， 一般通过uid分片</li>\n</ul>\n<h3><span id=\"商品库分表\"> 商品库分表</span></h3>\n<ul>\n<li>基因注入法 【todo】</li>\n</ul>\n<h3><span id=\"系统消息分表\"> 系统消息分表</span></h3>\n<ul>\n<li>冷热数据分表<br>假如系统消息有效期为30天，按月分库。msg_1901，msg_1902，msg_1903。。。。<br>如果查询的时候30天的数据，则需要查询2个表，不舒服。<br>可用用双写的方案，当月数据也写到下月的数据表中。<br>查询的时候，则查询本月数据表，本月数据表中，自然携带上月的数据。</li>\n</ul>\n<h2><span id=\"sharding-sphere应用实践\"> Sharding Sphere应用实践</span></h2>\n<h3><span id=\"分库分表带来的问题\"> 分库分表带来的问题</span></h3>\n<ul>\n<li>\n<p>查询路由问题</p>\n<ul>\n<li>分表规则</li>\n<li>写入路由</li>\n<li>查询路由</li>\n<li>分页查询方案</li>\n</ul>\n</li>\n<li>\n<p>Sharding Sphere 选型</p>\n<ul>\n<li>\n<p>sharding sphere ，从业务进程内，对sql进行改写。</p>\n</li>\n<li>\n<p>sharding proxy，代理访问数据库，使得访问变得透明。</p>\n<table>\n<thead>\n<tr>\n<th>对比项</th>\n<th>sharding-jdbc</th>\n<th>sharding-proxy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>数据库</td>\n<td>任意<br>只要JDBC支持的库<br>他都支持</td>\n<td>仅mysql</td>\n</tr>\n<tr>\n<td>异构语言</td>\n<td>仅支持java</td>\n<td>任意语言</td>\n</tr>\n<tr>\n<td>连接数</td>\n<td>高</td>\n<td>低</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>损耗低</td>\n<td>损耗略高</td>\n</tr>\n<tr>\n<td>去中心化</td>\n<td>是</td>\n<td>否</td>\n</tr>\n<tr>\n<td>静态入口<br>Navicat直接访问</td>\n<td>无</td>\n<td>有</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>最终选型，全家桶方案</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731215348.png\" style=\"zoom:50%;\">\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本章主要讲大量数据的分库分表</p>","more":"<hr />\n<h2 id=\"什么时候考虑分表\"><a class=\"markdownIt-Anchor\" href=\"#什么时候考虑分表\"></a> 什么时候考虑分表</h2>\n<ul>\n<li>在线服务，单表超过1000万，考虑分表</li>\n</ul>\n<h2 id=\"分库分表的方式\"><a class=\"markdownIt-Anchor\" href=\"#分库分表的方式\"></a> 分库分表的方式</h2>\n<h3 id=\"分表方式\"><a class=\"markdownIt-Anchor\" href=\"#分表方式\"></a> 分表方式</h3>\n<ul>\n<li>\n<p>取模：存储相对均匀，访问也均匀，用户数据一般这样分，</p>\n</li>\n<li>\n<p>宽表拆成窄表，假如有一个宽表，有的列需要频繁改动，则拆出去。<br>比如 user <code>uid , nickname, img_url, userswitch</code> 其中userswitch 是一个64位Long类型，<br>描述了用户的很多开关，比如是否允许被加好友，是否允许被搜索到，是否允许xxx等<br>可以拆成 user_extra 来单拎出来，进行查询 or 修改</p>\n</li>\n<li>\n<p>按时间：冷热库拆分，订单场景。</p>\n</li>\n</ul>\n<h3 id=\"分库的方式\"><a class=\"markdownIt-Anchor\" href=\"#分库的方式\"></a> 分库的方式</h3>\n<ul>\n<li>按业务垂直分，用户库，商品库，订单库。防止某个业务把整个数据库压垮</li>\n<li>水平分成多个库，一般伴随着分表进行，<br>比如一个表分成128个表，再分成4个库进行存储。</li>\n</ul>\n<h2 id=\"分表最佳实践\"><a class=\"markdownIt-Anchor\" href=\"#分表最佳实践\"></a> 分表最佳实践</h2>\n<h3 id=\"用户库分表\"><a class=\"markdownIt-Anchor\" href=\"#用户库分表\"></a> 用户库分表</h3>\n<ul>\n<li>选择合适的分片键， 一般通过uid分片</li>\n</ul>\n<h3 id=\"商品库分表\"><a class=\"markdownIt-Anchor\" href=\"#商品库分表\"></a> 商品库分表</h3>\n<ul>\n<li>基因注入法 【todo】</li>\n</ul>\n<h3 id=\"系统消息分表\"><a class=\"markdownIt-Anchor\" href=\"#系统消息分表\"></a> 系统消息分表</h3>\n<ul>\n<li>冷热数据分表<br>假如系统消息有效期为30天，按月分库。msg_1901，msg_1902，msg_1903。。。。<br>如果查询的时候30天的数据，则需要查询2个表，不舒服。<br>可用用双写的方案，当月数据也写到下月的数据表中。<br>查询的时候，则查询本月数据表，本月数据表中，自然携带上月的数据。</li>\n</ul>\n<h2 id=\"sharding-sphere应用实践\"><a class=\"markdownIt-Anchor\" href=\"#sharding-sphere应用实践\"></a> Sharding Sphere应用实践</h2>\n<h3 id=\"分库分表带来的问题\"><a class=\"markdownIt-Anchor\" href=\"#分库分表带来的问题\"></a> 分库分表带来的问题</h3>\n<ul>\n<li>\n<p>查询路由问题</p>\n<ul>\n<li>分表规则</li>\n<li>写入路由</li>\n<li>查询路由</li>\n<li>分页查询方案</li>\n</ul>\n</li>\n<li>\n<p>Sharding Sphere 选型</p>\n<ul>\n<li>\n<p>sharding sphere ，从业务进程内，对sql进行改写。</p>\n</li>\n<li>\n<p>sharding proxy，代理访问数据库，使得访问变得透明。</p>\n<table>\n<thead>\n<tr>\n<th>对比项</th>\n<th>sharding-jdbc</th>\n<th>sharding-proxy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>数据库</td>\n<td>任意<br>只要JDBC支持的库<br/>他都支持</td>\n<td>仅mysql</td>\n</tr>\n<tr>\n<td>异构语言</td>\n<td>仅支持java</td>\n<td>任意语言</td>\n</tr>\n<tr>\n<td>连接数</td>\n<td>高</td>\n<td>低</td>\n</tr>\n<tr>\n<td>性能</td>\n<td>损耗低</td>\n<td>损耗略高</td>\n</tr>\n<tr>\n<td>去中心化</td>\n<td>是</td>\n<td>否</td>\n</tr>\n<tr>\n<td>静态入口<br>Navicat直接访问</td>\n<td>无</td>\n<td>有</td>\n</tr>\n</tbody>\n</table>\n</li>\n</ul>\n</li>\n<li>\n<p>最终选型，全家桶方案</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210731215348.png\" style=\"zoom:50%;\" />\n</li>\n</ul>"},{"title":"rpc【1】概述","toc":true,"hide":true,"sortn":10,"date":"2021-08-01T09:49:05.000Z","_content":"\nrpc学习 之 概述\n<!-- more -->\n\n------\n\n\n\n# rpc概述\n\n\n\n## rpc定义：\n\n​\t像调用本地方法一样调用远程服务。\n\n\n\n## rpc功能概述\n\n### consumer功能分析\n\n![consumer模块](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801182613.png)\n\n#### 连接管理，connect manager\n\n- 初始化时机\n- 连接数维护\n- 心跳、重连机制\n\n\n\n#### 负载均衡\n\n#### 请求路由\n\n#### 超时处理\n\n#### 健康检查\n\n\n\n### provicer功能分析\n\n#### 队列/线程池\n\n#### 超时丢弃\n\n#### 优雅关闭\n\n#### 过载保护\n\n","source":"_posts/rpc框架/rpc【1】概述.md","raw":"---\ntitle: rpc【1】概述\ntoc: true\ncategories:\n  - rpc框架\ntags:\n  - rpc\nhide: true\nsortn: 10\ndate: 2021-08-01 17:49:05\n---\n\nrpc学习 之 概述\n<!-- more -->\n\n------\n\n\n\n# rpc概述\n\n\n\n## rpc定义：\n\n​\t像调用本地方法一样调用远程服务。\n\n\n\n## rpc功能概述\n\n### consumer功能分析\n\n![consumer模块](https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801182613.png)\n\n#### 连接管理，connect manager\n\n- 初始化时机\n- 连接数维护\n- 心跳、重连机制\n\n\n\n#### 负载均衡\n\n#### 请求路由\n\n#### 超时处理\n\n#### 健康检查\n\n\n\n### provicer功能分析\n\n#### 队列/线程池\n\n#### 超时丢弃\n\n#### 优雅关闭\n\n#### 过载保护\n\n","slug":"rpc框架/rpc【1】概述","published":1,"updated":"2021-08-01T09:49:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmt000kcpfy0fq316ig","content":"<p>rpc学习 之 概述</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"rpc概述\"> rpc概述</span></h1>\n<h2><span id=\"rpc定义\"> rpc定义：</span></h2>\n<p>​\t像调用本地方法一样调用远程服务。</p>\n<h2><span id=\"rpc功能概述\"> rpc功能概述</span></h2>\n<h3><span id=\"consumer功能分析\"> consumer功能分析</span></h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801182613.png\" alt=\"consumer模块\"></p>\n<h4><span id=\"连接管理connect-manager\"> 连接管理，connect manager</span></h4>\n<ul>\n<li>初始化时机</li>\n<li>连接数维护</li>\n<li>心跳、重连机制</li>\n</ul>\n<h4><span id=\"负载均衡\"> 负载均衡</span></h4>\n<h4><span id=\"请求路由\"> 请求路由</span></h4>\n<h4><span id=\"超时处理\"> 超时处理</span></h4>\n<h4><span id=\"健康检查\"> 健康检查</span></h4>\n<h3><span id=\"provicer功能分析\"> provicer功能分析</span></h3>\n<h4><span id=\"队列线程池\"> 队列/线程池</span></h4>\n<h4><span id=\"超时丢弃\"> 超时丢弃</span></h4>\n<h4><span id=\"优雅关闭\"> 优雅关闭</span></h4>\n<h4><span id=\"过载保护\"> 过载保护</span></h4>\n","site":{"data":{}},"excerpt":"<p>rpc学习 之 概述</p>","more":"<hr />\n<h1 id=\"rpc概述\"><a class=\"markdownIt-Anchor\" href=\"#rpc概述\"></a> rpc概述</h1>\n<h2 id=\"rpc定义\"><a class=\"markdownIt-Anchor\" href=\"#rpc定义\"></a> rpc定义：</h2>\n<p>​\t像调用本地方法一样调用远程服务。</p>\n<h2 id=\"rpc功能概述\"><a class=\"markdownIt-Anchor\" href=\"#rpc功能概述\"></a> rpc功能概述</h2>\n<h3 id=\"consumer功能分析\"><a class=\"markdownIt-Anchor\" href=\"#consumer功能分析\"></a> consumer功能分析</h3>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801182613.png\" alt=\"consumer模块\" /></p>\n<h4 id=\"连接管理connect-manager\"><a class=\"markdownIt-Anchor\" href=\"#连接管理connect-manager\"></a> 连接管理，connect manager</h4>\n<ul>\n<li>初始化时机</li>\n<li>连接数维护</li>\n<li>心跳、重连机制</li>\n</ul>\n<h4 id=\"负载均衡\"><a class=\"markdownIt-Anchor\" href=\"#负载均衡\"></a> 负载均衡</h4>\n<h4 id=\"请求路由\"><a class=\"markdownIt-Anchor\" href=\"#请求路由\"></a> 请求路由</h4>\n<h4 id=\"超时处理\"><a class=\"markdownIt-Anchor\" href=\"#超时处理\"></a> 超时处理</h4>\n<h4 id=\"健康检查\"><a class=\"markdownIt-Anchor\" href=\"#健康检查\"></a> 健康检查</h4>\n<h3 id=\"provicer功能分析\"><a class=\"markdownIt-Anchor\" href=\"#provicer功能分析\"></a> provicer功能分析</h3>\n<h4 id=\"队列线程池\"><a class=\"markdownIt-Anchor\" href=\"#队列线程池\"></a> 队列/线程池</h4>\n<h4 id=\"超时丢弃\"><a class=\"markdownIt-Anchor\" href=\"#超时丢弃\"></a> 超时丢弃</h4>\n<h4 id=\"优雅关闭\"><a class=\"markdownIt-Anchor\" href=\"#优雅关闭\"></a> 优雅关闭</h4>\n<h4 id=\"过载保护\"><a class=\"markdownIt-Anchor\" href=\"#过载保护\"></a> 过载保护</h4>"},{"title":"写代码避坑指南【1】java_集合","toc":true,"hide":true,"sortn":10,"date":"2021-08-02T17:27:34.000Z","_content":"\n\n\n我们从常用的“坑”出发，给你一个简单的避坑小抄，具体原因先不展开，只用一句话提示。\n\n本节主要讲的是 java 容器类常见的坑。\n\n<!-- more -->\n\n------\n\n\n\n## 写java避坑指南【1】有关collect包\n\n\n\n### Map\n\n\n\n#### 线程不安全\n\n- 多线程中，使用线程不安全的容器，后果不仅仅是数据不对，还可能导致程序死循环。所以还是不能无脑使用现成不安全的容器。\n\n- HashMap，中规中矩，默认使用。\n- Treemap，实现了SortedMap，放入的Key必须实现`Comparable`接口，有key排序首选使用。\n- EnumMap，如果作为key的对象是enum类型，首选使用，效率很高。\n- web开发中也需要空的 Map。使用`Map<K, V> emptyMap()`\n- LinkedHashMap，要求key按照，put顺序存储时使用。\n- IdentityHashMap，kv的查找关系不是equals，而是==。即java的地址查找，只有序列化框架可能会用到，业务开发一般用不到。\n\n\n\n#### 线程安全\n\n- concurrenthashmap，中规中矩，默认使用。\n\n- hashtable，当必须保证强一致性时使用。concurrenthashmap中的get、size 等方法没有用到锁，有可能获得旧的数据。\n\n- concurrentSkipListMap，超大数据量(万级别)时候使用，且存在大量增删改操作的时候使用，在高并发下，跳表性能表现反超 concurrenthashmap。（红黑树在并发情况下，删除和插入过程中有个平衡的过程，锁竞争度会升高几个级别）\n\n  \n\n\n### map的使用注意事项\n\n- 强制，k一定使用字符串，不允许用对象。（和equals方法有关，不展开）\n- 默认，kv都尽量不允许为null。并发容器，k一定不允许为null，可能报npe不说，主要是没有意义。\n\n| 集合类                | key<br>是否为null | value<br>是否为null | 是否线程安全 |\n| --------------------- | ----------------- | ------------------- | ------------ |\n| HashMap               | 允许l             | 允许                | 否           |\n| TreeMap               | 不允许            | 允许                | 否           |\n| LinkedHashMap         | 允许              | 允许                | 否           |\n| EnumMap               | 不允许            | 允许                | 否           |\n|                       |                   |                     |              |\n| HashTable             | 不允许            | 不允许              | 是           |\n| ConcurrentHashMap     | 不允许            | 不允许              | 是           |\n| ConcurrentSkipListMap | 不允许            | 不允许              | 是           |\n\n\n\n------\n\n\n\n### List\n\n\n\n#### 线程不安全\n\n- 默认情况下一律使用ArrayList\n- 有去重需要，默认使用HashSet\n- 去重 + 重新排序使用TreeSet。\n- web开发中经常需要空 List。使用 `Collections.emptyList();`\n- LinkedList，随机读性能很烂，业务开发没有使用场景，不建议使用\n\n\n\n#### 线程安全\n\n- 线程安全List，首选 `Colletcions.synchronizedList(new ArrayList<>());` 各方面都没有问题。\n- 线程安全Set，JDK没有提供，可以使用hutool实现的 [线程安全的HashSet-ConcurrentHashSet](https://www.hutool.cn/docs/#/core/集合类/线程安全的HashSet-ConcurrentHashSet?id=线程安全的hashset-concurrenthashset)\n- 线程安全的队列，使用hutool实现的，[有界优先队列-BoundedPriorityQueue](https://www.hutool.cn/docs/#/core/集合类/有界优先队列-BoundedPriorityQueue?id=有界优先队列-boundedpriorityqueue)\n- DelayQueue 延时队列，一般情况下不会使用，非要使用，切记不能使用纳秒为单位。<br>（纳秒会让cpu负载上升几个数量将）\n- CopyOnWriteArrayList 并发版ArrayList，这个容器写成本非常高，一般没有使用场景，如需并发写，ArrayList加锁即可。\n\n\n\n### List的使用注意事项\n\n| 集合类               | value<br/>是否为null | 是否线程安全 |\n| -------------------- | -------------------- | ------------ |\n| ArrayList            | 允许                 | 否           |\n| HashSet              | 允许                 | 否           |\n| TreeSet              | 不允许               | 否           |\n| LinkedList           | 允许                 | 否           |\n|                      |                      |              |\n| HashTable            | 允许                 | 是           |\n| ConcurrentHashSet    | 允许                 | 是           |\n| BoundedPriorityQueue | 允许                 | 是           |\n| DelayQueue           | 允许                 | 是           |\n| CopyOnWriteArrayList | 允许                 | 是           |\n\n","source":"_posts/写代码避坑指南/写代码避坑指南【1】java_集合.md","raw":"---\ntitle: 写代码避坑指南【1】java_集合\ntoc: true\ncategories:\n  - 写代码避坑指南\n  - java\ntags:\n  - java\n  - 实用开发小抄\n\nhide: true\nsortn: 10\ndate: 2021-08-03 01:27:34\n---\n\n\n\n我们从常用的“坑”出发，给你一个简单的避坑小抄，具体原因先不展开，只用一句话提示。\n\n本节主要讲的是 java 容器类常见的坑。\n\n<!-- more -->\n\n------\n\n\n\n## 写java避坑指南【1】有关collect包\n\n\n\n### Map\n\n\n\n#### 线程不安全\n\n- 多线程中，使用线程不安全的容器，后果不仅仅是数据不对，还可能导致程序死循环。所以还是不能无脑使用现成不安全的容器。\n\n- HashMap，中规中矩，默认使用。\n- Treemap，实现了SortedMap，放入的Key必须实现`Comparable`接口，有key排序首选使用。\n- EnumMap，如果作为key的对象是enum类型，首选使用，效率很高。\n- web开发中也需要空的 Map。使用`Map<K, V> emptyMap()`\n- LinkedHashMap，要求key按照，put顺序存储时使用。\n- IdentityHashMap，kv的查找关系不是equals，而是==。即java的地址查找，只有序列化框架可能会用到，业务开发一般用不到。\n\n\n\n#### 线程安全\n\n- concurrenthashmap，中规中矩，默认使用。\n\n- hashtable，当必须保证强一致性时使用。concurrenthashmap中的get、size 等方法没有用到锁，有可能获得旧的数据。\n\n- concurrentSkipListMap，超大数据量(万级别)时候使用，且存在大量增删改操作的时候使用，在高并发下，跳表性能表现反超 concurrenthashmap。（红黑树在并发情况下，删除和插入过程中有个平衡的过程，锁竞争度会升高几个级别）\n\n  \n\n\n### map的使用注意事项\n\n- 强制，k一定使用字符串，不允许用对象。（和equals方法有关，不展开）\n- 默认，kv都尽量不允许为null。并发容器，k一定不允许为null，可能报npe不说，主要是没有意义。\n\n| 集合类                | key<br>是否为null | value<br>是否为null | 是否线程安全 |\n| --------------------- | ----------------- | ------------------- | ------------ |\n| HashMap               | 允许l             | 允许                | 否           |\n| TreeMap               | 不允许            | 允许                | 否           |\n| LinkedHashMap         | 允许              | 允许                | 否           |\n| EnumMap               | 不允许            | 允许                | 否           |\n|                       |                   |                     |              |\n| HashTable             | 不允许            | 不允许              | 是           |\n| ConcurrentHashMap     | 不允许            | 不允许              | 是           |\n| ConcurrentSkipListMap | 不允许            | 不允许              | 是           |\n\n\n\n------\n\n\n\n### List\n\n\n\n#### 线程不安全\n\n- 默认情况下一律使用ArrayList\n- 有去重需要，默认使用HashSet\n- 去重 + 重新排序使用TreeSet。\n- web开发中经常需要空 List。使用 `Collections.emptyList();`\n- LinkedList，随机读性能很烂，业务开发没有使用场景，不建议使用\n\n\n\n#### 线程安全\n\n- 线程安全List，首选 `Colletcions.synchronizedList(new ArrayList<>());` 各方面都没有问题。\n- 线程安全Set，JDK没有提供，可以使用hutool实现的 [线程安全的HashSet-ConcurrentHashSet](https://www.hutool.cn/docs/#/core/集合类/线程安全的HashSet-ConcurrentHashSet?id=线程安全的hashset-concurrenthashset)\n- 线程安全的队列，使用hutool实现的，[有界优先队列-BoundedPriorityQueue](https://www.hutool.cn/docs/#/core/集合类/有界优先队列-BoundedPriorityQueue?id=有界优先队列-boundedpriorityqueue)\n- DelayQueue 延时队列，一般情况下不会使用，非要使用，切记不能使用纳秒为单位。<br>（纳秒会让cpu负载上升几个数量将）\n- CopyOnWriteArrayList 并发版ArrayList，这个容器写成本非常高，一般没有使用场景，如需并发写，ArrayList加锁即可。\n\n\n\n### List的使用注意事项\n\n| 集合类               | value<br/>是否为null | 是否线程安全 |\n| -------------------- | -------------------- | ------------ |\n| ArrayList            | 允许                 | 否           |\n| HashSet              | 允许                 | 否           |\n| TreeSet              | 不允许               | 否           |\n| LinkedList           | 允许                 | 否           |\n|                      |                      |              |\n| HashTable            | 允许                 | 是           |\n| ConcurrentHashSet    | 允许                 | 是           |\n| BoundedPriorityQueue | 允许                 | 是           |\n| DelayQueue           | 允许                 | 是           |\n| CopyOnWriteArrayList | 允许                 | 是           |\n\n","slug":"写代码避坑指南/写代码避坑指南【1】java_集合","published":1,"updated":"2021-08-02T17:27:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmu000ocpfy22pl2lvc","content":"<p>我们从常用的“坑”出发，给你一个简单的避坑小抄，具体原因先不展开，只用一句话提示。</p>\n<p>本节主要讲的是 java 容器类常见的坑。</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"写java避坑指南1有关collect包\"> 写java避坑指南【1】有关collect包</span></h2>\n<h3><span id=\"map\"> Map</span></h3>\n<h4><span id=\"线程不安全\"> 线程不安全</span></h4>\n<ul>\n<li>\n<p>多线程中，使用线程不安全的容器，后果不仅仅是数据不对，还可能导致程序死循环。所以还是不能无脑使用现成不安全的容器。</p>\n</li>\n<li>\n<p>HashMap，中规中矩，默认使用。</p>\n</li>\n<li>\n<p>Treemap，实现了SortedMap，放入的Key必须实现<code>Comparable</code>接口，有key排序首选使用。</p>\n</li>\n<li>\n<p>EnumMap，如果作为key的对象是enum类型，首选使用，效率很高。</p>\n</li>\n<li>\n<p>web开发中也需要空的 Map。使用<code>Map&lt;K, V&gt; emptyMap()</code></p>\n</li>\n<li>\n<p>LinkedHashMap，要求key按照，put顺序存储时使用。</p>\n</li>\n<li>\n<p>IdentityHashMap，kv的查找关系不是equals，而是==。即java的地址查找，只有序列化框架可能会用到，业务开发一般用不到。</p>\n</li>\n</ul>\n<h4><span id=\"线程安全\"> 线程安全</span></h4>\n<ul>\n<li>\n<p>concurrenthashmap，中规中矩，默认使用。</p>\n</li>\n<li>\n<p>hashtable，当必须保证强一致性时使用。concurrenthashmap中的get、size 等方法没有用到锁，有可能获得旧的数据。</p>\n</li>\n<li>\n<p>concurrentSkipListMap，超大数据量(万级别)时候使用，且存在大量增删改操作的时候使用，在高并发下，跳表性能表现反超 concurrenthashmap。（红黑树在并发情况下，删除和插入过程中有个平衡的过程，锁竞争度会升高几个级别）</p>\n</li>\n</ul>\n<h3><span id=\"map的使用注意事项\"> map的使用注意事项</span></h3>\n<ul>\n<li>强制，k一定使用字符串，不允许用对象。（和equals方法有关，不展开）</li>\n<li>默认，kv都尽量不允许为null。并发容器，k一定不允许为null，可能报npe不说，主要是没有意义。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>集合类</th>\n<th>key<br>是否为null</th>\n<th>value<br>是否为null</th>\n<th>是否线程安全</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>HashMap</td>\n<td>允许l</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>TreeMap</td>\n<td>不允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>LinkedHashMap</td>\n<td>允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>EnumMap</td>\n<td>不允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>HashTable</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentHashMap</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentSkipListMap</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3><span id=\"list\"> List</span></h3>\n<h4><span id=\"线程不安全\"> 线程不安全</span></h4>\n<ul>\n<li>默认情况下一律使用ArrayList</li>\n<li>有去重需要，默认使用HashSet</li>\n<li>去重 + 重新排序使用TreeSet。</li>\n<li>web开发中经常需要空 List。使用 <code>Collections.emptyList();</code></li>\n<li>LinkedList，随机读性能很烂，业务开发没有使用场景，不建议使用</li>\n</ul>\n<h4><span id=\"线程安全\"> 线程安全</span></h4>\n<ul>\n<li>线程安全List，首选 <code>Colletcions.synchronizedList(new ArrayList&lt;&gt;());</code> 各方面都没有问题。</li>\n<li>线程安全Set，JDK没有提供，可以使用hutool实现的 <a href=\"https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84HashSet-ConcurrentHashSet?id=%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84hashset-concurrenthashset\">线程安全的HashSet-ConcurrentHashSet</a></li>\n<li>线程安全的队列，使用hutool实现的，<a href=\"https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-BoundedPriorityQueue?id=%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-boundedpriorityqueue\">有界优先队列-BoundedPriorityQueue</a></li>\n<li>DelayQueue 延时队列，一般情况下不会使用，非要使用，切记不能使用纳秒为单位。<br>（纳秒会让cpu负载上升几个数量将）</li>\n<li>CopyOnWriteArrayList 并发版ArrayList，这个容器写成本非常高，一般没有使用场景，如需并发写，ArrayList加锁即可。</li>\n</ul>\n<h3><span id=\"list的使用注意事项\"> List的使用注意事项</span></h3>\n<table>\n<thead>\n<tr>\n<th>集合类</th>\n<th>value<br>是否为null</th>\n<th>是否线程安全</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ArrayList</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>HashSet</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>TreeSet</td>\n<td>不允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>LinkedList</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>HashTable</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentHashSet</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>BoundedPriorityQueue</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>DelayQueue</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>CopyOnWriteArrayList</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n</tbody>\n</table>\n","site":{"data":{}},"excerpt":"<p>我们从常用的“坑”出发，给你一个简单的避坑小抄，具体原因先不展开，只用一句话提示。</p>\n<p>本节主要讲的是 java 容器类常见的坑。</p>","more":"<hr />\n<h2 id=\"写java避坑指南1有关collect包\"><a class=\"markdownIt-Anchor\" href=\"#写java避坑指南1有关collect包\"></a> 写java避坑指南【1】有关collect包</h2>\n<h3 id=\"map\"><a class=\"markdownIt-Anchor\" href=\"#map\"></a> Map</h3>\n<h4 id=\"线程不安全\"><a class=\"markdownIt-Anchor\" href=\"#线程不安全\"></a> 线程不安全</h4>\n<ul>\n<li>\n<p>多线程中，使用线程不安全的容器，后果不仅仅是数据不对，还可能导致程序死循环。所以还是不能无脑使用现成不安全的容器。</p>\n</li>\n<li>\n<p>HashMap，中规中矩，默认使用。</p>\n</li>\n<li>\n<p>Treemap，实现了SortedMap，放入的Key必须实现<code>Comparable</code>接口，有key排序首选使用。</p>\n</li>\n<li>\n<p>EnumMap，如果作为key的对象是enum类型，首选使用，效率很高。</p>\n</li>\n<li>\n<p>web开发中也需要空的 Map。使用<code>Map&lt;K, V&gt; emptyMap()</code></p>\n</li>\n<li>\n<p>LinkedHashMap，要求key按照，put顺序存储时使用。</p>\n</li>\n<li>\n<p>IdentityHashMap，kv的查找关系不是equals，而是==。即java的地址查找，只有序列化框架可能会用到，业务开发一般用不到。</p>\n</li>\n</ul>\n<h4 id=\"线程安全\"><a class=\"markdownIt-Anchor\" href=\"#线程安全\"></a> 线程安全</h4>\n<ul>\n<li>\n<p>concurrenthashmap，中规中矩，默认使用。</p>\n</li>\n<li>\n<p>hashtable，当必须保证强一致性时使用。concurrenthashmap中的get、size 等方法没有用到锁，有可能获得旧的数据。</p>\n</li>\n<li>\n<p>concurrentSkipListMap，超大数据量(万级别)时候使用，且存在大量增删改操作的时候使用，在高并发下，跳表性能表现反超 concurrenthashmap。（红黑树在并发情况下，删除和插入过程中有个平衡的过程，锁竞争度会升高几个级别）</p>\n</li>\n</ul>\n<h3 id=\"map的使用注意事项\"><a class=\"markdownIt-Anchor\" href=\"#map的使用注意事项\"></a> map的使用注意事项</h3>\n<ul>\n<li>强制，k一定使用字符串，不允许用对象。（和equals方法有关，不展开）</li>\n<li>默认，kv都尽量不允许为null。并发容器，k一定不允许为null，可能报npe不说，主要是没有意义。</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>集合类</th>\n<th>key<br>是否为null</th>\n<th>value<br>是否为null</th>\n<th>是否线程安全</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>HashMap</td>\n<td>允许l</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>TreeMap</td>\n<td>不允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>LinkedHashMap</td>\n<td>允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>EnumMap</td>\n<td>不允许</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>HashTable</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentHashMap</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentSkipListMap</td>\n<td>不允许</td>\n<td>不允许</td>\n<td>是</td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h3 id=\"list\"><a class=\"markdownIt-Anchor\" href=\"#list\"></a> List</h3>\n<h4 id=\"线程不安全-2\"><a class=\"markdownIt-Anchor\" href=\"#线程不安全-2\"></a> 线程不安全</h4>\n<ul>\n<li>默认情况下一律使用ArrayList</li>\n<li>有去重需要，默认使用HashSet</li>\n<li>去重 + 重新排序使用TreeSet。</li>\n<li>web开发中经常需要空 List。使用 <code>Collections.emptyList();</code></li>\n<li>LinkedList，随机读性能很烂，业务开发没有使用场景，不建议使用</li>\n</ul>\n<h4 id=\"线程安全-2\"><a class=\"markdownIt-Anchor\" href=\"#线程安全-2\"></a> 线程安全</h4>\n<ul>\n<li>线程安全List，首选 <code>Colletcions.synchronizedList(new ArrayList&lt;&gt;());</code> 各方面都没有问题。</li>\n<li>线程安全Set，JDK没有提供，可以使用hutool实现的 <a href=\"https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84HashSet-ConcurrentHashSet?id=%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84hashset-concurrenthashset\">线程安全的HashSet-ConcurrentHashSet</a></li>\n<li>线程安全的队列，使用hutool实现的，<a href=\"https://www.hutool.cn/docs/#/core/%E9%9B%86%E5%90%88%E7%B1%BB/%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-BoundedPriorityQueue?id=%E6%9C%89%E7%95%8C%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97-boundedpriorityqueue\">有界优先队列-BoundedPriorityQueue</a></li>\n<li>DelayQueue 延时队列，一般情况下不会使用，非要使用，切记不能使用纳秒为单位。<br>（纳秒会让cpu负载上升几个数量将）</li>\n<li>CopyOnWriteArrayList 并发版ArrayList，这个容器写成本非常高，一般没有使用场景，如需并发写，ArrayList加锁即可。</li>\n</ul>\n<h3 id=\"list的使用注意事项\"><a class=\"markdownIt-Anchor\" href=\"#list的使用注意事项\"></a> List的使用注意事项</h3>\n<table>\n<thead>\n<tr>\n<th>集合类</th>\n<th>value<br/>是否为null</th>\n<th>是否线程安全</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ArrayList</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>HashSet</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>TreeSet</td>\n<td>不允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td>LinkedList</td>\n<td>允许</td>\n<td>否</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>HashTable</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>ConcurrentHashSet</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>BoundedPriorityQueue</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>DelayQueue</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n<tr>\n<td>CopyOnWriteArrayList</td>\n<td>允许</td>\n<td>是</td>\n</tr>\n</tbody>\n</table>"},{"title":"mysql开发规范","date":"2021-07-27T14:53:44.000Z","toc":true,"hide":false,"_content":"\n\n\nhttp设计规范，设计接口后，可以对照自查表自省一下。\n\n<!-- more -->\n\n------\n\n\n\n## **建表规范**\n\n\n\n1. 默认使用使用innoDB 引擎，字符集 utf8mb4\n2. 表名称规范<br>`[biz]_xxxx_[app|mis]_conf` : 在线、离线服务配置。 <br>`[biz]_xxxx_record` : 数据表，最高优先级。<br>`[biz]_xxxx_[app|mis]log` : 日志表，低优先级\n3. 所有字段 NOT NULL ，优先设置 unsigned，小数设置为decimal，金额存成分，时间设置为datatime\n4. 字段最大长度，保存克制，防止建索引时空间不够。\n5. 字段长度大于1024需要拆分表，使用text， 主表上存拆分表id。\n6. 表示 “是否” 字段，一律使用 if_xxx 的方式命名，数据类型是unsigned tinyint\n7. 日增10万，年增5000万，id使用bigint，雪花算法。其余情况使用integer自增主键\n8. 字段顺序依次为：主键、业务主键、状态、各种外键、各种分类、具体props、base属性… <br>正确示例：id，order_id，order_status，product_id，user_id，order_time\n9. 保留名称，show、update、desc、status、range、match、delayed\n10. 推荐：单表最大长度小于2000万，单行长度小于16Kb，单表小于2g\n\n\n\n\n\n## **索引规范**\n\n1. 联合索引的字段数目不能超过5，单表索引数量也不能超过5，索引设计遵循B+ Tree最左前匹配原则\n2. 对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引  \n3. 根据业务命名空间的顺序构造联合索引，比如 productId/userId/serviceId/time/xxx\n4. order by ， group by 的字段需要建立索引，尽量不使用groupby，orderby 使用java进程完成此操作\n5. 业务上的全局唯一字段，需要建立唯一索引\n6. 事物中，如 SELECT * FROM yes WHERE name ='yes' FOR UPDATE; <br>通过等普通条件判断【name = xxx】进行筛选加锁时，则该列（name）需要加索引。否则容易锁表。\n7. 索引是要建在尽量不改动的字段上，频繁的变动索引列，对系统压力较大\n\n\n\n\n\n\n## **SQL开发规范**\n\n1. 对于 java 程序，只能使用 sql 模板查询，不允许使用各类动态sql生成器。\n\n2. 强烈推荐：只使用 mybatis_code_helper_pro 生成 xml sql 语句。\n\n3. 对外在线接口：<br>使用短sql，禁止三个表 join，禁止 where 子句，禁止 sql 函数。<br>对外接口尽量避免复杂查询，查询首先保证拓展性。\n\n4. 推荐：使用mysql执行计划验收sql语句，注意索引的有序性，尽量使用覆盖索引。\n\n5. 事务避免本类调用，使用hutool，SpringUtil获取事务方法。<br>直接使用传统 commit 指令也是不错的选择。\n\n6. 超过10万行数据，首先确定分页的必要性；能否转换为下拉查询，或时间查询。<br>必须精确分页的话，查询使用 inner join\n\n   ```sql\n   select * from tables inner join\n   ( select id from tables where [条件]  order by xxx limie 10000,10 )\n   using id;\n   ```\n\n\n\n\n\n##  **分库分表后查询规范**\n\n- 禁用语句\n\n\n1. 分表后尽量只查询，或者根据 id update，避免范围修改，严禁莽撞的跨区修改。\n2. 禁止，子查询，group by，order by\n3. 禁止，悲观锁，使用Redisson替代数据库悲观锁（尽量使用无锁方法处理业务逻辑）。\n4. 禁止，update sharding-key。update 分片键后可能会导致后面的查询找不到数据。\n5. 禁止，跨区 update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，造成过多删除。\n\n","source":"_posts/技术规范/mysql开发规范.md","raw":"---\ntitle: mysql开发规范\ndate: 2021-07-27 22:53:44\ntoc: true \n\ncategories:\n- 后端\n\ntags:\n- mysql\n- 技术规范\n- 设计\n\nhide: false\n---\n\n\n\nhttp设计规范，设计接口后，可以对照自查表自省一下。\n\n<!-- more -->\n\n------\n\n\n\n## **建表规范**\n\n\n\n1. 默认使用使用innoDB 引擎，字符集 utf8mb4\n2. 表名称规范<br>`[biz]_xxxx_[app|mis]_conf` : 在线、离线服务配置。 <br>`[biz]_xxxx_record` : 数据表，最高优先级。<br>`[biz]_xxxx_[app|mis]log` : 日志表，低优先级\n3. 所有字段 NOT NULL ，优先设置 unsigned，小数设置为decimal，金额存成分，时间设置为datatime\n4. 字段最大长度，保存克制，防止建索引时空间不够。\n5. 字段长度大于1024需要拆分表，使用text， 主表上存拆分表id。\n6. 表示 “是否” 字段，一律使用 if_xxx 的方式命名，数据类型是unsigned tinyint\n7. 日增10万，年增5000万，id使用bigint，雪花算法。其余情况使用integer自增主键\n8. 字段顺序依次为：主键、业务主键、状态、各种外键、各种分类、具体props、base属性… <br>正确示例：id，order_id，order_status，product_id，user_id，order_time\n9. 保留名称，show、update、desc、status、range、match、delayed\n10. 推荐：单表最大长度小于2000万，单行长度小于16Kb，单表小于2g\n\n\n\n\n\n## **索引规范**\n\n1. 联合索引的字段数目不能超过5，单表索引数量也不能超过5，索引设计遵循B+ Tree最左前匹配原则\n2. 对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引  \n3. 根据业务命名空间的顺序构造联合索引，比如 productId/userId/serviceId/time/xxx\n4. order by ， group by 的字段需要建立索引，尽量不使用groupby，orderby 使用java进程完成此操作\n5. 业务上的全局唯一字段，需要建立唯一索引\n6. 事物中，如 SELECT * FROM yes WHERE name ='yes' FOR UPDATE; <br>通过等普通条件判断【name = xxx】进行筛选加锁时，则该列（name）需要加索引。否则容易锁表。\n7. 索引是要建在尽量不改动的字段上，频繁的变动索引列，对系统压力较大\n\n\n\n\n\n\n## **SQL开发规范**\n\n1. 对于 java 程序，只能使用 sql 模板查询，不允许使用各类动态sql生成器。\n\n2. 强烈推荐：只使用 mybatis_code_helper_pro 生成 xml sql 语句。\n\n3. 对外在线接口：<br>使用短sql，禁止三个表 join，禁止 where 子句，禁止 sql 函数。<br>对外接口尽量避免复杂查询，查询首先保证拓展性。\n\n4. 推荐：使用mysql执行计划验收sql语句，注意索引的有序性，尽量使用覆盖索引。\n\n5. 事务避免本类调用，使用hutool，SpringUtil获取事务方法。<br>直接使用传统 commit 指令也是不错的选择。\n\n6. 超过10万行数据，首先确定分页的必要性；能否转换为下拉查询，或时间查询。<br>必须精确分页的话，查询使用 inner join\n\n   ```sql\n   select * from tables inner join\n   ( select id from tables where [条件]  order by xxx limie 10000,10 )\n   using id;\n   ```\n\n\n\n\n\n##  **分库分表后查询规范**\n\n- 禁用语句\n\n\n1. 分表后尽量只查询，或者根据 id update，避免范围修改，严禁莽撞的跨区修改。\n2. 禁止，子查询，group by，order by\n3. 禁止，悲观锁，使用Redisson替代数据库悲观锁（尽量使用无锁方法处理业务逻辑）。\n4. 禁止，update sharding-key。update 分片键后可能会导致后面的查询找不到数据。\n5. 禁止，跨区 update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，造成过多删除。\n\n","slug":"技术规范/mysql开发规范","published":1,"updated":"2021-07-27T14:53:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmv000qcpfy8ramf0l1","content":"<p>http设计规范，设计接口后，可以对照自查表自省一下。</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"建表规范\"> <strong>建表规范</strong></span></h2>\n<ol>\n<li>默认使用使用innoDB 引擎，字符集 utf8mb4</li>\n<li>表名称规范<br><code>[biz]_xxxx_[app|mis]_conf</code> : 在线、离线服务配置。 <br><code>[biz]_xxxx_record</code> : 数据表，最高优先级。<br><code>[biz]_xxxx_[app|mis]log</code> : 日志表，低优先级</li>\n<li>所有字段 NOT NULL ，优先设置 unsigned，小数设置为decimal，金额存成分，时间设置为datatime</li>\n<li>字段最大长度，保存克制，防止建索引时空间不够。</li>\n<li>字段长度大于1024需要拆分表，使用text， 主表上存拆分表id。</li>\n<li>表示 “是否” 字段，一律使用 if_xxx 的方式命名，数据类型是unsigned tinyint</li>\n<li>日增10万，年增5000万，id使用bigint，雪花算法。其余情况使用integer自增主键</li>\n<li>字段顺序依次为：主键、业务主键、状态、各种外键、各种分类、具体props、base属性… <br>正确示例：id，order_id，order_status，product_id，user_id，order_time</li>\n<li>保留名称，show、update、desc、status、range、match、delayed</li>\n<li>推荐：单表最大长度小于2000万，单行长度小于16Kb，单表小于2g</li>\n</ol>\n<h2><span id=\"索引规范\"> <strong>索引规范</strong></span></h2>\n<ol>\n<li>联合索引的字段数目不能超过5，单表索引数量也不能超过5，索引设计遵循B+ Tree最左前匹配原则</li>\n<li>对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引</li>\n<li>根据业务命名空间的顺序构造联合索引，比如 productId/userId/serviceId/time/xxx</li>\n<li>order by ， group by 的字段需要建立索引，尽量不使用groupby，orderby 使用java进程完成此操作</li>\n<li>业务上的全局唯一字段，需要建立唯一索引</li>\n<li>事物中，如 SELECT * FROM yes WHERE name =‘yes’ FOR UPDATE; <br>通过等普通条件判断【name = xxx】进行筛选加锁时，则该列（name）需要加索引。否则容易锁表。</li>\n<li>索引是要建在尽量不改动的字段上，频繁的变动索引列，对系统压力较大</li>\n</ol>\n<h2><span id=\"sql开发规范\"> <strong>SQL开发规范</strong></span></h2>\n<ol>\n<li>\n<p>对于 java 程序，只能使用 sql 模板查询，不允许使用各类动态sql生成器。</p>\n</li>\n<li>\n<p>强烈推荐：只使用 mybatis_code_helper_pro 生成 xml sql 语句。</p>\n</li>\n<li>\n<p>对外在线接口：<br>使用短sql，禁止三个表 join，禁止 where 子句，禁止 sql 函数。<br>对外接口尽量避免复杂查询，查询首先保证拓展性。</p>\n</li>\n<li>\n<p>推荐：使用mysql执行计划验收sql语句，注意索引的有序性，尽量使用覆盖索引。</p>\n</li>\n<li>\n<p>事务避免本类调用，使用hutool，SpringUtil获取事务方法。<br>直接使用传统 commit 指令也是不错的选择。</p>\n</li>\n<li>\n<p>超过10万行数据，首先确定分页的必要性；能否转换为下拉查询，或时间查询。<br>必须精确分页的话，查询使用 inner join</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs sql\"><span class=\"hljs-keyword\">select</span> <span class=\"hljs-operator\">*</span> <span class=\"hljs-keyword\">from</span> tables <span class=\"hljs-keyword\">inner</span> <span class=\"hljs-keyword\">join</span><br>( <span class=\"hljs-keyword\">select</span> id <span class=\"hljs-keyword\">from</span> tables <span class=\"hljs-keyword\">where</span> [条件]  <span class=\"hljs-keyword\">order</span> <span class=\"hljs-keyword\">by</span> xxx limie <span class=\"hljs-number\">10000</span>,<span class=\"hljs-number\">10</span> )<br><span class=\"hljs-keyword\">using</span> id;<br></code></pre></div></td></tr></table></figure>\n</li>\n</ol>\n<h2><span id=\"分库分表后查询规范\"> <strong>分库分表后查询规范</strong></span></h2>\n<ul>\n<li>禁用语句</li>\n</ul>\n<ol>\n<li>分表后尽量只查询，或者根据 id update，避免范围修改，严禁莽撞的跨区修改。</li>\n<li>禁止，子查询，group by，order by</li>\n<li>禁止，悲观锁，使用Redisson替代数据库悲观锁（尽量使用无锁方法处理业务逻辑）。</li>\n<li>禁止，update sharding-key。update 分片键后可能会导致后面的查询找不到数据。</li>\n<li>禁止，跨区 update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，造成过多删除。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>http设计规范，设计接口后，可以对照自查表自省一下。</p>","more":"<hr />\n<h2 id=\"建表规范\"><a class=\"markdownIt-Anchor\" href=\"#建表规范\"></a> <strong>建表规范</strong></h2>\n<ol>\n<li>默认使用使用innoDB 引擎，字符集 utf8mb4</li>\n<li>表名称规范<br><code>[biz]_xxxx_[app|mis]_conf</code> : 在线、离线服务配置。 <br><code>[biz]_xxxx_record</code> : 数据表，最高优先级。<br><code>[biz]_xxxx_[app|mis]log</code> : 日志表，低优先级</li>\n<li>所有字段 NOT NULL ，优先设置 unsigned，小数设置为decimal，金额存成分，时间设置为datatime</li>\n<li>字段最大长度，保存克制，防止建索引时空间不够。</li>\n<li>字段长度大于1024需要拆分表，使用text， 主表上存拆分表id。</li>\n<li>表示 “是否” 字段，一律使用 if_xxx 的方式命名，数据类型是unsigned tinyint</li>\n<li>日增10万，年增5000万，id使用bigint，雪花算法。其余情况使用integer自增主键</li>\n<li>字段顺序依次为：主键、业务主键、状态、各种外键、各种分类、具体props、base属性… <br>正确示例：id，order_id，order_status，product_id，user_id，order_time</li>\n<li>保留名称，show、update、desc、status、range、match、delayed</li>\n<li>推荐：单表最大长度小于2000万，单行长度小于16Kb，单表小于2g</li>\n</ol>\n<h2 id=\"索引规范\"><a class=\"markdownIt-Anchor\" href=\"#索引规范\"></a> <strong>索引规范</strong></h2>\n<ol>\n<li>联合索引的字段数目不能超过5，单表索引数量也不能超过5，索引设计遵循B+ Tree最左前匹配原则</li>\n<li>对一个VARCHAR(N)列创建索引时，通常取其50%（甚至更小）左右长度创建前缀索引就足以满足80%以上的查询需求了，没必要创建整列的全长度索引</li>\n<li>根据业务命名空间的顺序构造联合索引，比如 productId/userId/serviceId/time/xxx</li>\n<li>order by ， group by 的字段需要建立索引，尽量不使用groupby，orderby 使用java进程完成此操作</li>\n<li>业务上的全局唯一字段，需要建立唯一索引</li>\n<li>事物中，如 SELECT * FROM yes WHERE name =‘yes’ FOR UPDATE; <br>通过等普通条件判断【name = xxx】进行筛选加锁时，则该列（name）需要加索引。否则容易锁表。</li>\n<li>索引是要建在尽量不改动的字段上，频繁的变动索引列，对系统压力较大</li>\n</ol>\n<h2 id=\"sql开发规范\"><a class=\"markdownIt-Anchor\" href=\"#sql开发规范\"></a> <strong>SQL开发规范</strong></h2>\n<ol>\n<li>\n<p>对于 java 程序，只能使用 sql 模板查询，不允许使用各类动态sql生成器。</p>\n</li>\n<li>\n<p>强烈推荐：只使用 mybatis_code_helper_pro 生成 xml sql 语句。</p>\n</li>\n<li>\n<p>对外在线接口：<br>使用短sql，禁止三个表 join，禁止 where 子句，禁止 sql 函数。<br>对外接口尽量避免复杂查询，查询首先保证拓展性。</p>\n</li>\n<li>\n<p>推荐：使用mysql执行计划验收sql语句，注意索引的有序性，尽量使用覆盖索引。</p>\n</li>\n<li>\n<p>事务避免本类调用，使用hutool，SpringUtil获取事务方法。<br>直接使用传统 commit 指令也是不错的选择。</p>\n</li>\n<li>\n<p>超过10万行数据，首先确定分页的必要性；能否转换为下拉查询，或时间查询。<br>必须精确分页的话，查询使用 inner join</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs sql\"><span class=\"hljs-keyword\">select</span> <span class=\"hljs-operator\">*</span> <span class=\"hljs-keyword\">from</span> tables <span class=\"hljs-keyword\">inner</span> <span class=\"hljs-keyword\">join</span><br>( <span class=\"hljs-keyword\">select</span> id <span class=\"hljs-keyword\">from</span> tables <span class=\"hljs-keyword\">where</span> [条件]  <span class=\"hljs-keyword\">order</span> <span class=\"hljs-keyword\">by</span> xxx limie <span class=\"hljs-number\">10000</span>,<span class=\"hljs-number\">10</span> )<br><span class=\"hljs-keyword\">using</span> id;<br></code></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"分库分表后查询规范\"><a class=\"markdownIt-Anchor\" href=\"#分库分表后查询规范\"></a> <strong>分库分表后查询规范</strong></h2>\n<ul>\n<li>禁用语句</li>\n</ul>\n<ol>\n<li>分表后尽量只查询，或者根据 id update，避免范围修改，严禁莽撞的跨区修改。</li>\n<li>禁止，子查询，group by，order by</li>\n<li>禁止，悲观锁，使用Redisson替代数据库悲观锁（尽量使用无锁方法处理业务逻辑）。</li>\n<li>禁止，update sharding-key。update 分片键后可能会导致后面的查询找不到数据。</li>\n<li>禁止，跨区 update 、delete [order by] limit 。 mycat会在多个节点执行 limit语句，造成过多删除。</li>\n</ol>"},{"title":"API设计规范","date":"2021-07-29T19:05:15.000Z","toc":true,"hide":false,"_content":"\n\n\nhttp设计规范，设计接口后，可以对照自查表自省一下。\n\n<!-- more -->\n\n------\n\n\n\n## API设计自查表\n\n\n\n| 考虑点                                        | 结论 |\n| :-------------------------------------------- | ---- |\n| 接口命名                                      |      |\n| 入参                                          |      |\n| 出参                                          |      |\n| header                                        |      |\n| 包装结构体                                    |      |\n| 版本                                          |      |\n| 保障级别 （对内服务 or 对外服务 ｜ 使用人群） |      |\n| 是否需要黑白名单，哪个位置加                  |      |\n| 是否需要幂等，以及实现方案                    |      |\n| 是否需要异步，以及实现方案                    |      |\n\n\n\n\n\n------\n\n\n\n## 详细解释\n\n\n\n### 标准接口命名\n\n- 范例：<br>`xxx/user/p0/v1/getuserInfo`<br>业务线 / 所属服务 / 保护级别 / 版本 / getuserInfo\n\n- 禁止，PathVariable，不好管理，性能也有点问题<br>例如：/user/{user_id}\n\n- 禁止，除了 get、post 以外的method，网关不好管理\n\n- **保护级别**\n\n  - p0: 主流程接口，对外服务核心流程，一般此类接口挂了，用户就会发现系统有问题。<br>需要全力保障的接口\n  - p1: 非必要业务接口，一般是非核心查询接口，这类接口挂了，用户不容易察觉，<br>网关可以进行接口限流，根据user level 接口限流，也可以拿这类接口开刀。\n  - p2: 信息采集类接口，可以不用保证可用性，后端也永远返回成功，<br>服务资源不足时候，网关可以直接下掉他们。\n\n- 版本号\n\n  - 使用v1、v2即可\n\n  \n\n### header\n\n- jwt\n\n- 业务上下文，采集使用\n\n  如 user_id，client_id，client_type，biz，version，user_level，addr 等\n\n  按需添加\n\n- 调用链，trace_id，span_id，\n\n  一般由工具生成。\n\n\n\n### 入参\n\n- 对外服务公共参数\n\n  - 防篡改签名\n  - 加token\n\n  \n\n- 对内服务公共参数\n\n  - user_id\n  - biz_id\n  - service_id\n\n\n\n### 出参\n\n- 类型\n\n  强制使用 application/json 类型，尽量为字符串类型。\n\n  避免返回Long。\n\n  \n\n- 返回码\n\n  业务异常、系统异常要分开。<br>业务异常保证无歧义，系统异常返回码为99999，降级使用。<br>确保多重状态，有不同的返回码，<br>例如，有一个接口叫\"收单接口\"，其内部调用\"下单\"接口。<br>收单服务正常的时候，下单接口可能返回失败。<br>设计接口结构时，状态码不能有歧义，\"收单正常，下单失败\" 与 \"收单失败\"  返回不同的状态码\n\n  \n\n- 包装结构\n\n  错误返回：`{ code, msg, trace_id }`<br>正常返回：`{ code, msg, result: {} }` <br>分页返回：`{ code, msg, result: { recordList:[], page_info:{} } }`<br>**result 不允许为数组，默认为 空 {}，在java中使用 emptyMap 常量**\n\n  \n\n### 实现幂等的策略\n\n- 唯一id + 时间字段。通过时间过滤后，使用trans_id 避免重复 （最通用的实现）\n\n  可以加前置 缓存队列 ，进行专门的去重。\n\n- 新增类接口，加唯一索引。（低并发下，实现最简单）\n\n- 乐观锁字段。（效率最高，但大量并发时需要避免）\n\n- 服务端发放提交票据，（两次交互，费时费力，不推荐）\n\n- 状态机幂等， `set order_status = [done] ` 天生幂等 \n\n效率优先：乐观锁 > 唯一约束 > 唯一索引\n\n\n\n### 异步策略\n\n例如**上传接口**\n\n- 同步\n\n```java\npublic SyncUploadResponse syncUpload(SyncUploadRequest request) {\n  SyncUploadResponse response = new SyncUploadResponse();\n  response.setDownloadUrl(uploadFile(request.getFile()));\n  response.setThumbnailDownloadUrl(uploadThumbnailFile(request.getFile()));\n  return response;\n}\n```\n\n- 异步上传，立即返回一个任务id，客户端根据任务id轮询结果。\n\n  \n\n```java\n//在接口实现上，我们同样把上传任务提交到线程池处理，但是并不会同步等待任务完成，而是完成后把结果写入一个 HashMap，任务查询接口通过查询这个 HashMap 来获得文件 的 URL\npublic class asyncDemo {\n\n    //计数器，作为上传任务的ID\n    private AtomicInteger atomicInteger = new AtomicInteger(0);\n    //暂存上传操作的结果，生产代码需要考虑数据持久化\n    private ConcurrentHashMap<String, SyncQueryUploadTaskResponse> downloadUrl = new ConcurrentHashMap<>();\n\n    // 立即返回任务id\n    public AsyncUploadResponse asyncUpload(AsyncUploadRequest request) {\n        AsyncUploadResponse response = new AsyncUploadResponse();\n        //生成唯一的上传任务ID\n        String taskId = \"upload\" + atomicInteger.incrementAndGet\n        //异步上传操作只返回任务ID\n        response.setTaskId(taskId);\n        //提交上传原始文件操作到线程池异步处理\n        threadPool.execute(() -> {\n            String url = uploadFile(request.getFile());\n            //如果ConcurrentHashMap不包含Key，则初始化一个SyncQueryUploadTaskResponse\n            downloadUrl.computeIfAbsent(taskId,\n                    id -> new SyncQueryUploadTaskResponse(id)).setDownloadUrl(url);\n        });\n\n        //提交上传缩略图操作到线程池异步处理\n        threadPool.execute(() -> {\n            String url = uploadThumbnailFile(request.getFile());\n            downloadUrl.computeIfAbsent(taskId,\n                    id -> new SyncQueryUploadTaskResponse(id)).setThumbnailDownloadUrl(url);\n        });\n        return response;\n    }\n\n```\n\n","source":"_posts/技术规范/API设计规范.md","raw":"---\ntitle: API设计规范\ndate: 2021-07-30 03:05:15\ntoc: true\n\ncategories:\n  - 后端\n\ntags:\n  - 设计\n  - 技术规范\n\nhide: false\n\n---\n\n\n\nhttp设计规范，设计接口后，可以对照自查表自省一下。\n\n<!-- more -->\n\n------\n\n\n\n## API设计自查表\n\n\n\n| 考虑点                                        | 结论 |\n| :-------------------------------------------- | ---- |\n| 接口命名                                      |      |\n| 入参                                          |      |\n| 出参                                          |      |\n| header                                        |      |\n| 包装结构体                                    |      |\n| 版本                                          |      |\n| 保障级别 （对内服务 or 对外服务 ｜ 使用人群） |      |\n| 是否需要黑白名单，哪个位置加                  |      |\n| 是否需要幂等，以及实现方案                    |      |\n| 是否需要异步，以及实现方案                    |      |\n\n\n\n\n\n------\n\n\n\n## 详细解释\n\n\n\n### 标准接口命名\n\n- 范例：<br>`xxx/user/p0/v1/getuserInfo`<br>业务线 / 所属服务 / 保护级别 / 版本 / getuserInfo\n\n- 禁止，PathVariable，不好管理，性能也有点问题<br>例如：/user/{user_id}\n\n- 禁止，除了 get、post 以外的method，网关不好管理\n\n- **保护级别**\n\n  - p0: 主流程接口，对外服务核心流程，一般此类接口挂了，用户就会发现系统有问题。<br>需要全力保障的接口\n  - p1: 非必要业务接口，一般是非核心查询接口，这类接口挂了，用户不容易察觉，<br>网关可以进行接口限流，根据user level 接口限流，也可以拿这类接口开刀。\n  - p2: 信息采集类接口，可以不用保证可用性，后端也永远返回成功，<br>服务资源不足时候，网关可以直接下掉他们。\n\n- 版本号\n\n  - 使用v1、v2即可\n\n  \n\n### header\n\n- jwt\n\n- 业务上下文，采集使用\n\n  如 user_id，client_id，client_type，biz，version，user_level，addr 等\n\n  按需添加\n\n- 调用链，trace_id，span_id，\n\n  一般由工具生成。\n\n\n\n### 入参\n\n- 对外服务公共参数\n\n  - 防篡改签名\n  - 加token\n\n  \n\n- 对内服务公共参数\n\n  - user_id\n  - biz_id\n  - service_id\n\n\n\n### 出参\n\n- 类型\n\n  强制使用 application/json 类型，尽量为字符串类型。\n\n  避免返回Long。\n\n  \n\n- 返回码\n\n  业务异常、系统异常要分开。<br>业务异常保证无歧义，系统异常返回码为99999，降级使用。<br>确保多重状态，有不同的返回码，<br>例如，有一个接口叫\"收单接口\"，其内部调用\"下单\"接口。<br>收单服务正常的时候，下单接口可能返回失败。<br>设计接口结构时，状态码不能有歧义，\"收单正常，下单失败\" 与 \"收单失败\"  返回不同的状态码\n\n  \n\n- 包装结构\n\n  错误返回：`{ code, msg, trace_id }`<br>正常返回：`{ code, msg, result: {} }` <br>分页返回：`{ code, msg, result: { recordList:[], page_info:{} } }`<br>**result 不允许为数组，默认为 空 {}，在java中使用 emptyMap 常量**\n\n  \n\n### 实现幂等的策略\n\n- 唯一id + 时间字段。通过时间过滤后，使用trans_id 避免重复 （最通用的实现）\n\n  可以加前置 缓存队列 ，进行专门的去重。\n\n- 新增类接口，加唯一索引。（低并发下，实现最简单）\n\n- 乐观锁字段。（效率最高，但大量并发时需要避免）\n\n- 服务端发放提交票据，（两次交互，费时费力，不推荐）\n\n- 状态机幂等， `set order_status = [done] ` 天生幂等 \n\n效率优先：乐观锁 > 唯一约束 > 唯一索引\n\n\n\n### 异步策略\n\n例如**上传接口**\n\n- 同步\n\n```java\npublic SyncUploadResponse syncUpload(SyncUploadRequest request) {\n  SyncUploadResponse response = new SyncUploadResponse();\n  response.setDownloadUrl(uploadFile(request.getFile()));\n  response.setThumbnailDownloadUrl(uploadThumbnailFile(request.getFile()));\n  return response;\n}\n```\n\n- 异步上传，立即返回一个任务id，客户端根据任务id轮询结果。\n\n  \n\n```java\n//在接口实现上，我们同样把上传任务提交到线程池处理，但是并不会同步等待任务完成，而是完成后把结果写入一个 HashMap，任务查询接口通过查询这个 HashMap 来获得文件 的 URL\npublic class asyncDemo {\n\n    //计数器，作为上传任务的ID\n    private AtomicInteger atomicInteger = new AtomicInteger(0);\n    //暂存上传操作的结果，生产代码需要考虑数据持久化\n    private ConcurrentHashMap<String, SyncQueryUploadTaskResponse> downloadUrl = new ConcurrentHashMap<>();\n\n    // 立即返回任务id\n    public AsyncUploadResponse asyncUpload(AsyncUploadRequest request) {\n        AsyncUploadResponse response = new AsyncUploadResponse();\n        //生成唯一的上传任务ID\n        String taskId = \"upload\" + atomicInteger.incrementAndGet\n        //异步上传操作只返回任务ID\n        response.setTaskId(taskId);\n        //提交上传原始文件操作到线程池异步处理\n        threadPool.execute(() -> {\n            String url = uploadFile(request.getFile());\n            //如果ConcurrentHashMap不包含Key，则初始化一个SyncQueryUploadTaskResponse\n            downloadUrl.computeIfAbsent(taskId,\n                    id -> new SyncQueryUploadTaskResponse(id)).setDownloadUrl(url);\n        });\n\n        //提交上传缩略图操作到线程池异步处理\n        threadPool.execute(() -> {\n            String url = uploadThumbnailFile(request.getFile());\n            downloadUrl.computeIfAbsent(taskId,\n                    id -> new SyncQueryUploadTaskResponse(id)).setThumbnailDownloadUrl(url);\n        });\n        return response;\n    }\n\n```\n\n","slug":"技术规范/API设计规范","published":1,"updated":"2021-07-29T19:05:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmw000vcpfy8hvl9n97","content":"<p>http设计规范，设计接口后，可以对照自查表自省一下。</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"api设计自查表\"> API设计自查表</span></h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">考虑点</th>\n<th>结论</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">接口命名</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">入参</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">出参</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">header</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">包装结构体</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">版本</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">保障级别 （对内服务 or 对外服务 ｜ 使用人群）</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要黑白名单，哪个位置加</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要幂等，以及实现方案</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要异步，以及实现方案</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2><span id=\"详细解释\"> 详细解释</span></h2>\n<h3><span id=\"标准接口命名\"> 标准接口命名</span></h3>\n<ul>\n<li>\n<p>范例：<br><code>xxx/user/p0/v1/getuserInfo</code><br>业务线 / 所属服务 / 保护级别 / 版本 / getuserInfo</p>\n</li>\n<li>\n<p>禁止，PathVariable，不好管理，性能也有点问题<br>例如：/user/{user_id}</p>\n</li>\n<li>\n<p>禁止，除了 get、post 以外的method，网关不好管理</p>\n</li>\n<li>\n<p><strong>保护级别</strong></p>\n<ul>\n<li>p0: 主流程接口，对外服务核心流程，一般此类接口挂了，用户就会发现系统有问题。<br>需要全力保障的接口</li>\n<li>p1: 非必要业务接口，一般是非核心查询接口，这类接口挂了，用户不容易察觉，<br>网关可以进行接口限流，根据user level 接口限流，也可以拿这类接口开刀。</li>\n<li>p2: 信息采集类接口，可以不用保证可用性，后端也永远返回成功，<br>服务资源不足时候，网关可以直接下掉他们。</li>\n</ul>\n</li>\n<li>\n<p>版本号</p>\n<ul>\n<li>使用v1、v2即可</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"header\"> header</span></h3>\n<ul>\n<li>\n<p>jwt</p>\n</li>\n<li>\n<p>业务上下文，采集使用</p>\n<p>如 user_id，client_id，client_type，biz，version，user_level，addr 等</p>\n<p>按需添加</p>\n</li>\n<li>\n<p>调用链，trace_id，span_id，</p>\n<p>一般由工具生成。</p>\n</li>\n</ul>\n<h3><span id=\"入参\"> 入参</span></h3>\n<ul>\n<li>\n<p>对外服务公共参数</p>\n<ul>\n<li>防篡改签名</li>\n<li>加token</li>\n</ul>\n</li>\n<li>\n<p>对内服务公共参数</p>\n<ul>\n<li>user_id</li>\n<li>biz_id</li>\n<li>service_id</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"出参\"> 出参</span></h3>\n<ul>\n<li>\n<p>类型</p>\n<p>强制使用 application/json 类型，尽量为字符串类型。</p>\n<p>避免返回Long。</p>\n</li>\n<li>\n<p>返回码</p>\n<p>业务异常、系统异常要分开。<br>业务异常保证无歧义，系统异常返回码为99999，降级使用。<br>确保多重状态，有不同的返回码，<br>例如，有一个接口叫&quot;收单接口&quot;，其内部调用&quot;下单&quot;接口。<br>收单服务正常的时候，下单接口可能返回失败。<br>设计接口结构时，状态码不能有歧义，“收单正常，下单失败” 与 “收单失败”  返回不同的状态码</p>\n</li>\n<li>\n<p>包装结构</p>\n<p>错误返回：<code>&#123; code, msg, trace_id &#125;</code><br>正常返回：<code>&#123; code, msg, result: &#123;&#125; &#125;</code> <br>分页返回：<code>&#123; code, msg, result: &#123; recordList:[], page_info:&#123;&#125; &#125; &#125;</code><br><strong>result 不允许为数组，默认为 空 {}，在java中使用 emptyMap 常量</strong></p>\n</li>\n</ul>\n<h3><span id=\"实现幂等的策略\"> 实现幂等的策略</span></h3>\n<ul>\n<li>\n<p>唯一id + 时间字段。通过时间过滤后，使用trans_id 避免重复 （最通用的实现）</p>\n<p>可以加前置 缓存队列 ，进行专门的去重。</p>\n</li>\n<li>\n<p>新增类接口，加唯一索引。（低并发下，实现最简单）</p>\n</li>\n<li>\n<p>乐观锁字段。（效率最高，但大量并发时需要避免）</p>\n</li>\n<li>\n<p>服务端发放提交票据，（两次交互，费时费力，不推荐）</p>\n</li>\n<li>\n<p>状态机幂等， <code>set order_status = [done]</code> 天生幂等</p>\n</li>\n</ul>\n<p>效率优先：乐观锁 &gt; 唯一约束 &gt; 唯一索引</p>\n<h3><span id=\"异步策略\"> 异步策略</span></h3>\n<p>例如<strong>上传接口</strong></p>\n<ul>\n<li>同步</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> SyncUploadResponse <span class=\"hljs-title\">syncUpload</span><span class=\"hljs-params\">(SyncUploadRequest request)</span> </span>&#123;<br>  SyncUploadResponse response = <span class=\"hljs-keyword\">new</span> SyncUploadResponse();<br>  response.setDownloadUrl(uploadFile(request.getFile()));<br>  response.setThumbnailDownloadUrl(uploadThumbnailFile(request.getFile()));<br>  <span class=\"hljs-keyword\">return</span> response;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>异步上传，立即返回一个任务id，客户端根据任务id轮询结果。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//在接口实现上，我们同样把上传任务提交到线程池处理，但是并不会同步等待任务完成，而是完成后把结果写入一个 HashMap，任务查询接口通过查询这个 HashMap 来获得文件 的 URL</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">asyncDemo</span> </span>&#123;<br><br>    <span class=\"hljs-comment\">//计数器，作为上传任务的ID</span><br>    <span class=\"hljs-keyword\">private</span> AtomicInteger atomicInteger = <span class=\"hljs-keyword\">new</span> AtomicInteger(<span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-comment\">//暂存上传操作的结果，生产代码需要考虑数据持久化</span><br>    <span class=\"hljs-keyword\">private</span> ConcurrentHashMap&lt;String, SyncQueryUploadTaskResponse&gt; downloadUrl = <span class=\"hljs-keyword\">new</span> ConcurrentHashMap&lt;&gt;();<br><br>    <span class=\"hljs-comment\">// 立即返回任务id</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> AsyncUploadResponse <span class=\"hljs-title\">asyncUpload</span><span class=\"hljs-params\">(AsyncUploadRequest request)</span> </span>&#123;<br>        AsyncUploadResponse response = <span class=\"hljs-keyword\">new</span> AsyncUploadResponse();<br>        <span class=\"hljs-comment\">//生成唯一的上传任务ID</span><br>        String taskId = <span class=\"hljs-string\">&quot;upload&quot;</span> + atomicInteger.incrementAndGet<br>        <span class=\"hljs-comment\">//异步上传操作只返回任务ID</span><br>        response.setTaskId(taskId);<br>        <span class=\"hljs-comment\">//提交上传原始文件操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadFile(request.getFile());<br>            <span class=\"hljs-comment\">//如果ConcurrentHashMap不包含Key，则初始化一个SyncQueryUploadTaskResponse</span><br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class=\"hljs-keyword\">new</span> SyncQueryUploadTaskResponse(id)).setDownloadUrl(url);<br>        &#125;);<br><br>        <span class=\"hljs-comment\">//提交上传缩略图操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadThumbnailFile(request.getFile());<br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class=\"hljs-keyword\">new</span> SyncQueryUploadTaskResponse(id)).setThumbnailDownloadUrl(url);<br>        &#125;);<br>        <span class=\"hljs-keyword\">return</span> response;<br>    &#125;<br><br></code></pre></div></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>http设计规范，设计接口后，可以对照自查表自省一下。</p>","more":"<hr />\n<h2 id=\"api设计自查表\"><a class=\"markdownIt-Anchor\" href=\"#api设计自查表\"></a> API设计自查表</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">考虑点</th>\n<th>结论</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">接口命名</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">入参</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">出参</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">header</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">包装结构体</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">版本</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">保障级别 （对内服务 or 对外服务 ｜ 使用人群）</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要黑白名单，哪个位置加</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要幂等，以及实现方案</td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">是否需要异步，以及实现方案</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<hr />\n<h2 id=\"详细解释\"><a class=\"markdownIt-Anchor\" href=\"#详细解释\"></a> 详细解释</h2>\n<h3 id=\"标准接口命名\"><a class=\"markdownIt-Anchor\" href=\"#标准接口命名\"></a> 标准接口命名</h3>\n<ul>\n<li>\n<p>范例：<br><code>xxx/user/p0/v1/getuserInfo</code><br>业务线 / 所属服务 / 保护级别 / 版本 / getuserInfo</p>\n</li>\n<li>\n<p>禁止，PathVariable，不好管理，性能也有点问题<br>例如：/user/{user_id}</p>\n</li>\n<li>\n<p>禁止，除了 get、post 以外的method，网关不好管理</p>\n</li>\n<li>\n<p><strong>保护级别</strong></p>\n<ul>\n<li>p0: 主流程接口，对外服务核心流程，一般此类接口挂了，用户就会发现系统有问题。<br>需要全力保障的接口</li>\n<li>p1: 非必要业务接口，一般是非核心查询接口，这类接口挂了，用户不容易察觉，<br>网关可以进行接口限流，根据user level 接口限流，也可以拿这类接口开刀。</li>\n<li>p2: 信息采集类接口，可以不用保证可用性，后端也永远返回成功，<br>服务资源不足时候，网关可以直接下掉他们。</li>\n</ul>\n</li>\n<li>\n<p>版本号</p>\n<ul>\n<li>使用v1、v2即可</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"header\"><a class=\"markdownIt-Anchor\" href=\"#header\"></a> header</h3>\n<ul>\n<li>\n<p>jwt</p>\n</li>\n<li>\n<p>业务上下文，采集使用</p>\n<p>如 user_id，client_id，client_type，biz，version，user_level，addr 等</p>\n<p>按需添加</p>\n</li>\n<li>\n<p>调用链，trace_id，span_id，</p>\n<p>一般由工具生成。</p>\n</li>\n</ul>\n<h3 id=\"入参\"><a class=\"markdownIt-Anchor\" href=\"#入参\"></a> 入参</h3>\n<ul>\n<li>\n<p>对外服务公共参数</p>\n<ul>\n<li>防篡改签名</li>\n<li>加token</li>\n</ul>\n</li>\n<li>\n<p>对内服务公共参数</p>\n<ul>\n<li>user_id</li>\n<li>biz_id</li>\n<li>service_id</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"出参\"><a class=\"markdownIt-Anchor\" href=\"#出参\"></a> 出参</h3>\n<ul>\n<li>\n<p>类型</p>\n<p>强制使用 application/json 类型，尽量为字符串类型。</p>\n<p>避免返回Long。</p>\n</li>\n<li>\n<p>返回码</p>\n<p>业务异常、系统异常要分开。<br>业务异常保证无歧义，系统异常返回码为99999，降级使用。<br>确保多重状态，有不同的返回码，<br>例如，有一个接口叫&quot;收单接口&quot;，其内部调用&quot;下单&quot;接口。<br>收单服务正常的时候，下单接口可能返回失败。<br>设计接口结构时，状态码不能有歧义，“收单正常，下单失败” 与 “收单失败”  返回不同的状态码</p>\n</li>\n<li>\n<p>包装结构</p>\n<p>错误返回：<code>&#123; code, msg, trace_id &#125;</code><br>正常返回：<code>&#123; code, msg, result: &#123;&#125; &#125;</code> <br>分页返回：<code>&#123; code, msg, result: &#123; recordList:[], page_info:&#123;&#125; &#125; &#125;</code><br><strong>result 不允许为数组，默认为 空 {}，在java中使用 emptyMap 常量</strong></p>\n</li>\n</ul>\n<h3 id=\"实现幂等的策略\"><a class=\"markdownIt-Anchor\" href=\"#实现幂等的策略\"></a> 实现幂等的策略</h3>\n<ul>\n<li>\n<p>唯一id + 时间字段。通过时间过滤后，使用trans_id 避免重复 （最通用的实现）</p>\n<p>可以加前置 缓存队列 ，进行专门的去重。</p>\n</li>\n<li>\n<p>新增类接口，加唯一索引。（低并发下，实现最简单）</p>\n</li>\n<li>\n<p>乐观锁字段。（效率最高，但大量并发时需要避免）</p>\n</li>\n<li>\n<p>服务端发放提交票据，（两次交互，费时费力，不推荐）</p>\n</li>\n<li>\n<p>状态机幂等， <code>set order_status = [done]</code> 天生幂等</p>\n</li>\n</ul>\n<p>效率优先：乐观锁 &gt; 唯一约束 &gt; 唯一索引</p>\n<h3 id=\"异步策略\"><a class=\"markdownIt-Anchor\" href=\"#异步策略\"></a> 异步策略</h3>\n<p>例如<strong>上传接口</strong></p>\n<ul>\n<li>同步</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> SyncUploadResponse <span class=\"hljs-title\">syncUpload</span><span class=\"hljs-params\">(SyncUploadRequest request)</span> </span>&#123;<br>  SyncUploadResponse response = <span class=\"hljs-keyword\">new</span> SyncUploadResponse();<br>  response.setDownloadUrl(uploadFile(request.getFile()));<br>  response.setThumbnailDownloadUrl(uploadThumbnailFile(request.getFile()));<br>  <span class=\"hljs-keyword\">return</span> response;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>异步上传，立即返回一个任务id，客户端根据任务id轮询结果。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//在接口实现上，我们同样把上传任务提交到线程池处理，但是并不会同步等待任务完成，而是完成后把结果写入一个 HashMap，任务查询接口通过查询这个 HashMap 来获得文件 的 URL</span><br><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">asyncDemo</span> </span>&#123;<br><br>    <span class=\"hljs-comment\">//计数器，作为上传任务的ID</span><br>    <span class=\"hljs-keyword\">private</span> AtomicInteger atomicInteger = <span class=\"hljs-keyword\">new</span> AtomicInteger(<span class=\"hljs-number\">0</span>);<br>    <span class=\"hljs-comment\">//暂存上传操作的结果，生产代码需要考虑数据持久化</span><br>    <span class=\"hljs-keyword\">private</span> ConcurrentHashMap&lt;String, SyncQueryUploadTaskResponse&gt; downloadUrl = <span class=\"hljs-keyword\">new</span> ConcurrentHashMap&lt;&gt;();<br><br>    <span class=\"hljs-comment\">// 立即返回任务id</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> AsyncUploadResponse <span class=\"hljs-title\">asyncUpload</span><span class=\"hljs-params\">(AsyncUploadRequest request)</span> </span>&#123;<br>        AsyncUploadResponse response = <span class=\"hljs-keyword\">new</span> AsyncUploadResponse();<br>        <span class=\"hljs-comment\">//生成唯一的上传任务ID</span><br>        String taskId = <span class=\"hljs-string\">&quot;upload&quot;</span> + atomicInteger.incrementAndGet<br>        <span class=\"hljs-comment\">//异步上传操作只返回任务ID</span><br>        response.setTaskId(taskId);<br>        <span class=\"hljs-comment\">//提交上传原始文件操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadFile(request.getFile());<br>            <span class=\"hljs-comment\">//如果ConcurrentHashMap不包含Key，则初始化一个SyncQueryUploadTaskResponse</span><br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class=\"hljs-keyword\">new</span> SyncQueryUploadTaskResponse(id)).setDownloadUrl(url);<br>        &#125;);<br><br>        <span class=\"hljs-comment\">//提交上传缩略图操作到线程池异步处理</span><br>        threadPool.execute(() -&gt; &#123;<br>            String url = uploadThumbnailFile(request.getFile());<br>            downloadUrl.computeIfAbsent(taskId,<br>                    id -&gt; <span class=\"hljs-keyword\">new</span> SyncQueryUploadTaskResponse(id)).setThumbnailDownloadUrl(url);<br>        &#125;);<br>        <span class=\"hljs-keyword\">return</span> response;<br>    &#125;<br><br></code></pre></td></tr></table></figure>"},{"title":"分支规范","date":"2021-07-29T19:06:46.000Z","toc":true,"hide":false,"_content":"\n\n\n介绍一个分支模型 - AoneFlow。<br>已经使用1年，目前没遇到坑，用起来也比较舒服，优雅。\n<!-- more -->\n\n------\n\n\n\n## 分支规范\nAoneFlow：一种 TrunkBased 与 GitFlow  的折衷方案\n\n\n\n#### 三种分支类型\n- 主干分支 master tag: v1.2、 v1.3 <br>对应线上的当前代码，需要只读保护。\n- 发布分支 release/qa1、release/qa2… 、release/ prod <br>对应测试环境、预发环境上的代码（测试环境可能有很多个，有时候需要并行测试）<br>禁止直接push，仅支持merge request 后push\n- 特性分支 feature/001、feature/002<br>对应功能点分支。\n\n\n\n#### 组成\n一个master + N个 feature 分支 + N个 release 分支\n\n\n\n#### 工作流程\n1. 开始工作前，从master 创建特性分支 feature/001，开始开发。\n2. 开发完毕后，feature/001 提交 PR 到 release/qa， 此时开发者相互CR 其他人的 PR。\n3. CR完成后，合并所有PR，如果有冲突，重新提交无冲突的 PR，开始测试。\n4. 测试完毕后\n   1. 检查master 是否有更新，比如开发新特性的时候，master分支发生了hotfix。<br>如果有更新，则需要对 release/prod 进行回归测试。\n   2. 根据master 创新新分支 release/prod , 将 release/qa 合并到 release/prod\n5. 使用 release/prod merge 到 master <br>此时墙裂建议使用idea diff code 功能，整体看一下本次的合并，有没有额外的脏代码<br>合并后，添加 tag ，开始上线流程。\n6. 上线后，删除相关的 feature 分支，清理半年以前的tag，看日志，观察程序运行情况。\n\n\n\n#### 核心逻辑\n任何代码的改动，只能在feature 上push，其他分支的代码，如果需要响应改动<br>则通过 merge request 将变动传进来。\n\n\n\n#### 小痛点\n- 提交改动有点麻烦，每次都要在feature分支上提交后，在release分支上进行merge request\n- 这个模式的一个痛点，当n个f分支，n个release分支的时候<br>需要记住，n个feature分支，与release 分支间的对应关系。\n\n\n\n#### 工具\n- 阿里巴巴内部使用aone平台管理，对外发布的产品叫 [云效平台](https://help.aliyun.com/document_detail/153762.html?spm=5176.168087.J_7469444330.4.91376942pV1EvU)\n- 有赞qa平台，公交车发布系统，也借鉴了aoneFlow的思路[3.4 公交车系统](https://tech.youzan.com/team/)\n\n\n\n#### 参考介绍：\n- [项目版本管理的最佳实践：飞流Flow（阿里AoneFlow）篇](https://blog.csdn.net/bbcckkl/article/details/111087267)\n- [Git-flow分支管理与Aone-flow分支管理对比](https://blog.csdn.net/liumingzhe1/article/details/105287150)\n- [阿里巴巴如何管理代码分支？ ](https://www.infoq.cn/article/EaC4c6yiJrzZ_Gtaf9Ne)\n- [阿里巴巴在DevOps实践中的创新和思考-ppt ](http://bos.itdks.com/7b7b1baa2f1244b8b3c2b3ae26de3eea.pdf)\n\n","source":"_posts/技术规范/分支规范.md","raw":"---\ntitle: 分支规范\ndate: 2021-07-30 03:06:46\ntoc: true\n\ncategories:\n  - 后端\n\ntags:\n  - 设计\n  - 技术规范\n\n\nhide: false\n---\n\n\n\n介绍一个分支模型 - AoneFlow。<br>已经使用1年，目前没遇到坑，用起来也比较舒服，优雅。\n<!-- more -->\n\n------\n\n\n\n## 分支规范\nAoneFlow：一种 TrunkBased 与 GitFlow  的折衷方案\n\n\n\n#### 三种分支类型\n- 主干分支 master tag: v1.2、 v1.3 <br>对应线上的当前代码，需要只读保护。\n- 发布分支 release/qa1、release/qa2… 、release/ prod <br>对应测试环境、预发环境上的代码（测试环境可能有很多个，有时候需要并行测试）<br>禁止直接push，仅支持merge request 后push\n- 特性分支 feature/001、feature/002<br>对应功能点分支。\n\n\n\n#### 组成\n一个master + N个 feature 分支 + N个 release 分支\n\n\n\n#### 工作流程\n1. 开始工作前，从master 创建特性分支 feature/001，开始开发。\n2. 开发完毕后，feature/001 提交 PR 到 release/qa， 此时开发者相互CR 其他人的 PR。\n3. CR完成后，合并所有PR，如果有冲突，重新提交无冲突的 PR，开始测试。\n4. 测试完毕后\n   1. 检查master 是否有更新，比如开发新特性的时候，master分支发生了hotfix。<br>如果有更新，则需要对 release/prod 进行回归测试。\n   2. 根据master 创新新分支 release/prod , 将 release/qa 合并到 release/prod\n5. 使用 release/prod merge 到 master <br>此时墙裂建议使用idea diff code 功能，整体看一下本次的合并，有没有额外的脏代码<br>合并后，添加 tag ，开始上线流程。\n6. 上线后，删除相关的 feature 分支，清理半年以前的tag，看日志，观察程序运行情况。\n\n\n\n#### 核心逻辑\n任何代码的改动，只能在feature 上push，其他分支的代码，如果需要响应改动<br>则通过 merge request 将变动传进来。\n\n\n\n#### 小痛点\n- 提交改动有点麻烦，每次都要在feature分支上提交后，在release分支上进行merge request\n- 这个模式的一个痛点，当n个f分支，n个release分支的时候<br>需要记住，n个feature分支，与release 分支间的对应关系。\n\n\n\n#### 工具\n- 阿里巴巴内部使用aone平台管理，对外发布的产品叫 [云效平台](https://help.aliyun.com/document_detail/153762.html?spm=5176.168087.J_7469444330.4.91376942pV1EvU)\n- 有赞qa平台，公交车发布系统，也借鉴了aoneFlow的思路[3.4 公交车系统](https://tech.youzan.com/team/)\n\n\n\n#### 参考介绍：\n- [项目版本管理的最佳实践：飞流Flow（阿里AoneFlow）篇](https://blog.csdn.net/bbcckkl/article/details/111087267)\n- [Git-flow分支管理与Aone-flow分支管理对比](https://blog.csdn.net/liumingzhe1/article/details/105287150)\n- [阿里巴巴如何管理代码分支？ ](https://www.infoq.cn/article/EaC4c6yiJrzZ_Gtaf9Ne)\n- [阿里巴巴在DevOps实践中的创新和思考-ppt ](http://bos.itdks.com/7b7b1baa2f1244b8b3c2b3ae26de3eea.pdf)\n\n","slug":"技术规范/分支规范","published":1,"updated":"2021-07-29T19:06:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmx000xcpfy2rubfwcu","content":"<p>介绍一个分支模型 - AoneFlow。<br>已经使用1年，目前没遇到坑，用起来也比较舒服，优雅。</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"分支规范\"> 分支规范</span></h2>\n<p>AoneFlow：一种 TrunkBased 与 GitFlow  的折衷方案</p>\n<h4><span id=\"三种分支类型\"> 三种分支类型</span></h4>\n<ul>\n<li>主干分支 master tag: v1.2、 v1.3 <br>对应线上的当前代码，需要只读保护。</li>\n<li>发布分支 release/qa1、release/qa2… 、release/ prod <br>对应测试环境、预发环境上的代码（测试环境可能有很多个，有时候需要并行测试）<br>禁止直接push，仅支持merge request 后push</li>\n<li>特性分支 feature/001、feature/002<br>对应功能点分支。</li>\n</ul>\n<h4><span id=\"组成\"> 组成</span></h4>\n<p>一个master + N个 feature 分支 + N个 release 分支</p>\n<h4><span id=\"工作流程\"> 工作流程</span></h4>\n<ol>\n<li>开始工作前，从master 创建特性分支 feature/001，开始开发。</li>\n<li>开发完毕后，feature/001 提交 PR 到 release/qa， 此时开发者相互CR 其他人的 PR。</li>\n<li>CR完成后，合并所有PR，如果有冲突，重新提交无冲突的 PR，开始测试。</li>\n<li>测试完毕后\n<ol>\n<li>检查master 是否有更新，比如开发新特性的时候，master分支发生了hotfix。<br>如果有更新，则需要对 release/prod 进行回归测试。</li>\n<li>根据master 创新新分支 release/prod , 将 release/qa 合并到 release/prod</li>\n</ol>\n</li>\n<li>使用 release/prod merge 到 master <br>此时墙裂建议使用idea diff code 功能，整体看一下本次的合并，有没有额外的脏代码<br>合并后，添加 tag ，开始上线流程。</li>\n<li>上线后，删除相关的 feature 分支，清理半年以前的tag，看日志，观察程序运行情况。</li>\n</ol>\n<h4><span id=\"核心逻辑\"> 核心逻辑</span></h4>\n<p>任何代码的改动，只能在feature 上push，其他分支的代码，如果需要响应改动<br>则通过 merge request 将变动传进来。</p>\n<h4><span id=\"小痛点\"> 小痛点</span></h4>\n<ul>\n<li>提交改动有点麻烦，每次都要在feature分支上提交后，在release分支上进行merge request</li>\n<li>这个模式的一个痛点，当n个f分支，n个release分支的时候<br>需要记住，n个feature分支，与release 分支间的对应关系。</li>\n</ul>\n<h4><span id=\"工具\"> 工具</span></h4>\n<ul>\n<li>阿里巴巴内部使用aone平台管理，对外发布的产品叫 <a href=\"https://help.aliyun.com/document_detail/153762.html?spm=5176.168087.J_7469444330.4.91376942pV1EvU\">云效平台</a></li>\n<li>有赞qa平台，公交车发布系统，也借鉴了aoneFlow的思路<a href=\"https://tech.youzan.com/team/\">3.4 公交车系统</a></li>\n</ul>\n<h4><span id=\"参考介绍\"> 参考介绍：</span></h4>\n<ul>\n<li><a href=\"https://blog.csdn.net/bbcckkl/article/details/111087267\">项目版本管理的最佳实践：飞流Flow（阿里AoneFlow）篇</a></li>\n<li><a href=\"https://blog.csdn.net/liumingzhe1/article/details/105287150\">Git-flow分支管理与Aone-flow分支管理对比</a></li>\n<li><a href=\"https://www.infoq.cn/article/EaC4c6yiJrzZ_Gtaf9Ne\">阿里巴巴如何管理代码分支？ </a></li>\n<li><a href=\"http://bos.itdks.com/7b7b1baa2f1244b8b3c2b3ae26de3eea.pdf\">阿里巴巴在DevOps实践中的创新和思考-ppt </a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>介绍一个分支模型 - AoneFlow。<br>已经使用1年，目前没遇到坑，用起来也比较舒服，优雅。</p>","more":"<hr />\n<h2 id=\"分支规范\"><a class=\"markdownIt-Anchor\" href=\"#分支规范\"></a> 分支规范</h2>\n<p>AoneFlow：一种 TrunkBased 与 GitFlow  的折衷方案</p>\n<h4 id=\"三种分支类型\"><a class=\"markdownIt-Anchor\" href=\"#三种分支类型\"></a> 三种分支类型</h4>\n<ul>\n<li>主干分支 master tag: v1.2、 v1.3 <br>对应线上的当前代码，需要只读保护。</li>\n<li>发布分支 release/qa1、release/qa2… 、release/ prod <br>对应测试环境、预发环境上的代码（测试环境可能有很多个，有时候需要并行测试）<br>禁止直接push，仅支持merge request 后push</li>\n<li>特性分支 feature/001、feature/002<br>对应功能点分支。</li>\n</ul>\n<h4 id=\"组成\"><a class=\"markdownIt-Anchor\" href=\"#组成\"></a> 组成</h4>\n<p>一个master + N个 feature 分支 + N个 release 分支</p>\n<h4 id=\"工作流程\"><a class=\"markdownIt-Anchor\" href=\"#工作流程\"></a> 工作流程</h4>\n<ol>\n<li>开始工作前，从master 创建特性分支 feature/001，开始开发。</li>\n<li>开发完毕后，feature/001 提交 PR 到 release/qa， 此时开发者相互CR 其他人的 PR。</li>\n<li>CR完成后，合并所有PR，如果有冲突，重新提交无冲突的 PR，开始测试。</li>\n<li>测试完毕后\n<ol>\n<li>检查master 是否有更新，比如开发新特性的时候，master分支发生了hotfix。<br>如果有更新，则需要对 release/prod 进行回归测试。</li>\n<li>根据master 创新新分支 release/prod , 将 release/qa 合并到 release/prod</li>\n</ol>\n</li>\n<li>使用 release/prod merge 到 master <br>此时墙裂建议使用idea diff code 功能，整体看一下本次的合并，有没有额外的脏代码<br>合并后，添加 tag ，开始上线流程。</li>\n<li>上线后，删除相关的 feature 分支，清理半年以前的tag，看日志，观察程序运行情况。</li>\n</ol>\n<h4 id=\"核心逻辑\"><a class=\"markdownIt-Anchor\" href=\"#核心逻辑\"></a> 核心逻辑</h4>\n<p>任何代码的改动，只能在feature 上push，其他分支的代码，如果需要响应改动<br>则通过 merge request 将变动传进来。</p>\n<h4 id=\"小痛点\"><a class=\"markdownIt-Anchor\" href=\"#小痛点\"></a> 小痛点</h4>\n<ul>\n<li>提交改动有点麻烦，每次都要在feature分支上提交后，在release分支上进行merge request</li>\n<li>这个模式的一个痛点，当n个f分支，n个release分支的时候<br>需要记住，n个feature分支，与release 分支间的对应关系。</li>\n</ul>\n<h4 id=\"工具\"><a class=\"markdownIt-Anchor\" href=\"#工具\"></a> 工具</h4>\n<ul>\n<li>阿里巴巴内部使用aone平台管理，对外发布的产品叫 <a href=\"https://help.aliyun.com/document_detail/153762.html?spm=5176.168087.J_7469444330.4.91376942pV1EvU\">云效平台</a></li>\n<li>有赞qa平台，公交车发布系统，也借鉴了aoneFlow的思路<a href=\"https://tech.youzan.com/team/\">3.4 公交车系统</a></li>\n</ul>\n<h4 id=\"参考介绍\"><a class=\"markdownIt-Anchor\" href=\"#参考介绍\"></a> 参考介绍：</h4>\n<ul>\n<li><a href=\"https://blog.csdn.net/bbcckkl/article/details/111087267\">项目版本管理的最佳实践：飞流Flow（阿里AoneFlow）篇</a></li>\n<li><a href=\"https://blog.csdn.net/liumingzhe1/article/details/105287150\">Git-flow分支管理与Aone-flow分支管理对比</a></li>\n<li><a href=\"https://www.infoq.cn/article/EaC4c6yiJrzZ_Gtaf9Ne\">阿里巴巴如何管理代码分支？ </a></li>\n<li><a href=\"http://bos.itdks.com/7b7b1baa2f1244b8b3c2b3ae26de3eea.pdf\">阿里巴巴在DevOps实践中的创新和思考-ppt </a></li>\n</ul>"},{"title":"生产就绪备忘清单","toc":true,"hide":false,"date":"2021-07-30T07:37:15.000Z","_content":"\n\n\n功能完备只是起点，服务总要经过线上的打磨与历练； <br>这里有份清单标志着生产的就绪； <br>在街头，口口相传，哥哥来告诉弟弟\n\n<!-- more -->\n\n------\n\n\n\n## 生产就绪备忘清单\n\n\n\n\n\n| 要求         | 自查套路                                                     | 是否完成 | 备注 |\n| ------------ | ------------------------------------------------------------ | -------- | ---- |\n| 功能完备     | 对照产品文档；<br />对照接口文档回顾一遍<br />大约20分钟即可 |          |      |\n| 性能完备     | 预期流量是多少<br />是否需要压测，其实很多服务不需要压测<br />如果有点压力的话，可以与运维沟通加点机器<br />或者与组长提前沟通一下，说一下压力点 |          |      |\n| 容量规划     | 日志产物<br />IO上传、现在产物<br />产物留存时间<br />清理计划 |          |      |\n| 中间件迭代   | 中间件Schema<br />mysql、mq topic、es、hbase 是否准备完毕<br />不只要建好，更要确定此版本schema已经备份 |          |      |\n| 数据迭代     | 是否需要数据迁移<br />数据迁移功能是否经过测试<br />是否有线上验证逻辑 |          |      |\n| 兼容性考量   | 中间件：是否可以提前准备中间件环境<br />接口：与外部接口的交互，新旧版本支持情况<br />内部接口，是否有依赖关系，是否可以乱序上线 |          |      |\n| 配置文件     | 是否是prod 配置文件，是否完备                                |          |      |\n| 日志管理     | 走读代码<br />关键条件分支是否添加日志<br>日志量评估，3天，10天，90天分别多大。<br/>日志分级 |          |      |\n| 健康检查接口 | 是否具备<br />是否与监控组件调试通过<br />是否联通容器的Heathcheck |          |      |\n| 调用链监控   | 是否接入tracer <br />traceId 是否已经打通日志                |          |      |\n| 部署数量     | 多少流量，<br/>多少数据量，<br/>多少机器，<br/>是否可以快速扩容新节点 |          |      |\n| 高可用       | 是否是多节点，<br/>是否需要多集群，<br />如果部分节点宕机是否继续可用 |          |      |\n| 拓展性       | 是否是无状态应用<br />是否支持服务漂移<br/>有状态应用需要主备同步，副本机制 |          |      |\n| 回滚策略     | 确定上一个版本的tag<br>中间件schema 回滚语句准备完成<br />是否需要回滚数据 |          |      |\n\n","source":"_posts/技术规范/生产就绪备忘清单.md","raw":"---\ntitle: 生产就绪备忘清单\ntoc: true\ncategories:\n  - 后端\n\ntags:\n  - devOps\n  - 技术规范\nhide: false\ndate: 2021-07-30 15:37:15\n---\n\n\n\n功能完备只是起点，服务总要经过线上的打磨与历练； <br>这里有份清单标志着生产的就绪； <br>在街头，口口相传，哥哥来告诉弟弟\n\n<!-- more -->\n\n------\n\n\n\n## 生产就绪备忘清单\n\n\n\n\n\n| 要求         | 自查套路                                                     | 是否完成 | 备注 |\n| ------------ | ------------------------------------------------------------ | -------- | ---- |\n| 功能完备     | 对照产品文档；<br />对照接口文档回顾一遍<br />大约20分钟即可 |          |      |\n| 性能完备     | 预期流量是多少<br />是否需要压测，其实很多服务不需要压测<br />如果有点压力的话，可以与运维沟通加点机器<br />或者与组长提前沟通一下，说一下压力点 |          |      |\n| 容量规划     | 日志产物<br />IO上传、现在产物<br />产物留存时间<br />清理计划 |          |      |\n| 中间件迭代   | 中间件Schema<br />mysql、mq topic、es、hbase 是否准备完毕<br />不只要建好，更要确定此版本schema已经备份 |          |      |\n| 数据迭代     | 是否需要数据迁移<br />数据迁移功能是否经过测试<br />是否有线上验证逻辑 |          |      |\n| 兼容性考量   | 中间件：是否可以提前准备中间件环境<br />接口：与外部接口的交互，新旧版本支持情况<br />内部接口，是否有依赖关系，是否可以乱序上线 |          |      |\n| 配置文件     | 是否是prod 配置文件，是否完备                                |          |      |\n| 日志管理     | 走读代码<br />关键条件分支是否添加日志<br>日志量评估，3天，10天，90天分别多大。<br/>日志分级 |          |      |\n| 健康检查接口 | 是否具备<br />是否与监控组件调试通过<br />是否联通容器的Heathcheck |          |      |\n| 调用链监控   | 是否接入tracer <br />traceId 是否已经打通日志                |          |      |\n| 部署数量     | 多少流量，<br/>多少数据量，<br/>多少机器，<br/>是否可以快速扩容新节点 |          |      |\n| 高可用       | 是否是多节点，<br/>是否需要多集群，<br />如果部分节点宕机是否继续可用 |          |      |\n| 拓展性       | 是否是无状态应用<br />是否支持服务漂移<br/>有状态应用需要主备同步，副本机制 |          |      |\n| 回滚策略     | 确定上一个版本的tag<br>中间件schema 回滚语句准备完成<br />是否需要回滚数据 |          |      |\n\n","slug":"技术规范/生产就绪备忘清单","published":1,"updated":"2021-07-30T07:37:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxmz0011cpfy0a4ndh22","content":"<p>功能完备只是起点，服务总要经过线上的打磨与历练； <br>这里有份清单标志着生产的就绪； <br>在街头，口口相传，哥哥来告诉弟弟</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"生产就绪备忘清单\"> 生产就绪备忘清单</span></h2>\n<table>\n<thead>\n<tr>\n<th>要求</th>\n<th>自查套路</th>\n<th>是否完成</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>功能完备</td>\n<td>对照产品文档；<br>对照接口文档回顾一遍<br>大约20分钟即可</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>性能完备</td>\n<td>预期流量是多少<br>是否需要压测，其实很多服务不需要压测<br>如果有点压力的话，可以与运维沟通加点机器<br>或者与组长提前沟通一下，说一下压力点</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>容量规划</td>\n<td>日志产物<br>IO上传、现在产物<br>产物留存时间<br>清理计划</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>中间件迭代</td>\n<td>中间件Schema<br>mysql、mq topic、es、hbase 是否准备完毕<br>不只要建好，更要确定此版本schema已经备份</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>数据迭代</td>\n<td>是否需要数据迁移<br>数据迁移功能是否经过测试<br>是否有线上验证逻辑</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>兼容性考量</td>\n<td>中间件：是否可以提前准备中间件环境<br>接口：与外部接口的交互，新旧版本支持情况<br>内部接口，是否有依赖关系，是否可以乱序上线</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>配置文件</td>\n<td>是否是prod 配置文件，是否完备</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>日志管理</td>\n<td>走读代码<br>关键条件分支是否添加日志<br>日志量评估，3天，10天，90天分别多大。<br>日志分级</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>健康检查接口</td>\n<td>是否具备<br>是否与监控组件调试通过<br>是否联通容器的Heathcheck</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>调用链监控</td>\n<td>是否接入tracer <br>traceId 是否已经打通日志</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>部署数量</td>\n<td>多少流量，<br>多少数据量，<br>多少机器，<br>是否可以快速扩容新节点</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>高可用</td>\n<td>是否是多节点，<br>是否需要多集群，<br>如果部分节点宕机是否继续可用</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>拓展性</td>\n<td>是否是无状态应用<br>是否支持服务漂移<br>有状态应用需要主备同步，副本机制</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>回滚策略</td>\n<td>确定上一个版本的tag<br>中间件schema 回滚语句准备完成<br>是否需要回滚数据</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n","site":{"data":{}},"excerpt":"<p>功能完备只是起点，服务总要经过线上的打磨与历练； <br>这里有份清单标志着生产的就绪； <br>在街头，口口相传，哥哥来告诉弟弟</p>","more":"<hr />\n<h2 id=\"生产就绪备忘清单\"><a class=\"markdownIt-Anchor\" href=\"#生产就绪备忘清单\"></a> 生产就绪备忘清单</h2>\n<table>\n<thead>\n<tr>\n<th>要求</th>\n<th>自查套路</th>\n<th>是否完成</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>功能完备</td>\n<td>对照产品文档；<br />对照接口文档回顾一遍<br />大约20分钟即可</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>性能完备</td>\n<td>预期流量是多少<br />是否需要压测，其实很多服务不需要压测<br />如果有点压力的话，可以与运维沟通加点机器<br />或者与组长提前沟通一下，说一下压力点</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>容量规划</td>\n<td>日志产物<br />IO上传、现在产物<br />产物留存时间<br />清理计划</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>中间件迭代</td>\n<td>中间件Schema<br />mysql、mq topic、es、hbase 是否准备完毕<br />不只要建好，更要确定此版本schema已经备份</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>数据迭代</td>\n<td>是否需要数据迁移<br />数据迁移功能是否经过测试<br />是否有线上验证逻辑</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>兼容性考量</td>\n<td>中间件：是否可以提前准备中间件环境<br />接口：与外部接口的交互，新旧版本支持情况<br />内部接口，是否有依赖关系，是否可以乱序上线</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>配置文件</td>\n<td>是否是prod 配置文件，是否完备</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>日志管理</td>\n<td>走读代码<br />关键条件分支是否添加日志<br>日志量评估，3天，10天，90天分别多大。<br/>日志分级</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>健康检查接口</td>\n<td>是否具备<br />是否与监控组件调试通过<br />是否联通容器的Heathcheck</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>调用链监控</td>\n<td>是否接入tracer <br />traceId 是否已经打通日志</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>部署数量</td>\n<td>多少流量，<br/>多少数据量，<br/>多少机器，<br/>是否可以快速扩容新节点</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>高可用</td>\n<td>是否是多节点，<br/>是否需要多集群，<br />如果部分节点宕机是否继续可用</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>拓展性</td>\n<td>是否是无状态应用<br />是否支持服务漂移<br/>有状态应用需要主备同步，副本机制</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>回滚策略</td>\n<td>确定上一个版本的tag<br>中间件schema 回滚语句准备完成<br />是否需要回滚数据</td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>"},{"title":"监控规范","toc":true,"hide":true,"date":"2021-07-30T09:27:14.000Z","_content":"\n\n\n去吧，把服务照明\n\n<!-- more -->\n\n------\n\n\n\n## 常见监控点\n\n\n\n### 系统层\n\n\n\n|            | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| ---------- | ------ | ------------------ | -------- | ------ |\n| 虚拟机监控 |        |                    |          |        |\n| 容器监控   |        |                    |          |        |\n|            |        |                    |          |        |\n\n\n\n### 网络层\n\n|                | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| -------------- | ------ | ------------------ | -------- | ------ |\n| 监控专线带宽   |        |                    |          |        |\n| 交换机基本情况 |        |                    |          |        |\n| 网络延迟       |        |                    |          |        |\n\n\n\n\n\n### 中间件\n\n|          | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| -------- | ------ | ------------------ | -------- | ------ |\n| 注册中心 |        |                    |          |        |\n|          |        |                    |          |        |\n| mysql    |        |                    |          |        |\n|          |        |                    |          |        |\n| redis    |        |                    |          |        |\n|          |        |                    |          |        |\n| es       |        |                    |          |        |\n|          |        |                    |          |        |\n\n\n\n### 应用程序本身\n\n|            | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| ---------- | ------ | ------------------ | -------- | ------ |\n| jvm        |        |                    |          |        |\n|            |        |                    |          |        |\n| GC         |        |                    |          |        |\n|            |        |                    |          |        |\n| 内存       |        |                    |          |        |\n|            |        |                    |          |        |\n| 线程       |        |                    |          |        |\n|            |        |                    |          |        |\n| 队列       |        |                    |          |        |\n|            |        |                    |          |        |\n| 缓存       |        |                    |          |        |\n|            |        |                    |          |        |\n| 可用性     |        |                    |          |        |\n|            |        |                    |          |        |\n| 业务正确性 |        |                    |          |        |\n\n\n\n\n\n## 日志规范\n\n#### 日志规范\n\n1. 对外服务接口，所有if分支需要打印日志\n2. 使用日志异步配置\n3. 禁止打印全部实体，打印实体id即可，实体关键属性即可\n4. 打印traceId\n\n\n\n#### 日志分级\n\n- DEBUG 用于开发调试；敏感信息一律使用debug。\n- INFO 用于重要流程信息；if 各种分支\n- WARN 用于需要关注但无需报警的问题；一般是为了方便排查的日志。\n- ERROR 需要报警的异常；一般是系统异常、需要人工介入的业务异常\n\n\n\n#### 日志分割\n\n近期（7天内）日志，根据日期&大小分割，保存日志原文。<br>如果有日志平台，则不需要保存长期日志<br>没有日志平台的话，需要保存30天日志，根据日期分割，使用压缩格式，文件中要体现时间。\n\n\n\n#### 日志中的信息\n\n- \n\n","source":"_posts/技术规范/监控规范.md","raw":"---\ntitle: 监控规范\ntoc: true\ncategories:\n  - 后端\n\ntags:\n  - devOps\n  - 技术规范\nhide: true\ndate: 2021-07-30 17:27:14\n---\n\n\n\n去吧，把服务照明\n\n<!-- more -->\n\n------\n\n\n\n## 常见监控点\n\n\n\n### 系统层\n\n\n\n|            | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| ---------- | ------ | ------------------ | -------- | ------ |\n| 虚拟机监控 |        |                    |          |        |\n| 容器监控   |        |                    |          |        |\n|            |        |                    |          |        |\n\n\n\n### 网络层\n\n|                | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| -------------- | ------ | ------------------ | -------- | ------ |\n| 监控专线带宽   |        |                    |          |        |\n| 交换机基本情况 |        |                    |          |        |\n| 网络延迟       |        |                    |          |        |\n\n\n\n\n\n### 中间件\n\n|          | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| -------- | ------ | ------------------ | -------- | ------ |\n| 注册中心 |        |                    |          |        |\n|          |        |                    |          |        |\n| mysql    |        |                    |          |        |\n|          |        |                    |          |        |\n| redis    |        |                    |          |        |\n|          |        |                    |          |        |\n| es       |        |                    |          |        |\n|          |        |                    |          |        |\n\n\n\n### 应用程序本身\n\n|            | 监控点 | 常用监控方案及工具 | 常见指标 | 报警点 |\n| ---------- | ------ | ------------------ | -------- | ------ |\n| jvm        |        |                    |          |        |\n|            |        |                    |          |        |\n| GC         |        |                    |          |        |\n|            |        |                    |          |        |\n| 内存       |        |                    |          |        |\n|            |        |                    |          |        |\n| 线程       |        |                    |          |        |\n|            |        |                    |          |        |\n| 队列       |        |                    |          |        |\n|            |        |                    |          |        |\n| 缓存       |        |                    |          |        |\n|            |        |                    |          |        |\n| 可用性     |        |                    |          |        |\n|            |        |                    |          |        |\n| 业务正确性 |        |                    |          |        |\n\n\n\n\n\n## 日志规范\n\n#### 日志规范\n\n1. 对外服务接口，所有if分支需要打印日志\n2. 使用日志异步配置\n3. 禁止打印全部实体，打印实体id即可，实体关键属性即可\n4. 打印traceId\n\n\n\n#### 日志分级\n\n- DEBUG 用于开发调试；敏感信息一律使用debug。\n- INFO 用于重要流程信息；if 各种分支\n- WARN 用于需要关注但无需报警的问题；一般是为了方便排查的日志。\n- ERROR 需要报警的异常；一般是系统异常、需要人工介入的业务异常\n\n\n\n#### 日志分割\n\n近期（7天内）日志，根据日期&大小分割，保存日志原文。<br>如果有日志平台，则不需要保存长期日志<br>没有日志平台的话，需要保存30天日志，根据日期分割，使用压缩格式，文件中要体现时间。\n\n\n\n#### 日志中的信息\n\n- \n\n","slug":"技术规范/监控规范","published":1,"updated":"2021-07-30T09:27:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn00014cpfy6bh12q85","content":"<p>去吧，把服务照明</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"常见监控点\"> 常见监控点</span></h2>\n<h3><span id=\"系统层\"> 系统层</span></h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>虚拟机监控</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>容器监控</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3><span id=\"网络层\"> 网络层</span></h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>监控专线带宽</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>交换机基本情况</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>网络延迟</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3><span id=\"中间件\"> 中间件</span></h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>注册中心</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>mysql</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>redis</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>es</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3><span id=\"应用程序本身\"> 应用程序本身</span></h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jvm</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>GC</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>内存</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>线程</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>队列</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>缓存</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>可用性</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>业务正确性</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2><span id=\"日志规范\"> 日志规范</span></h2>\n<h4><span id=\"日志规范\"> 日志规范</span></h4>\n<ol>\n<li>对外服务接口，所有if分支需要打印日志</li>\n<li>使用日志异步配置</li>\n<li>禁止打印全部实体，打印实体id即可，实体关键属性即可</li>\n<li>打印traceId</li>\n</ol>\n<h4><span id=\"日志分级\"> 日志分级</span></h4>\n<ul>\n<li>DEBUG 用于开发调试；敏感信息一律使用debug。</li>\n<li>INFO 用于重要流程信息；if 各种分支</li>\n<li>WARN 用于需要关注但无需报警的问题；一般是为了方便排查的日志。</li>\n<li>ERROR 需要报警的异常；一般是系统异常、需要人工介入的业务异常</li>\n</ul>\n<h4><span id=\"日志分割\"> 日志分割</span></h4>\n<p>近期（7天内）日志，根据日期&amp;大小分割，保存日志原文。<br>如果有日志平台，则不需要保存长期日志<br>没有日志平台的话，需要保存30天日志，根据日期分割，使用压缩格式，文件中要体现时间。</p>\n<h4><span id=\"日志中的信息\"> 日志中的信息</span></h4>\n<ul>\n<li></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>去吧，把服务照明</p>","more":"<hr />\n<h2 id=\"常见监控点\"><a class=\"markdownIt-Anchor\" href=\"#常见监控点\"></a> 常见监控点</h2>\n<h3 id=\"系统层\"><a class=\"markdownIt-Anchor\" href=\"#系统层\"></a> 系统层</h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>虚拟机监控</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>容器监控</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"网络层\"><a class=\"markdownIt-Anchor\" href=\"#网络层\"></a> 网络层</h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>监控专线带宽</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>交换机基本情况</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>网络延迟</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"中间件\"><a class=\"markdownIt-Anchor\" href=\"#中间件\"></a> 中间件</h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>注册中心</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>mysql</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>redis</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>es</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"应用程序本身\"><a class=\"markdownIt-Anchor\" href=\"#应用程序本身\"></a> 应用程序本身</h3>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>监控点</th>\n<th>常用监控方案及工具</th>\n<th>常见指标</th>\n<th>报警点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>jvm</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>GC</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>内存</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>线程</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>队列</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>缓存</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>可用性</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>业务正确性</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"日志规范\"><a class=\"markdownIt-Anchor\" href=\"#日志规范\"></a> 日志规范</h2>\n<h4 id=\"日志规范-2\"><a class=\"markdownIt-Anchor\" href=\"#日志规范-2\"></a> 日志规范</h4>\n<ol>\n<li>对外服务接口，所有if分支需要打印日志</li>\n<li>使用日志异步配置</li>\n<li>禁止打印全部实体，打印实体id即可，实体关键属性即可</li>\n<li>打印traceId</li>\n</ol>\n<h4 id=\"日志分级\"><a class=\"markdownIt-Anchor\" href=\"#日志分级\"></a> 日志分级</h4>\n<ul>\n<li>DEBUG 用于开发调试；敏感信息一律使用debug。</li>\n<li>INFO 用于重要流程信息；if 各种分支</li>\n<li>WARN 用于需要关注但无需报警的问题；一般是为了方便排查的日志。</li>\n<li>ERROR 需要报警的异常；一般是系统异常、需要人工介入的业务异常</li>\n</ul>\n<h4 id=\"日志分割\"><a class=\"markdownIt-Anchor\" href=\"#日志分割\"></a> 日志分割</h4>\n<p>近期（7天内）日志，根据日期&amp;大小分割，保存日志原文。<br>如果有日志平台，则不需要保存长期日志<br>没有日志平台的话，需要保存30天日志，根据日期分割，使用压缩格式，文件中要体现时间。</p>\n<h4 id=\"日志中的信息\"><a class=\"markdownIt-Anchor\" href=\"#日志中的信息\"></a> 日志中的信息</h4>\n<ul>\n<li></li>\n</ul>"},{"title":"注册中心的设计与选型","toc":true,"hide":true,"date":"2021-07-31T15:47:39.000Z","_content":"\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# 注册中心的设计与选型\n\n\n\n## 没有注册中心的解决方案\n\n- 通过全局配置文件，来规定服务ip的调用关系。<br>迁移、扩容的时候非常痛苦。\n\n\n\n## 注册中心，需要实现的点\n\n\n\n### 注册中心的主要功能\n\n#### 获取服务信息\n\n- 路由信息，服务注册节点的IP，端口。\n- 服务元数据信息，序列化协议，负载均衡规则，节点权重等\n\n\n\n#### 服务发现：\n\n- 启动时拉：消费方启动后，先从注册中心获取提供方的节点列表\n\n- 通知回调：提供方的节点变更时，主动调用消费方，让消费方重新拉取节点数据\n\n- 轮询拉取：回调不一定总是成功，所以需要兜底策略：轮询，分钟级别。\n\n  \n\n#### 主动通知调用方，服务节点发生变更\n\n#### 机器迁移\n\n#### 权重\n\n#### 灰度流量\n\n\n\n#### 健康检查\n\n- 一般情况下的服务失效原因\n\n  1. 部署重启，正常下线，可以主动通知注册中心\n  2. 服务异常终止，比如机器掉电，无法主动通知下线事件\n  3. 服务假死（注册中心线程可用，但工作线程不可用，表现起来就是依然可用向注册中心发心跳，但业务接口已经卡死不可用。）\n\n  \n\n- 注册中心监控不健康节点的方案\n\n  - 主动下线，能解决1 \n  - 心跳上报，能解决 1，2\n  - 注册中心，主动探活，探测工作线程是否可用。能解决 1，2，3\n  - consumer 通过正常调用，也可以感知到对方服务是否假死。<br>也通过consumer上报异常，解决  1，2，3\n\n  \n\n## 注册中心的实现方案\n\n### 业务模型\n\n- 消费者视角，主要关心的是服务的提供者的ip地址。\n- 提供者的角度，主要关系的是，本服务被哪些消费者注册消费了，方便提供者节点上下线的时候，主动通知消费者\n\n```json\n{\n    \"providerList\": [\n        {\n            \"serverName\": \"orderSvr\",\n            \"consumerList\": \"userSvr,addrSvr,productSvr\"\n        },\n        {\n            \"serverName\": \"addrSvr\",\n            \"consumerList\": \"userSvr,addrSvr,productSvr\"\n        }\n    ],\n    \"consumerList\": [\n        {\n            \"serverName\": \"userSvr\",\n            \"providerList\": \"orderSvr,addrSvr,productSvr\"\n        },\n        {\n            \"serverName\": \"orderSvr\",\n            \"providerList\": \"userSvr,addrSvr,productSvr\"\n\n        }\n    ],\n    \"ipList\": [\n        {\n            \"serverName\": \"orderSvr\",\n            \"ipList\": \"xxxx,xxxx,xxxx\",\n            \"port\": \"8081\"\n        },\n        {\n            \"serverName\": \"userSvr\",\n            \"ipList\": \"xxxx,xxxx,xxxx\",\n            \"port\": \"8082\"\n        }\n    ]\n}\n```\n\n\n\n### 超时处理\n\n- 遍历扫描，以前的微服务注册中心，使用该方法即可，因为节点不多。\n\n- 动态分组算法，节点数量较多时使用，一般应用在 IM 中 长连接 keepalive 超时主动清理的扫描机制， 节点以10万为单位。遍历肯定不行\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801012443.png\" alt=\"image-20210801012442966\" style=\"zoom:33%;\" />\n\n\n\n1. 该数据模型，如果n秒超时，有n个bucket。比如1分钟超时，就有60个bucket。\n\n2. 这样每一个连接的超时时间，就能确定的放到某一个bucket里面，比如现在是53秒，有一个新的连接进来，那么新的连接就要放到。\n\n3. 有一个游标一直轮询bucket，每一秒往后移动一格，当53秒的时候，移动到52号格子里，然后清理52号格子。\n\n   \n\n### 变更通知\n\n#### gossip协议\n\n- 六度分离理论，周期性散播下线通知。\n- 随机选择n个节点，传递新数据，传x轮。每个节点获取新数据后，仍然选n个节点，传新数据，传x轮。\n- 避免不了重复传递，但无所谓。\n- 经过x/n轮后，所有节点已经更新数据。\n\n\n\n\n\n## 开源注册中心选型\n\n\n\n### CAP\n\n本质上，注册中心是一个高可用，高数据一致性的分布式存储，里面存了各个节点的数据。\n\n那么分布式cun存储，就要搬出CAP理论了：\n\n- （partition toleran）数据可靠性，数据是冗余存储的，不会因为单节点故障导致数据整体丢失。\n- （consistency）数据一致性，个节点间的数据，最终会保证统一。\n- （availability）服务整体可用性，服务不间断对外提供服务。\n\n\n\n### AP or CP\n\n- AP，牺牲一致性，保证不间断对外提供服务。<br>代表组件：**eureka，nacos**\n- CP，优先保证数据一致性，当发现数据不一致的时候，重新选举，然后同步数据；<br>在这期间，停止对外服务 <br>代表组件：**zookeeper**\n\n- 总结：\n\n  如果是**注册中心**：一定选取AP模式，对于注册中心这个产品，节点状态数据变动不频繁。<br>注册中心不能因为自身的任何原因，让程序变得不可用，这是注册中心设计应该遵循的铁律<br>注册中心，如果节点变动超过阈值，甚至要主动报警；并防止节点下线（保护模式）。\n\n  如果是**分布式协调器**，分布式锁。则需要使用CP模式。\n\n\n\n### 注册中心的综合对比\n\n| 特征               | zookeeper | etcd     | consul   | eureka   | nacos                  |\n| ------------------ | --------- | :------- | -------- | -------- | ---------------------- |\n| 服务健康检查       | 长连接    | 心跳     | 心跳     | 心跳     | 支持                   |\n| 多数据中心         | \\--       | \\--      | 支持     | \\--      | 支持                   |\n| kv存储服务         | 支持      | 支持     | 支持     | \\--      | 支持                   |\n| 一致性             | Zab       | raft     | raft     | 弱一致性 | Distro                 |\n| CAP定理            | CP        | CP       | CP       | AP       | AP                     |\n| 服务端<br>主动探活 | 私有协议  | 私有协议 | 支持     | 长轮询   | 长轮询<br>v2使用长连接 |\n| 客户端访问         | SDK       | http     | http&dns | http     | http                   |\n| 社区支持           | 积极      | 积极     | 积极     | 不积极   | 积极                   |\n\n\n\n\n\n\n\n\n\n## Nacos注册中心深入分析\n\n### 健康检查\n\n- 临时节点：心跳注册机制，ttl超时下线。\n- 持久化节点，比如数据库，使用服务端探活机制，标记不可用。如果不可用超过阈值，则报警。\n- 心跳阈值：5秒，上报；15秒，标记不健康；30秒，剔除节点\n\n### 数据模型\n\n- 数据存储，IP地址，端口，健康检查，ttl，权重。\n\n- 数据隔离，多重命名空间，User，NameSpace，Group\n\n  User：多租户\n\n  NameSpace：业务线隔离\n\n  Group：A，B集群，平滑上线使用。\n\n### 数据一致性保障\n\n- Raft CP一致性\t【一般适不使用该模式】\n- Distro AP一致性 【无主模式】\n\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802234926.png\" alt=\"image-20210802234926080\" style=\"zoom: 33%;\" />\n\n\n\n\n\n节点上线逻辑：【】\n\n节点下线逻辑：【】\n\n\n\n## Zookeeper实现深入剖析\n\n\n\n### 选主逻辑\n\n#### zk节点的角色\n\n- leader，响应写入请求，发起提案，超过半数follower同意写入，则写入成功。\n- follower，响应查询，将写入请求转发给leader，参与选举 和 投票 以及写入操作。\n- observer，响应查询，将写入请求转发给leader，不参与投票，只负责接收写入操作。\n- leader，代表公司ceo，只输出提案，并最终确认提案；<br>follower，代表管理层，转发提案并参与投票，最终执行提案；<br>observer，代表一线员工，转发提案，不参与投票，执行提案。\n\n#### 选主规则\n\n- 获得法定数量的票数，即follower 数量过半。\n\n- 判断依据\n\n  - Epoch：leader的任期\n  - ZXID：zookeeper的事务ID，越大表示事务越新\n  - SID：集群的每个节点唯一编号\n  - 比较策略：连续排序，根据 任期、ZXID、SID 三个值，做比较。大的胜利。\n\n- 选主逻辑\n\n  - 节点进入 looking 状态\n\n  - 广播发起投票，选出 最大 的节点，发起二次投票\n\n  - 超过半数成为主。\n\n    \n\n### 数据一致性保障\n\n- zab协议， todo。\n\n\n\n### 数据模型\n\n树状结构存储数据，分为永久节点和临时节点\n\n- DataNode ，Zookeeper中存储的最小单元，是持久化数据节点描述的最小单位\n\n```java\nDataNode parent;  \t\t//父节点的引用 \nbyte data[]; \t\t\t\t\t//该节点存储的数据\nLong acl;\t\t\t\t\t\t\t//acl控制权限\nStatPersisted stat; \t//持久化节点状态\nSet<String> children; //子节点列表\n```\n\n- DataTree，以树形结构存储了zookeeper中所有的数据信息\n\n```java\nConcurrentHashMap<String, DataNode> nodes;\t//当前树存的节点\nWatchManager dataWatches;\t\t\t\t\t\t\t\t\t\t//数据变更通知\nWatchManager childWatches;\t\t\t\t\t\t\t\t\t//节点变更通知\nString rootZookeeper;\t\t\t\t\t\t\t\t\t\t\t\t//根节点\nMap<Long, HashSet<String>> ephemerals\t\t\t\t//临时节点信息\n```\n\n- ZKDataBase，负责管理Zookeeper的数据、会话信息和事务日志\n\n```java\nDataTree dataTree;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//这zk的这棵树\nConcurrentHashMap<Long, Integer> sessionsWithTimeouts; \t//客户端会话连接管理 FileTxnSnapLog snapLog; \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//事务日志\n```\n\n","source":"_posts/注册中心/注册中心的选型与设计.md","raw":"---\ntitle: 注册中心的设计与选型\ntoc: true\ncategories:\n  - 后端\ntags:\n  - 注册中心\n  - 设计\nhide: true\ndate: 2021-07-31 23:47:39\n---\n\n这是摘要\n<!-- more -->\n\n------\n\n\n\n# 注册中心的设计与选型\n\n\n\n## 没有注册中心的解决方案\n\n- 通过全局配置文件，来规定服务ip的调用关系。<br>迁移、扩容的时候非常痛苦。\n\n\n\n## 注册中心，需要实现的点\n\n\n\n### 注册中心的主要功能\n\n#### 获取服务信息\n\n- 路由信息，服务注册节点的IP，端口。\n- 服务元数据信息，序列化协议，负载均衡规则，节点权重等\n\n\n\n#### 服务发现：\n\n- 启动时拉：消费方启动后，先从注册中心获取提供方的节点列表\n\n- 通知回调：提供方的节点变更时，主动调用消费方，让消费方重新拉取节点数据\n\n- 轮询拉取：回调不一定总是成功，所以需要兜底策略：轮询，分钟级别。\n\n  \n\n#### 主动通知调用方，服务节点发生变更\n\n#### 机器迁移\n\n#### 权重\n\n#### 灰度流量\n\n\n\n#### 健康检查\n\n- 一般情况下的服务失效原因\n\n  1. 部署重启，正常下线，可以主动通知注册中心\n  2. 服务异常终止，比如机器掉电，无法主动通知下线事件\n  3. 服务假死（注册中心线程可用，但工作线程不可用，表现起来就是依然可用向注册中心发心跳，但业务接口已经卡死不可用。）\n\n  \n\n- 注册中心监控不健康节点的方案\n\n  - 主动下线，能解决1 \n  - 心跳上报，能解决 1，2\n  - 注册中心，主动探活，探测工作线程是否可用。能解决 1，2，3\n  - consumer 通过正常调用，也可以感知到对方服务是否假死。<br>也通过consumer上报异常，解决  1，2，3\n\n  \n\n## 注册中心的实现方案\n\n### 业务模型\n\n- 消费者视角，主要关心的是服务的提供者的ip地址。\n- 提供者的角度，主要关系的是，本服务被哪些消费者注册消费了，方便提供者节点上下线的时候，主动通知消费者\n\n```json\n{\n    \"providerList\": [\n        {\n            \"serverName\": \"orderSvr\",\n            \"consumerList\": \"userSvr,addrSvr,productSvr\"\n        },\n        {\n            \"serverName\": \"addrSvr\",\n            \"consumerList\": \"userSvr,addrSvr,productSvr\"\n        }\n    ],\n    \"consumerList\": [\n        {\n            \"serverName\": \"userSvr\",\n            \"providerList\": \"orderSvr,addrSvr,productSvr\"\n        },\n        {\n            \"serverName\": \"orderSvr\",\n            \"providerList\": \"userSvr,addrSvr,productSvr\"\n\n        }\n    ],\n    \"ipList\": [\n        {\n            \"serverName\": \"orderSvr\",\n            \"ipList\": \"xxxx,xxxx,xxxx\",\n            \"port\": \"8081\"\n        },\n        {\n            \"serverName\": \"userSvr\",\n            \"ipList\": \"xxxx,xxxx,xxxx\",\n            \"port\": \"8082\"\n        }\n    ]\n}\n```\n\n\n\n### 超时处理\n\n- 遍历扫描，以前的微服务注册中心，使用该方法即可，因为节点不多。\n\n- 动态分组算法，节点数量较多时使用，一般应用在 IM 中 长连接 keepalive 超时主动清理的扫描机制， 节点以10万为单位。遍历肯定不行\n\n  <img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801012443.png\" alt=\"image-20210801012442966\" style=\"zoom:33%;\" />\n\n\n\n1. 该数据模型，如果n秒超时，有n个bucket。比如1分钟超时，就有60个bucket。\n\n2. 这样每一个连接的超时时间，就能确定的放到某一个bucket里面，比如现在是53秒，有一个新的连接进来，那么新的连接就要放到。\n\n3. 有一个游标一直轮询bucket，每一秒往后移动一格，当53秒的时候，移动到52号格子里，然后清理52号格子。\n\n   \n\n### 变更通知\n\n#### gossip协议\n\n- 六度分离理论，周期性散播下线通知。\n- 随机选择n个节点，传递新数据，传x轮。每个节点获取新数据后，仍然选n个节点，传新数据，传x轮。\n- 避免不了重复传递，但无所谓。\n- 经过x/n轮后，所有节点已经更新数据。\n\n\n\n\n\n## 开源注册中心选型\n\n\n\n### CAP\n\n本质上，注册中心是一个高可用，高数据一致性的分布式存储，里面存了各个节点的数据。\n\n那么分布式cun存储，就要搬出CAP理论了：\n\n- （partition toleran）数据可靠性，数据是冗余存储的，不会因为单节点故障导致数据整体丢失。\n- （consistency）数据一致性，个节点间的数据，最终会保证统一。\n- （availability）服务整体可用性，服务不间断对外提供服务。\n\n\n\n### AP or CP\n\n- AP，牺牲一致性，保证不间断对外提供服务。<br>代表组件：**eureka，nacos**\n- CP，优先保证数据一致性，当发现数据不一致的时候，重新选举，然后同步数据；<br>在这期间，停止对外服务 <br>代表组件：**zookeeper**\n\n- 总结：\n\n  如果是**注册中心**：一定选取AP模式，对于注册中心这个产品，节点状态数据变动不频繁。<br>注册中心不能因为自身的任何原因，让程序变得不可用，这是注册中心设计应该遵循的铁律<br>注册中心，如果节点变动超过阈值，甚至要主动报警；并防止节点下线（保护模式）。\n\n  如果是**分布式协调器**，分布式锁。则需要使用CP模式。\n\n\n\n### 注册中心的综合对比\n\n| 特征               | zookeeper | etcd     | consul   | eureka   | nacos                  |\n| ------------------ | --------- | :------- | -------- | -------- | ---------------------- |\n| 服务健康检查       | 长连接    | 心跳     | 心跳     | 心跳     | 支持                   |\n| 多数据中心         | \\--       | \\--      | 支持     | \\--      | 支持                   |\n| kv存储服务         | 支持      | 支持     | 支持     | \\--      | 支持                   |\n| 一致性             | Zab       | raft     | raft     | 弱一致性 | Distro                 |\n| CAP定理            | CP        | CP       | CP       | AP       | AP                     |\n| 服务端<br>主动探活 | 私有协议  | 私有协议 | 支持     | 长轮询   | 长轮询<br>v2使用长连接 |\n| 客户端访问         | SDK       | http     | http&dns | http     | http                   |\n| 社区支持           | 积极      | 积极     | 积极     | 不积极   | 积极                   |\n\n\n\n\n\n\n\n\n\n## Nacos注册中心深入分析\n\n### 健康检查\n\n- 临时节点：心跳注册机制，ttl超时下线。\n- 持久化节点，比如数据库，使用服务端探活机制，标记不可用。如果不可用超过阈值，则报警。\n- 心跳阈值：5秒，上报；15秒，标记不健康；30秒，剔除节点\n\n### 数据模型\n\n- 数据存储，IP地址，端口，健康检查，ttl，权重。\n\n- 数据隔离，多重命名空间，User，NameSpace，Group\n\n  User：多租户\n\n  NameSpace：业务线隔离\n\n  Group：A，B集群，平滑上线使用。\n\n### 数据一致性保障\n\n- Raft CP一致性\t【一般适不使用该模式】\n- Distro AP一致性 【无主模式】\n\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802234926.png\" alt=\"image-20210802234926080\" style=\"zoom: 33%;\" />\n\n\n\n\n\n节点上线逻辑：【】\n\n节点下线逻辑：【】\n\n\n\n## Zookeeper实现深入剖析\n\n\n\n### 选主逻辑\n\n#### zk节点的角色\n\n- leader，响应写入请求，发起提案，超过半数follower同意写入，则写入成功。\n- follower，响应查询，将写入请求转发给leader，参与选举 和 投票 以及写入操作。\n- observer，响应查询，将写入请求转发给leader，不参与投票，只负责接收写入操作。\n- leader，代表公司ceo，只输出提案，并最终确认提案；<br>follower，代表管理层，转发提案并参与投票，最终执行提案；<br>observer，代表一线员工，转发提案，不参与投票，执行提案。\n\n#### 选主规则\n\n- 获得法定数量的票数，即follower 数量过半。\n\n- 判断依据\n\n  - Epoch：leader的任期\n  - ZXID：zookeeper的事务ID，越大表示事务越新\n  - SID：集群的每个节点唯一编号\n  - 比较策略：连续排序，根据 任期、ZXID、SID 三个值，做比较。大的胜利。\n\n- 选主逻辑\n\n  - 节点进入 looking 状态\n\n  - 广播发起投票，选出 最大 的节点，发起二次投票\n\n  - 超过半数成为主。\n\n    \n\n### 数据一致性保障\n\n- zab协议， todo。\n\n\n\n### 数据模型\n\n树状结构存储数据，分为永久节点和临时节点\n\n- DataNode ，Zookeeper中存储的最小单元，是持久化数据节点描述的最小单位\n\n```java\nDataNode parent;  \t\t//父节点的引用 \nbyte data[]; \t\t\t\t\t//该节点存储的数据\nLong acl;\t\t\t\t\t\t\t//acl控制权限\nStatPersisted stat; \t//持久化节点状态\nSet<String> children; //子节点列表\n```\n\n- DataTree，以树形结构存储了zookeeper中所有的数据信息\n\n```java\nConcurrentHashMap<String, DataNode> nodes;\t//当前树存的节点\nWatchManager dataWatches;\t\t\t\t\t\t\t\t\t\t//数据变更通知\nWatchManager childWatches;\t\t\t\t\t\t\t\t\t//节点变更通知\nString rootZookeeper;\t\t\t\t\t\t\t\t\t\t\t\t//根节点\nMap<Long, HashSet<String>> ephemerals\t\t\t\t//临时节点信息\n```\n\n- ZKDataBase，负责管理Zookeeper的数据、会话信息和事务日志\n\n```java\nDataTree dataTree;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//这zk的这棵树\nConcurrentHashMap<Long, Integer> sessionsWithTimeouts; \t//客户端会话连接管理 FileTxnSnapLog snapLog; \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//事务日志\n```\n\n","slug":"注册中心/注册中心的选型与设计","published":1,"updated":"2021-07-31T15:47:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn10019cpfy2mg38xhc","content":"<p>这是摘要</p>\n<span id=\"more\"></span>\n<hr>\n<h1><span id=\"注册中心的设计与选型\"> 注册中心的设计与选型</span></h1>\n<h2><span id=\"没有注册中心的解决方案\"> 没有注册中心的解决方案</span></h2>\n<ul>\n<li>通过全局配置文件，来规定服务ip的调用关系。<br>迁移、扩容的时候非常痛苦。</li>\n</ul>\n<h2><span id=\"注册中心需要实现的点\"> 注册中心，需要实现的点</span></h2>\n<h3><span id=\"注册中心的主要功能\"> 注册中心的主要功能</span></h3>\n<h4><span id=\"获取服务信息\"> 获取服务信息</span></h4>\n<ul>\n<li>路由信息，服务注册节点的IP，端口。</li>\n<li>服务元数据信息，序列化协议，负载均衡规则，节点权重等</li>\n</ul>\n<h4><span id=\"服务发现\"> 服务发现：</span></h4>\n<ul>\n<li>\n<p>启动时拉：消费方启动后，先从注册中心获取提供方的节点列表</p>\n</li>\n<li>\n<p>通知回调：提供方的节点变更时，主动调用消费方，让消费方重新拉取节点数据</p>\n</li>\n<li>\n<p>轮询拉取：回调不一定总是成功，所以需要兜底策略：轮询，分钟级别。</p>\n</li>\n</ul>\n<h4><span id=\"主动通知调用方服务节点发生变更\"> 主动通知调用方，服务节点发生变更</span></h4>\n<h4><span id=\"机器迁移\"> 机器迁移</span></h4>\n<h4><span id=\"权重\"> 权重</span></h4>\n<h4><span id=\"灰度流量\"> 灰度流量</span></h4>\n<h4><span id=\"健康检查\"> 健康检查</span></h4>\n<ul>\n<li>\n<p>一般情况下的服务失效原因</p>\n<ol>\n<li>部署重启，正常下线，可以主动通知注册中心</li>\n<li>服务异常终止，比如机器掉电，无法主动通知下线事件</li>\n<li>服务假死（注册中心线程可用，但工作线程不可用，表现起来就是依然可用向注册中心发心跳，但业务接口已经卡死不可用。）</li>\n</ol>\n</li>\n<li>\n<p>注册中心监控不健康节点的方案</p>\n<ul>\n<li>主动下线，能解决1</li>\n<li>心跳上报，能解决 1，2</li>\n<li>注册中心，主动探活，探测工作线程是否可用。能解决 1，2，3</li>\n<li>consumer 通过正常调用，也可以感知到对方服务是否假死。<br>也通过consumer上报异常，解决  1，2，3</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"注册中心的实现方案\"> 注册中心的实现方案</span></h2>\n<h3><span id=\"业务模型\"> 业务模型</span></h3>\n<ul>\n<li>消费者视角，主要关心的是服务的提供者的ip地址。</li>\n<li>提供者的角度，主要关系的是，本服务被哪些消费者注册消费了，方便提供者节点上下线的时候，主动通知消费者</li>\n</ul>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs json\">&#123;<br>    <span class=\"hljs-attr\">&quot;providerList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;addrSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br>        &#125;<br>    ],<br>    <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;userSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;providerList&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr,addrSvr,productSvr&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;providerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br><br>        &#125;<br>    ],<br>    <span class=\"hljs-attr\">&quot;ipList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;ipList&quot;</span>: <span class=\"hljs-string\">&quot;xxxx,xxxx,xxxx&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;port&quot;</span>: <span class=\"hljs-string\">&quot;8081&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;userSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;ipList&quot;</span>: <span class=\"hljs-string\">&quot;xxxx,xxxx,xxxx&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;port&quot;</span>: <span class=\"hljs-string\">&quot;8082&quot;</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></div></td></tr></table></figure>\n<h3><span id=\"超时处理\"> 超时处理</span></h3>\n<ul>\n<li>\n<p>遍历扫描，以前的微服务注册中心，使用该方法即可，因为节点不多。</p>\n</li>\n<li>\n<p>动态分组算法，节点数量较多时使用，一般应用在 IM 中 长连接 keepalive 超时主动清理的扫描机制， 节点以10万为单位。遍历肯定不行</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801012443.png\" alt=\"image-20210801012442966\" style=\"zoom:33%;\">\n</li>\n</ul>\n<ol>\n<li>\n<p>该数据模型，如果n秒超时，有n个bucket。比如1分钟超时，就有60个bucket。</p>\n</li>\n<li>\n<p>这样每一个连接的超时时间，就能确定的放到某一个bucket里面，比如现在是53秒，有一个新的连接进来，那么新的连接就要放到。</p>\n</li>\n<li>\n<p>有一个游标一直轮询bucket，每一秒往后移动一格，当53秒的时候，移动到52号格子里，然后清理52号格子。</p>\n</li>\n</ol>\n<h3><span id=\"变更通知\"> 变更通知</span></h3>\n<h4><span id=\"gossip协议\"> gossip协议</span></h4>\n<ul>\n<li>六度分离理论，周期性散播下线通知。</li>\n<li>随机选择n个节点，传递新数据，传x轮。每个节点获取新数据后，仍然选n个节点，传新数据，传x轮。</li>\n<li>避免不了重复传递，但无所谓。</li>\n<li>经过x/n轮后，所有节点已经更新数据。</li>\n</ul>\n<h2><span id=\"开源注册中心选型\"> 开源注册中心选型</span></h2>\n<h3><span id=\"cap\"> CAP</span></h3>\n<p>本质上，注册中心是一个高可用，高数据一致性的分布式存储，里面存了各个节点的数据。</p>\n<p>那么分布式cun存储，就要搬出CAP理论了：</p>\n<ul>\n<li>（partition toleran）数据可靠性，数据是冗余存储的，不会因为单节点故障导致数据整体丢失。</li>\n<li>（consistency）数据一致性，个节点间的数据，最终会保证统一。</li>\n<li>（availability）服务整体可用性，服务不间断对外提供服务。</li>\n</ul>\n<h3><span id=\"ap-or-cp\"> AP or CP</span></h3>\n<ul>\n<li>\n<p>AP，牺牲一致性，保证不间断对外提供服务。<br>代表组件：<strong>eureka，nacos</strong></p>\n</li>\n<li>\n<p>CP，优先保证数据一致性，当发现数据不一致的时候，重新选举，然后同步数据；<br>在这期间，停止对外服务 <br>代表组件：<strong>zookeeper</strong></p>\n</li>\n<li>\n<p>总结：</p>\n<p>如果是<strong>注册中心</strong>：一定选取AP模式，对于注册中心这个产品，节点状态数据变动不频繁。<br>注册中心不能因为自身的任何原因，让程序变得不可用，这是注册中心设计应该遵循的铁律<br>注册中心，如果节点变动超过阈值，甚至要主动报警；并防止节点下线（保护模式）。</p>\n<p>如果是<strong>分布式协调器</strong>，分布式锁。则需要使用CP模式。</p>\n</li>\n</ul>\n<h3><span id=\"注册中心的综合对比\"> 注册中心的综合对比</span></h3>\n<table>\n<thead>\n<tr>\n<th>特征</th>\n<th>zookeeper</th>\n<th style=\"text-align:left\">etcd</th>\n<th>consul</th>\n<th>eureka</th>\n<th>nacos</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>服务健康检查</td>\n<td>长连接</td>\n<td style=\"text-align:left\">心跳</td>\n<td>心跳</td>\n<td>心跳</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>多数据中心</td>\n<td>–</td>\n<td style=\"text-align:left\">–</td>\n<td>支持</td>\n<td>–</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>kv存储服务</td>\n<td>支持</td>\n<td style=\"text-align:left\">支持</td>\n<td>支持</td>\n<td>–</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>一致性</td>\n<td>Zab</td>\n<td style=\"text-align:left\">raft</td>\n<td>raft</td>\n<td>弱一致性</td>\n<td>Distro</td>\n</tr>\n<tr>\n<td>CAP定理</td>\n<td>CP</td>\n<td style=\"text-align:left\">CP</td>\n<td>CP</td>\n<td>AP</td>\n<td>AP</td>\n</tr>\n<tr>\n<td>服务端<br>主动探活</td>\n<td>私有协议</td>\n<td style=\"text-align:left\">私有协议</td>\n<td>支持</td>\n<td>长轮询</td>\n<td>长轮询<br>v2使用长连接</td>\n</tr>\n<tr>\n<td>客户端访问</td>\n<td>SDK</td>\n<td style=\"text-align:left\">http</td>\n<td>http&amp;dns</td>\n<td>http</td>\n<td>http</td>\n</tr>\n<tr>\n<td>社区支持</td>\n<td>积极</td>\n<td style=\"text-align:left\">积极</td>\n<td>积极</td>\n<td>不积极</td>\n<td>积极</td>\n</tr>\n</tbody>\n</table>\n<h2><span id=\"nacos注册中心深入分析\"> Nacos注册中心深入分析</span></h2>\n<h3><span id=\"健康检查\"> 健康检查</span></h3>\n<ul>\n<li>临时节点：心跳注册机制，ttl超时下线。</li>\n<li>持久化节点，比如数据库，使用服务端探活机制，标记不可用。如果不可用超过阈值，则报警。</li>\n<li>心跳阈值：5秒，上报；15秒，标记不健康；30秒，剔除节点</li>\n</ul>\n<h3><span id=\"数据模型\"> 数据模型</span></h3>\n<ul>\n<li>\n<p>数据存储，IP地址，端口，健康检查，ttl，权重。</p>\n</li>\n<li>\n<p>数据隔离，多重命名空间，User，NameSpace，Group</p>\n<p>User：多租户</p>\n<p>NameSpace：业务线隔离</p>\n<p>Group：A，B集群，平滑上线使用。</p>\n</li>\n</ul>\n<h3><span id=\"数据一致性保障\"> 数据一致性保障</span></h3>\n<ul>\n<li>Raft CP一致性\t【一般适不使用该模式】</li>\n<li>Distro AP一致性 【无主模式】</li>\n</ul>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802234926.png\" alt=\"image-20210802234926080\" style=\"zoom: 33%;\">\n<p>节点上线逻辑：【】</p>\n<p>节点下线逻辑：【】</p>\n<h2><span id=\"zookeeper实现深入剖析\"> Zookeeper实现深入剖析</span></h2>\n<h3><span id=\"选主逻辑\"> 选主逻辑</span></h3>\n<h4><span id=\"zk节点的角色\"> zk节点的角色</span></h4>\n<ul>\n<li>leader，响应写入请求，发起提案，超过半数follower同意写入，则写入成功。</li>\n<li>follower，响应查询，将写入请求转发给leader，参与选举 和 投票 以及写入操作。</li>\n<li>observer，响应查询，将写入请求转发给leader，不参与投票，只负责接收写入操作。</li>\n<li>leader，代表公司ceo，只输出提案，并最终确认提案；<br>follower，代表管理层，转发提案并参与投票，最终执行提案；<br>observer，代表一线员工，转发提案，不参与投票，执行提案。</li>\n</ul>\n<h4><span id=\"选主规则\"> 选主规则</span></h4>\n<ul>\n<li>\n<p>获得法定数量的票数，即follower 数量过半。</p>\n</li>\n<li>\n<p>判断依据</p>\n<ul>\n<li>Epoch：leader的任期</li>\n<li>ZXID：zookeeper的事务ID，越大表示事务越新</li>\n<li>SID：集群的每个节点唯一编号</li>\n<li>比较策略：连续排序，根据 任期、ZXID、SID 三个值，做比较。大的胜利。</li>\n</ul>\n</li>\n<li>\n<p>选主逻辑</p>\n<ul>\n<li>\n<p>节点进入 looking 状态</p>\n</li>\n<li>\n<p>广播发起投票，选出 最大 的节点，发起二次投票</p>\n</li>\n<li>\n<p>超过半数成为主。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"数据一致性保障\"> 数据一致性保障</span></h3>\n<ul>\n<li>zab协议， todo。</li>\n</ul>\n<h3><span id=\"数据模型\"> 数据模型</span></h3>\n<p>树状结构存储数据，分为永久节点和临时节点</p>\n<ul>\n<li>DataNode ，Zookeeper中存储的最小单元，是持久化数据节点描述的最小单位</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\">DataNode parent;  \t\t<span class=\"hljs-comment\">//父节点的引用 </span><br><span class=\"hljs-keyword\">byte</span> data[]; \t\t\t\t\t<span class=\"hljs-comment\">//该节点存储的数据</span><br>Long acl;\t\t\t\t\t\t\t<span class=\"hljs-comment\">//acl控制权限</span><br>StatPersisted stat; \t<span class=\"hljs-comment\">//持久化节点状态</span><br>Set&lt;String&gt; children; <span class=\"hljs-comment\">//子节点列表</span><br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>DataTree，以树形结构存储了zookeeper中所有的数据信息</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\">ConcurrentHashMap&lt;String, DataNode&gt; nodes;\t<span class=\"hljs-comment\">//当前树存的节点</span><br>WatchManager dataWatches;\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//数据变更通知</span><br>WatchManager childWatches;\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//节点变更通知</span><br>String rootZookeeper;\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//根节点</span><br>Map&lt;Long, HashSet&lt;String&gt;&gt; ephemerals\t\t\t\t<span class=\"hljs-comment\">//临时节点信息</span><br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>ZKDataBase，负责管理Zookeeper的数据、会话信息和事务日志</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\">DataTree dataTree;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//这zk的这棵树</span><br>ConcurrentHashMap&lt;Long, Integer&gt; sessionsWithTimeouts; \t<span class=\"hljs-comment\">//客户端会话连接管理 FileTxnSnapLog snapLog; \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//事务日志</span><br></code></pre></div></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"<p>这是摘要</p>","more":"<hr />\n<h1 id=\"注册中心的设计与选型\"><a class=\"markdownIt-Anchor\" href=\"#注册中心的设计与选型\"></a> 注册中心的设计与选型</h1>\n<h2 id=\"没有注册中心的解决方案\"><a class=\"markdownIt-Anchor\" href=\"#没有注册中心的解决方案\"></a> 没有注册中心的解决方案</h2>\n<ul>\n<li>通过全局配置文件，来规定服务ip的调用关系。<br>迁移、扩容的时候非常痛苦。</li>\n</ul>\n<h2 id=\"注册中心需要实现的点\"><a class=\"markdownIt-Anchor\" href=\"#注册中心需要实现的点\"></a> 注册中心，需要实现的点</h2>\n<h3 id=\"注册中心的主要功能\"><a class=\"markdownIt-Anchor\" href=\"#注册中心的主要功能\"></a> 注册中心的主要功能</h3>\n<h4 id=\"获取服务信息\"><a class=\"markdownIt-Anchor\" href=\"#获取服务信息\"></a> 获取服务信息</h4>\n<ul>\n<li>路由信息，服务注册节点的IP，端口。</li>\n<li>服务元数据信息，序列化协议，负载均衡规则，节点权重等</li>\n</ul>\n<h4 id=\"服务发现\"><a class=\"markdownIt-Anchor\" href=\"#服务发现\"></a> 服务发现：</h4>\n<ul>\n<li>\n<p>启动时拉：消费方启动后，先从注册中心获取提供方的节点列表</p>\n</li>\n<li>\n<p>通知回调：提供方的节点变更时，主动调用消费方，让消费方重新拉取节点数据</p>\n</li>\n<li>\n<p>轮询拉取：回调不一定总是成功，所以需要兜底策略：轮询，分钟级别。</p>\n</li>\n</ul>\n<h4 id=\"主动通知调用方服务节点发生变更\"><a class=\"markdownIt-Anchor\" href=\"#主动通知调用方服务节点发生变更\"></a> 主动通知调用方，服务节点发生变更</h4>\n<h4 id=\"机器迁移\"><a class=\"markdownIt-Anchor\" href=\"#机器迁移\"></a> 机器迁移</h4>\n<h4 id=\"权重\"><a class=\"markdownIt-Anchor\" href=\"#权重\"></a> 权重</h4>\n<h4 id=\"灰度流量\"><a class=\"markdownIt-Anchor\" href=\"#灰度流量\"></a> 灰度流量</h4>\n<h4 id=\"健康检查\"><a class=\"markdownIt-Anchor\" href=\"#健康检查\"></a> 健康检查</h4>\n<ul>\n<li>\n<p>一般情况下的服务失效原因</p>\n<ol>\n<li>部署重启，正常下线，可以主动通知注册中心</li>\n<li>服务异常终止，比如机器掉电，无法主动通知下线事件</li>\n<li>服务假死（注册中心线程可用，但工作线程不可用，表现起来就是依然可用向注册中心发心跳，但业务接口已经卡死不可用。）</li>\n</ol>\n</li>\n<li>\n<p>注册中心监控不健康节点的方案</p>\n<ul>\n<li>主动下线，能解决1</li>\n<li>心跳上报，能解决 1，2</li>\n<li>注册中心，主动探活，探测工作线程是否可用。能解决 1，2，3</li>\n<li>consumer 通过正常调用，也可以感知到对方服务是否假死。<br>也通过consumer上报异常，解决  1，2，3</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"注册中心的实现方案\"><a class=\"markdownIt-Anchor\" href=\"#注册中心的实现方案\"></a> 注册中心的实现方案</h2>\n<h3 id=\"业务模型\"><a class=\"markdownIt-Anchor\" href=\"#业务模型\"></a> 业务模型</h3>\n<ul>\n<li>消费者视角，主要关心的是服务的提供者的ip地址。</li>\n<li>提供者的角度，主要关系的是，本服务被哪些消费者注册消费了，方便提供者节点上下线的时候，主动通知消费者</li>\n</ul>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs json\">&#123;<br>    <span class=\"hljs-attr\">&quot;providerList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;addrSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br>        &#125;<br>    ],<br>    <span class=\"hljs-attr\">&quot;consumerList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;userSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;providerList&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr,addrSvr,productSvr&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;providerList&quot;</span>: <span class=\"hljs-string\">&quot;userSvr,addrSvr,productSvr&quot;</span><br><br>        &#125;<br>    ],<br>    <span class=\"hljs-attr\">&quot;ipList&quot;</span>: [<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;orderSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;ipList&quot;</span>: <span class=\"hljs-string\">&quot;xxxx,xxxx,xxxx&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;port&quot;</span>: <span class=\"hljs-string\">&quot;8081&quot;</span><br>        &#125;,<br>        &#123;<br>            <span class=\"hljs-attr\">&quot;serverName&quot;</span>: <span class=\"hljs-string\">&quot;userSvr&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;ipList&quot;</span>: <span class=\"hljs-string\">&quot;xxxx,xxxx,xxxx&quot;</span>,<br>            <span class=\"hljs-attr\">&quot;port&quot;</span>: <span class=\"hljs-string\">&quot;8082&quot;</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"超时处理\"><a class=\"markdownIt-Anchor\" href=\"#超时处理\"></a> 超时处理</h3>\n<ul>\n<li>\n<p>遍历扫描，以前的微服务注册中心，使用该方法即可，因为节点不多。</p>\n</li>\n<li>\n<p>动态分组算法，节点数量较多时使用，一般应用在 IM 中 长连接 keepalive 超时主动清理的扫描机制， 节点以10万为单位。遍历肯定不行</p>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210801012443.png\" alt=\"image-20210801012442966\" style=\"zoom:33%;\" />\n</li>\n</ul>\n<ol>\n<li>\n<p>该数据模型，如果n秒超时，有n个bucket。比如1分钟超时，就有60个bucket。</p>\n</li>\n<li>\n<p>这样每一个连接的超时时间，就能确定的放到某一个bucket里面，比如现在是53秒，有一个新的连接进来，那么新的连接就要放到。</p>\n</li>\n<li>\n<p>有一个游标一直轮询bucket，每一秒往后移动一格，当53秒的时候，移动到52号格子里，然后清理52号格子。</p>\n</li>\n</ol>\n<h3 id=\"变更通知\"><a class=\"markdownIt-Anchor\" href=\"#变更通知\"></a> 变更通知</h3>\n<h4 id=\"gossip协议\"><a class=\"markdownIt-Anchor\" href=\"#gossip协议\"></a> gossip协议</h4>\n<ul>\n<li>六度分离理论，周期性散播下线通知。</li>\n<li>随机选择n个节点，传递新数据，传x轮。每个节点获取新数据后，仍然选n个节点，传新数据，传x轮。</li>\n<li>避免不了重复传递，但无所谓。</li>\n<li>经过x/n轮后，所有节点已经更新数据。</li>\n</ul>\n<h2 id=\"开源注册中心选型\"><a class=\"markdownIt-Anchor\" href=\"#开源注册中心选型\"></a> 开源注册中心选型</h2>\n<h3 id=\"cap\"><a class=\"markdownIt-Anchor\" href=\"#cap\"></a> CAP</h3>\n<p>本质上，注册中心是一个高可用，高数据一致性的分布式存储，里面存了各个节点的数据。</p>\n<p>那么分布式cun存储，就要搬出CAP理论了：</p>\n<ul>\n<li>（partition toleran）数据可靠性，数据是冗余存储的，不会因为单节点故障导致数据整体丢失。</li>\n<li>（consistency）数据一致性，个节点间的数据，最终会保证统一。</li>\n<li>（availability）服务整体可用性，服务不间断对外提供服务。</li>\n</ul>\n<h3 id=\"ap-or-cp\"><a class=\"markdownIt-Anchor\" href=\"#ap-or-cp\"></a> AP or CP</h3>\n<ul>\n<li>\n<p>AP，牺牲一致性，保证不间断对外提供服务。<br>代表组件：<strong>eureka，nacos</strong></p>\n</li>\n<li>\n<p>CP，优先保证数据一致性，当发现数据不一致的时候，重新选举，然后同步数据；<br>在这期间，停止对外服务 <br>代表组件：<strong>zookeeper</strong></p>\n</li>\n<li>\n<p>总结：</p>\n<p>如果是<strong>注册中心</strong>：一定选取AP模式，对于注册中心这个产品，节点状态数据变动不频繁。<br>注册中心不能因为自身的任何原因，让程序变得不可用，这是注册中心设计应该遵循的铁律<br>注册中心，如果节点变动超过阈值，甚至要主动报警；并防止节点下线（保护模式）。</p>\n<p>如果是<strong>分布式协调器</strong>，分布式锁。则需要使用CP模式。</p>\n</li>\n</ul>\n<h3 id=\"注册中心的综合对比\"><a class=\"markdownIt-Anchor\" href=\"#注册中心的综合对比\"></a> 注册中心的综合对比</h3>\n<table>\n<thead>\n<tr>\n<th>特征</th>\n<th>zookeeper</th>\n<th style=\"text-align:left\">etcd</th>\n<th>consul</th>\n<th>eureka</th>\n<th>nacos</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>服务健康检查</td>\n<td>长连接</td>\n<td style=\"text-align:left\">心跳</td>\n<td>心跳</td>\n<td>心跳</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>多数据中心</td>\n<td>–</td>\n<td style=\"text-align:left\">–</td>\n<td>支持</td>\n<td>–</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>kv存储服务</td>\n<td>支持</td>\n<td style=\"text-align:left\">支持</td>\n<td>支持</td>\n<td>–</td>\n<td>支持</td>\n</tr>\n<tr>\n<td>一致性</td>\n<td>Zab</td>\n<td style=\"text-align:left\">raft</td>\n<td>raft</td>\n<td>弱一致性</td>\n<td>Distro</td>\n</tr>\n<tr>\n<td>CAP定理</td>\n<td>CP</td>\n<td style=\"text-align:left\">CP</td>\n<td>CP</td>\n<td>AP</td>\n<td>AP</td>\n</tr>\n<tr>\n<td>服务端<br>主动探活</td>\n<td>私有协议</td>\n<td style=\"text-align:left\">私有协议</td>\n<td>支持</td>\n<td>长轮询</td>\n<td>长轮询<br>v2使用长连接</td>\n</tr>\n<tr>\n<td>客户端访问</td>\n<td>SDK</td>\n<td style=\"text-align:left\">http</td>\n<td>http&amp;dns</td>\n<td>http</td>\n<td>http</td>\n</tr>\n<tr>\n<td>社区支持</td>\n<td>积极</td>\n<td style=\"text-align:left\">积极</td>\n<td>积极</td>\n<td>不积极</td>\n<td>积极</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"nacos注册中心深入分析\"><a class=\"markdownIt-Anchor\" href=\"#nacos注册中心深入分析\"></a> Nacos注册中心深入分析</h2>\n<h3 id=\"健康检查-2\"><a class=\"markdownIt-Anchor\" href=\"#健康检查-2\"></a> 健康检查</h3>\n<ul>\n<li>临时节点：心跳注册机制，ttl超时下线。</li>\n<li>持久化节点，比如数据库，使用服务端探活机制，标记不可用。如果不可用超过阈值，则报警。</li>\n<li>心跳阈值：5秒，上报；15秒，标记不健康；30秒，剔除节点</li>\n</ul>\n<h3 id=\"数据模型\"><a class=\"markdownIt-Anchor\" href=\"#数据模型\"></a> 数据模型</h3>\n<ul>\n<li>\n<p>数据存储，IP地址，端口，健康检查，ttl，权重。</p>\n</li>\n<li>\n<p>数据隔离，多重命名空间，User，NameSpace，Group</p>\n<p>User：多租户</p>\n<p>NameSpace：业务线隔离</p>\n<p>Group：A，B集群，平滑上线使用。</p>\n</li>\n</ul>\n<h3 id=\"数据一致性保障\"><a class=\"markdownIt-Anchor\" href=\"#数据一致性保障\"></a> 数据一致性保障</h3>\n<ul>\n<li>Raft CP一致性\t【一般适不使用该模式】</li>\n<li>Distro AP一致性 【无主模式】</li>\n</ul>\n<img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802234926.png\" alt=\"image-20210802234926080\" style=\"zoom: 33%;\" />\n<p>节点上线逻辑：【】</p>\n<p>节点下线逻辑：【】</p>\n<h2 id=\"zookeeper实现深入剖析\"><a class=\"markdownIt-Anchor\" href=\"#zookeeper实现深入剖析\"></a> Zookeeper实现深入剖析</h2>\n<h3 id=\"选主逻辑\"><a class=\"markdownIt-Anchor\" href=\"#选主逻辑\"></a> 选主逻辑</h3>\n<h4 id=\"zk节点的角色\"><a class=\"markdownIt-Anchor\" href=\"#zk节点的角色\"></a> zk节点的角色</h4>\n<ul>\n<li>leader，响应写入请求，发起提案，超过半数follower同意写入，则写入成功。</li>\n<li>follower，响应查询，将写入请求转发给leader，参与选举 和 投票 以及写入操作。</li>\n<li>observer，响应查询，将写入请求转发给leader，不参与投票，只负责接收写入操作。</li>\n<li>leader，代表公司ceo，只输出提案，并最终确认提案；<br>follower，代表管理层，转发提案并参与投票，最终执行提案；<br>observer，代表一线员工，转发提案，不参与投票，执行提案。</li>\n</ul>\n<h4 id=\"选主规则\"><a class=\"markdownIt-Anchor\" href=\"#选主规则\"></a> 选主规则</h4>\n<ul>\n<li>\n<p>获得法定数量的票数，即follower 数量过半。</p>\n</li>\n<li>\n<p>判断依据</p>\n<ul>\n<li>Epoch：leader的任期</li>\n<li>ZXID：zookeeper的事务ID，越大表示事务越新</li>\n<li>SID：集群的每个节点唯一编号</li>\n<li>比较策略：连续排序，根据 任期、ZXID、SID 三个值，做比较。大的胜利。</li>\n</ul>\n</li>\n<li>\n<p>选主逻辑</p>\n<ul>\n<li>\n<p>节点进入 looking 状态</p>\n</li>\n<li>\n<p>广播发起投票，选出 最大 的节点，发起二次投票</p>\n</li>\n<li>\n<p>超过半数成为主。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"数据一致性保障-2\"><a class=\"markdownIt-Anchor\" href=\"#数据一致性保障-2\"></a> 数据一致性保障</h3>\n<ul>\n<li>zab协议， todo。</li>\n</ul>\n<h3 id=\"数据模型-2\"><a class=\"markdownIt-Anchor\" href=\"#数据模型-2\"></a> 数据模型</h3>\n<p>树状结构存储数据，分为永久节点和临时节点</p>\n<ul>\n<li>DataNode ，Zookeeper中存储的最小单元，是持久化数据节点描述的最小单位</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\">DataNode parent;  \t\t<span class=\"hljs-comment\">//父节点的引用 </span><br><span class=\"hljs-keyword\">byte</span> data[]; \t\t\t\t\t<span class=\"hljs-comment\">//该节点存储的数据</span><br>Long acl;\t\t\t\t\t\t\t<span class=\"hljs-comment\">//acl控制权限</span><br>StatPersisted stat; \t<span class=\"hljs-comment\">//持久化节点状态</span><br>Set&lt;String&gt; children; <span class=\"hljs-comment\">//子节点列表</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>DataTree，以树形结构存储了zookeeper中所有的数据信息</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\">ConcurrentHashMap&lt;String, DataNode&gt; nodes;\t<span class=\"hljs-comment\">//当前树存的节点</span><br>WatchManager dataWatches;\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//数据变更通知</span><br>WatchManager childWatches;\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//节点变更通知</span><br>String rootZookeeper;\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//根节点</span><br>Map&lt;Long, HashSet&lt;String&gt;&gt; ephemerals\t\t\t\t<span class=\"hljs-comment\">//临时节点信息</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>ZKDataBase，负责管理Zookeeper的数据、会话信息和事务日志</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\">DataTree dataTree;\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"hljs-comment\">//这zk的这棵树</span><br>ConcurrentHashMap&lt;Long, Integer&gt; sessionsWithTimeouts; \t<span class=\"hljs-comment\">//客户端会话连接管理 FileTxnSnapLog snapLog; \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t//事务日志</span><br></code></pre></td></tr></table></figure>"},{"title":"kafka【1】概述","toc":true,"hide":false,"sortn":10,"date":"2021-08-02T04:07:04.000Z","_content":"\n\n<!-- more -->\n\n------\n\n\n\n# kafka【1】概述\n\n\n\n## 消息队列的两种模式\n\n### 点对点模式 (一对一)\n\n- 消费者主动拉取数据消息，消息拉取后，queue 中不再存储。\n- 支持存在多个消费者，但是一个消息只能有一个消费者可以消费\n\n\n\n### 发布/订阅模式 (Pub/Sub)\n\n- 消费者拉取数据后不会立即清除信息，但是保留是有期限的\n- 消息provider将消息发布到 Topic 中，同时有多个consumer订阅消息。 发布到 Topic 的消息会被所有订阅者消费\n- 发布/订阅模式的队列又分为\n  - 消费者主动 pull (Kafka)\n  - broker 主动 push\n\n\n\n![kafak机构图](https://cdn。jsdelivr.net/gh/coolflameSLZ/img/img20210802121218.png)\n","source":"_posts/消息系统/kafka【1】概述.md","raw":"---\ntitle: kafka【1】概述\ntoc: true\ncategories:\n  - 消息系统\n  - kafka\ntags:\n  - kafka\nhide: false\nsortn: 10\ndate: 2021-08-02 12:07:04\n---\n\n\n<!-- more -->\n\n------\n\n\n\n# kafka【1】概述\n\n\n\n## 消息队列的两种模式\n\n### 点对点模式 (一对一)\n\n- 消费者主动拉取数据消息，消息拉取后，queue 中不再存储。\n- 支持存在多个消费者，但是一个消息只能有一个消费者可以消费\n\n\n\n### 发布/订阅模式 (Pub/Sub)\n\n- 消费者拉取数据后不会立即清除信息，但是保留是有期限的\n- 消息provider将消息发布到 Topic 中，同时有多个consumer订阅消息。 发布到 Topic 的消息会被所有订阅者消费\n- 发布/订阅模式的队列又分为\n  - 消费者主动 pull (Kafka)\n  - broker 主动 push\n\n\n\n![kafak机构图](https://cdn。jsdelivr.net/gh/coolflameSLZ/img/img20210802121218.png)\n","slug":"消息系统/kafka【1】概述","published":1,"updated":"2021-08-02T04:07:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn2001ccpfyewdf8z1m","content":"<span id=\"more\"></span>\n<hr>\n<h1><span id=\"kafka1概述\"> kafka【1】概述</span></h1>\n<h2><span id=\"消息队列的两种模式\"> 消息队列的两种模式</span></h2>\n<h3><span id=\"点对点模式-一对一\"> 点对点模式 (一对一)</span></h3>\n<ul>\n<li>消费者主动拉取数据消息，消息拉取后，queue 中不再存储。</li>\n<li>支持存在多个消费者，但是一个消息只能有一个消费者可以消费</li>\n</ul>\n<h3><span id=\"发布订阅模式-pubsub\"> 发布/订阅模式 (Pub/Sub)</span></h3>\n<ul>\n<li>消费者拉取数据后不会立即清除信息，但是保留是有期限的</li>\n<li>消息provider将消息发布到 Topic 中，同时有多个consumer订阅消息。 发布到 Topic 的消息会被所有订阅者消费</li>\n<li>发布/订阅模式的队列又分为\n<ul>\n<li>消费者主动 pull (Kafka)</li>\n<li>broker 主动 push</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802121218.png\" alt=\"kafak机构图\"></p>\n","site":{"data":{}},"excerpt":"","more":"<hr />\n<h1 id=\"kafka1概述\"><a class=\"markdownIt-Anchor\" href=\"#kafka1概述\"></a> kafka【1】概述</h1>\n<h2 id=\"消息队列的两种模式\"><a class=\"markdownIt-Anchor\" href=\"#消息队列的两种模式\"></a> 消息队列的两种模式</h2>\n<h3 id=\"点对点模式-一对一\"><a class=\"markdownIt-Anchor\" href=\"#点对点模式-一对一\"></a> 点对点模式 (一对一)</h3>\n<ul>\n<li>消费者主动拉取数据消息，消息拉取后，queue 中不再存储。</li>\n<li>支持存在多个消费者，但是一个消息只能有一个消费者可以消费</li>\n</ul>\n<h3 id=\"发布订阅模式-pubsub\"><a class=\"markdownIt-Anchor\" href=\"#发布订阅模式-pubsub\"></a> 发布/订阅模式 (Pub/Sub)</h3>\n<ul>\n<li>消费者拉取数据后不会立即清除信息，但是保留是有期限的</li>\n<li>消息provider将消息发布到 Topic 中，同时有多个consumer订阅消息。 发布到 Topic 的消息会被所有订阅者消费</li>\n<li>发布/订阅模式的队列又分为\n<ul>\n<li>消费者主动 pull (Kafka)</li>\n<li>broker 主动 push</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://cdn.jsdelivr.net/gh/coolflameSLZ/img/img20210802121218.png\" alt=\"kafak机构图\" /></p>"},{"title":"kafka【2】版本&部署规划","toc":true,"hide":false,"sortn":20,"date":"2021-08-02T04:26:02.000Z","_content":"\n\n\n<!-- more -->\n\n------\n\n\n\n## 版本选择\n\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0\n\n\n\n### 最低版本使用要求：\n\n- （总体上不建议使用）\n\n- 至少要选择 0.8.2.2 ，\n- 使用 老版本 Producer API ， \n- 老版本 Consumer API。\n\n### 0.9版本注意事项：\n\n- （总体上不建议使用）\n\n- 必须使用 新版本Producer API ，老版本Consumer API\n- 不要使用0.9版本中的 新版本Consumer API ，bug超多\n\n### 0.10版本注意事项：\n\n- 如果使用的话，就用最优小版本 **0.10.2.2**\n\n- 0.10.2.2 版本起，使用 新版本 Producer API ，新版本 Consumer API \n- 0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug， 基于性能的缘故你也应该升级到 0.10.2.2\n\n### 0.11版本注意事项：\n\n- 如果使用的话，就用最优小版本 **0.11.0.3**\n\n- 0.11.0.3版本，引入了两个重量级的功能\n  - 幂等性 Producer API 以及 事务 Transaction API\n  - 对 Kafka 消息格式做了重构。\n\n### 1.0、2.0版本\n\n- 主要增加的功能是流处理计算功能，\n- 消息引擎方面，没什么变更。\n- 如果不使用流处理功能，则不用升级。\n\n### 版本选择总结：\n\n- 无需流处理功能，则选择尽量将版本选为 0.11.0.3，这个版本的消息引擎功能已经非常完善了\n\n- 不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致， 否则可能损失很多 Kafka 为你提供的性能优化收益\n\n  \n\n## 部署方式\n\n\n\n### 操作系统选择linux\n\n- 实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能\n- 在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的 快速数据传输特性\n\n\n\n### 硬盘是否需要RAID\n\n- kafka自带高可用策略，无需RAID，使用普通磁盘组成存储空间即可。 使用机械磁盘完全能够胜任 Kafka 线上环境。\n\n  \n\n### 硬盘容量规划\n\n- 规划磁盘容量时你需要考虑下面这几个元素\n  - 新增消息数\n  - 消息留存时间\n  - 平均消息大小\n  - 备份数\n  - 是否启用压缩\n- 其实，硬盘不是瓶颈，给足就好。带宽才是。\n\n\n\n### 带宽计算公式\n\n- 带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上\n\n- 即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。 这里的其实是相当保守的，你可以结合你自己机器的使用情况酌情减少此值。\n\n- 举例：<br>\n\n  1小时处理1TB为目标。 根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台\n","source":"_posts/消息系统/kafka【2】版本&部署规划.md","raw":"---\ntitle: kafka【2】版本&部署规划\ntoc: true\ncategories:\n  - 消息系统\n  - kafka\ntags:\n  - kafka\nhide: false\nsortn: 20\ndate: 2021-08-02 12:26:02\n---\n\n\n\n<!-- more -->\n\n------\n\n\n\n## 版本选择\n\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0\n\n\n\n### 最低版本使用要求：\n\n- （总体上不建议使用）\n\n- 至少要选择 0.8.2.2 ，\n- 使用 老版本 Producer API ， \n- 老版本 Consumer API。\n\n### 0.9版本注意事项：\n\n- （总体上不建议使用）\n\n- 必须使用 新版本Producer API ，老版本Consumer API\n- 不要使用0.9版本中的 新版本Consumer API ，bug超多\n\n### 0.10版本注意事项：\n\n- 如果使用的话，就用最优小版本 **0.10.2.2**\n\n- 0.10.2.2 版本起，使用 新版本 Producer API ，新版本 Consumer API \n- 0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug， 基于性能的缘故你也应该升级到 0.10.2.2\n\n### 0.11版本注意事项：\n\n- 如果使用的话，就用最优小版本 **0.11.0.3**\n\n- 0.11.0.3版本，引入了两个重量级的功能\n  - 幂等性 Producer API 以及 事务 Transaction API\n  - 对 Kafka 消息格式做了重构。\n\n### 1.0、2.0版本\n\n- 主要增加的功能是流处理计算功能，\n- 消息引擎方面，没什么变更。\n- 如果不使用流处理功能，则不用升级。\n\n### 版本选择总结：\n\n- 无需流处理功能，则选择尽量将版本选为 0.11.0.3，这个版本的消息引擎功能已经非常完善了\n\n- 不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致， 否则可能损失很多 Kafka 为你提供的性能优化收益\n\n  \n\n## 部署方式\n\n\n\n### 操作系统选择linux\n\n- 实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能\n- 在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的 快速数据传输特性\n\n\n\n### 硬盘是否需要RAID\n\n- kafka自带高可用策略，无需RAID，使用普通磁盘组成存储空间即可。 使用机械磁盘完全能够胜任 Kafka 线上环境。\n\n  \n\n### 硬盘容量规划\n\n- 规划磁盘容量时你需要考虑下面这几个元素\n  - 新增消息数\n  - 消息留存时间\n  - 平均消息大小\n  - 备份数\n  - 是否启用压缩\n- 其实，硬盘不是瓶颈，给足就好。带宽才是。\n\n\n\n### 带宽计算公式\n\n- 带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上\n\n- 即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。 这里的其实是相当保守的，你可以结合你自己机器的使用情况酌情减少此值。\n\n- 举例：<br>\n\n  1小时处理1TB为目标。 根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台\n","slug":"消息系统/kafka【2】版本&部署规划","published":1,"updated":"2021-08-02T04:26:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn3001gcpfydp892qnt","content":"<span id=\"more\"></span>\n<hr>\n<h2><span id=\"版本选择\"> 版本选择</span></h2>\n<p>Kafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0</p>\n<h3><span id=\"最低版本使用要求\"> 最低版本使用要求：</span></h3>\n<ul>\n<li>\n<p>（总体上不建议使用）</p>\n</li>\n<li>\n<p>至少要选择 0.8.2.2 ，</p>\n</li>\n<li>\n<p>使用 老版本 Producer API ，</p>\n</li>\n<li>\n<p>老版本 Consumer API。</p>\n</li>\n</ul>\n<h3><span id=\"09版本注意事项\"> 0.9版本注意事项：</span></h3>\n<ul>\n<li>\n<p>（总体上不建议使用）</p>\n</li>\n<li>\n<p>必须使用 新版本Producer API ，老版本Consumer API</p>\n</li>\n<li>\n<p>不要使用0.9版本中的 新版本Consumer API ，bug超多</p>\n</li>\n</ul>\n<h3><span id=\"010版本注意事项\"> 0.10版本注意事项：</span></h3>\n<ul>\n<li>\n<p>如果使用的话，就用最优小版本 <strong>0.10.2.2</strong></p>\n</li>\n<li>\n<p>0.10.2.2 版本起，使用 新版本 Producer API ，新版本 Consumer API</p>\n</li>\n<li>\n<p>0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug， 基于性能的缘故你也应该升级到 0.10.2.2</p>\n</li>\n</ul>\n<h3><span id=\"011版本注意事项\"> 0.11版本注意事项：</span></h3>\n<ul>\n<li>\n<p>如果使用的话，就用最优小版本 <strong>0.11.0.3</strong></p>\n</li>\n<li>\n<p>0.11.0.3版本，引入了两个重量级的功能</p>\n<ul>\n<li>幂等性 Producer API 以及 事务 Transaction API</li>\n<li>对 Kafka 消息格式做了重构。</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"10-20版本\"> 1.0、2.0版本</span></h3>\n<ul>\n<li>主要增加的功能是流处理计算功能，</li>\n<li>消息引擎方面，没什么变更。</li>\n<li>如果不使用流处理功能，则不用升级。</li>\n</ul>\n<h3><span id=\"版本选择总结\"> 版本选择总结：</span></h3>\n<ul>\n<li>\n<p>无需流处理功能，则选择尽量将版本选为 0.11.0.3，这个版本的消息引擎功能已经非常完善了</p>\n</li>\n<li>\n<p>不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致， 否则可能损失很多 Kafka 为你提供的性能优化收益</p>\n</li>\n</ul>\n<h2><span id=\"部署方式\"> 部署方式</span></h2>\n<h3><span id=\"操作系统选择linux\"> 操作系统选择linux</span></h3>\n<ul>\n<li>实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能</li>\n<li>在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的 快速数据传输特性</li>\n</ul>\n<h3><span id=\"硬盘是否需要raid\"> 硬盘是否需要RAID</span></h3>\n<ul>\n<li>kafka自带高可用策略，无需RAID，使用普通磁盘组成存储空间即可。 使用机械磁盘完全能够胜任 Kafka 线上环境。</li>\n</ul>\n<h3><span id=\"硬盘容量规划\"> 硬盘容量规划</span></h3>\n<ul>\n<li>规划磁盘容量时你需要考虑下面这几个元素\n<ul>\n<li>新增消息数</li>\n<li>消息留存时间</li>\n<li>平均消息大小</li>\n<li>备份数</li>\n<li>是否启用压缩</li>\n</ul>\n</li>\n<li>其实，硬盘不是瓶颈，给足就好。带宽才是。</li>\n</ul>\n<h3><span id=\"带宽计算公式\"> 带宽计算公式</span></h3>\n<ul>\n<li>\n<p>带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上</p>\n</li>\n<li>\n<p>即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。 这里的其实是相当保守的，你可以结合你自己机器的使用情况酌情减少此值。</p>\n</li>\n<li>\n<p>举例：<br></p>\n<p>1小时处理1TB为目标。 根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<hr />\n<h2 id=\"版本选择\"><a class=\"markdownIt-Anchor\" href=\"#版本选择\"></a> 版本选择</h2>\n<p>Kafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0</p>\n<h3 id=\"最低版本使用要求\"><a class=\"markdownIt-Anchor\" href=\"#最低版本使用要求\"></a> 最低版本使用要求：</h3>\n<ul>\n<li>\n<p>（总体上不建议使用）</p>\n</li>\n<li>\n<p>至少要选择 0.8.2.2 ，</p>\n</li>\n<li>\n<p>使用 老版本 Producer API ，</p>\n</li>\n<li>\n<p>老版本 Consumer API。</p>\n</li>\n</ul>\n<h3 id=\"09版本注意事项\"><a class=\"markdownIt-Anchor\" href=\"#09版本注意事项\"></a> 0.9版本注意事项：</h3>\n<ul>\n<li>\n<p>（总体上不建议使用）</p>\n</li>\n<li>\n<p>必须使用 新版本Producer API ，老版本Consumer API</p>\n</li>\n<li>\n<p>不要使用0.9版本中的 新版本Consumer API ，bug超多</p>\n</li>\n</ul>\n<h3 id=\"010版本注意事项\"><a class=\"markdownIt-Anchor\" href=\"#010版本注意事项\"></a> 0.10版本注意事项：</h3>\n<ul>\n<li>\n<p>如果使用的话，就用最优小版本 <strong>0.10.2.2</strong></p>\n</li>\n<li>\n<p>0.10.2.2 版本起，使用 新版本 Producer API ，新版本 Consumer API</p>\n</li>\n<li>\n<p>0.10.2.2 修复了一个可能导致 Producer 性能降低的 Bug， 基于性能的缘故你也应该升级到 0.10.2.2</p>\n</li>\n</ul>\n<h3 id=\"011版本注意事项\"><a class=\"markdownIt-Anchor\" href=\"#011版本注意事项\"></a> 0.11版本注意事项：</h3>\n<ul>\n<li>\n<p>如果使用的话，就用最优小版本 <strong>0.11.0.3</strong></p>\n</li>\n<li>\n<p>0.11.0.3版本，引入了两个重量级的功能</p>\n<ul>\n<li>幂等性 Producer API 以及 事务 Transaction API</li>\n<li>对 Kafka 消息格式做了重构。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"10-20版本\"><a class=\"markdownIt-Anchor\" href=\"#10-20版本\"></a> 1.0、2.0版本</h3>\n<ul>\n<li>主要增加的功能是流处理计算功能，</li>\n<li>消息引擎方面，没什么变更。</li>\n<li>如果不使用流处理功能，则不用升级。</li>\n</ul>\n<h3 id=\"版本选择总结\"><a class=\"markdownIt-Anchor\" href=\"#版本选择总结\"></a> 版本选择总结：</h3>\n<ul>\n<li>\n<p>无需流处理功能，则选择尽量将版本选为 0.11.0.3，这个版本的消息引擎功能已经非常完善了</p>\n</li>\n<li>\n<p>不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致， 否则可能损失很多 Kafka 为你提供的性能优化收益</p>\n</li>\n</ul>\n<h2 id=\"部署方式\"><a class=\"markdownIt-Anchor\" href=\"#部署方式\"></a> 部署方式</h2>\n<h3 id=\"操作系统选择linux\"><a class=\"markdownIt-Anchor\" href=\"#操作系统选择linux\"></a> 操作系统选择linux</h3>\n<ul>\n<li>实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能</li>\n<li>在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的 快速数据传输特性</li>\n</ul>\n<h3 id=\"硬盘是否需要raid\"><a class=\"markdownIt-Anchor\" href=\"#硬盘是否需要raid\"></a> 硬盘是否需要RAID</h3>\n<ul>\n<li>kafka自带高可用策略，无需RAID，使用普通磁盘组成存储空间即可。 使用机械磁盘完全能够胜任 Kafka 线上环境。</li>\n</ul>\n<h3 id=\"硬盘容量规划\"><a class=\"markdownIt-Anchor\" href=\"#硬盘容量规划\"></a> 硬盘容量规划</h3>\n<ul>\n<li>规划磁盘容量时你需要考虑下面这几个元素\n<ul>\n<li>新增消息数</li>\n<li>消息留存时间</li>\n<li>平均消息大小</li>\n<li>备份数</li>\n<li>是否启用压缩</li>\n</ul>\n</li>\n<li>其实，硬盘不是瓶颈，给足就好。带宽才是。</li>\n</ul>\n<h3 id=\"带宽计算公式\"><a class=\"markdownIt-Anchor\" href=\"#带宽计算公式\"></a> 带宽计算公式</h3>\n<ul>\n<li>\n<p>带宽资源不足导致 Kafka 出现性能问题的比例至少占 60% 以上</p>\n</li>\n<li>\n<p>即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。 这里的其实是相当保守的，你可以结合你自己机器的使用情况酌情减少此值。</p>\n</li>\n<li>\n<p>举例：<br></p>\n<p>1小时处理1TB为目标。 根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台</p>\n</li>\n</ul>"},{"title":"kafka【3】server端配置实践","toc":true,"hide":false,"sortn":30,"date":"2021-08-02T04:44:22.000Z","_content":"\n这是摘要\n<!-- more -->\n\n------\n\n\n\n## **Broker 端参数**\n\n### 基本配置\n\n#### log.dirs\n\n- 这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。\n- 在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3\n- 如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上 多块物理磁盘同时读写数据有更高的吞吐量。 能够实现故障转移\n\n\n\n### 配置zookeeper\n\n####  zookeeper.connect\n\n- 非常重要的参数，代表了zk的地址。\n- 这也是一个 CSV 格式的参数，比 如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。\n- 如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定:\n  - zk1:2181,zk2:2181,zk3:2181/kafka1和 zk1:2181,zk2:2181,zk3:2181/kafka2。\n  - kafkaName 只需要写一次，而且是加到最后的。<br>反例 : zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3，这样的格式是不对的。\n\n\n\n### Broker连接\n\n#### compression.type\n\n设置成producer，要按照生产者压缩格式来，防止 broker出现消息解压缩。\n\n#### unclean.leader.election.enable\n\nunclean.leader.election.enable = false。 如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false\n\n#### replication.factor\n\nreplication.factor 配置要大于等于3。 最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余\n\n#### min.insync.replicas\n\nmin.insync.replicas 至少要大于1。 本属性代表，消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。\n\n确保 replication.factor > min.insync.replicas。 推荐设置成 replication.factor = min.insync.replicas + 1。\n\n\n\n### Topic管理\n\n#### auto.create.topics.enable\n\n是否允许自动创建 Topic。建议否，由运维管理，要不然乱七八糟的topic满天飞。\n\n#### unclean.leader.election.enable\n\n是否允许 Unclean Leader 选举。建议你还是显式地把它设置成 false\n\n#### auto.leader.rebalance.enable\n\n是否允许定期进行 Leader 选举，建议在生产环境中把这个参数设置成 false，系统正常运行，没必要整活\n\n\n\n### 数据留存\n\n#### log.retention.{hour|minutes|ms}\n\n都是控制一条消息数据被保存多长时间，根据业务需求来。\n\n#### log.retention.bytes\n\n这是指定 Broker 为消息保存的总磁盘容量大小 \n\n#### message.max.bytes\n\n控制 Broker 能够接收的最大消息大小。<br>默认的 1000012 (1MB)太少了，因此在线上环境中设置一个比较大的值比较保险。根据业务情况来\n","source":"_posts/消息系统/kafka【3】server端配置实践.md","raw":"---\ntitle: kafka【3】server端配置实践\ntoc: true\ncategories:\n  - 消息系统\n  - kafka\ntags:\n  - kafka\nhide: false\nsortn: 30\ndate: 2021-08-02 12:44:22\n---\n\n这是摘要\n<!-- more -->\n\n------\n\n\n\n## **Broker 端参数**\n\n### 基本配置\n\n#### log.dirs\n\n- 这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。\n- 在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3\n- 如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上 多块物理磁盘同时读写数据有更高的吞吐量。 能够实现故障转移\n\n\n\n### 配置zookeeper\n\n####  zookeeper.connect\n\n- 非常重要的参数，代表了zk的地址。\n- 这也是一个 CSV 格式的参数，比 如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。\n- 如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定:\n  - zk1:2181,zk2:2181,zk3:2181/kafka1和 zk1:2181,zk2:2181,zk3:2181/kafka2。\n  - kafkaName 只需要写一次，而且是加到最后的。<br>反例 : zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3，这样的格式是不对的。\n\n\n\n### Broker连接\n\n#### compression.type\n\n设置成producer，要按照生产者压缩格式来，防止 broker出现消息解压缩。\n\n#### unclean.leader.election.enable\n\nunclean.leader.election.enable = false。 如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false\n\n#### replication.factor\n\nreplication.factor 配置要大于等于3。 最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余\n\n#### min.insync.replicas\n\nmin.insync.replicas 至少要大于1。 本属性代表，消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。\n\n确保 replication.factor > min.insync.replicas。 推荐设置成 replication.factor = min.insync.replicas + 1。\n\n\n\n### Topic管理\n\n#### auto.create.topics.enable\n\n是否允许自动创建 Topic。建议否，由运维管理，要不然乱七八糟的topic满天飞。\n\n#### unclean.leader.election.enable\n\n是否允许 Unclean Leader 选举。建议你还是显式地把它设置成 false\n\n#### auto.leader.rebalance.enable\n\n是否允许定期进行 Leader 选举，建议在生产环境中把这个参数设置成 false，系统正常运行，没必要整活\n\n\n\n### 数据留存\n\n#### log.retention.{hour|minutes|ms}\n\n都是控制一条消息数据被保存多长时间，根据业务需求来。\n\n#### log.retention.bytes\n\n这是指定 Broker 为消息保存的总磁盘容量大小 \n\n#### message.max.bytes\n\n控制 Broker 能够接收的最大消息大小。<br>默认的 1000012 (1MB)太少了，因此在线上环境中设置一个比较大的值比较保险。根据业务情况来\n","slug":"消息系统/kafka【3】server端配置实践","published":1,"updated":"2021-08-02T04:44:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn4001icpfy3p8782yr","content":"<p>这是摘要</p>\n<span id=\"more\"></span>\n<hr>\n<h2><span id=\"broker-端参数\"> <strong>Broker 端参数</strong></span></h2>\n<h3><span id=\"基本配置\"> 基本配置</span></h3>\n<h4><span id=\"logdirs\"> log.dirs</span></h4>\n<ul>\n<li>这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。</li>\n<li>在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3</li>\n<li>如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上 多块物理磁盘同时读写数据有更高的吞吐量。 能够实现故障转移</li>\n</ul>\n<h3><span id=\"配置zookeeper\"> 配置zookeeper</span></h3>\n<h4><span id=\"zookeeperconnect\"> zookeeper.connect</span></h4>\n<ul>\n<li>非常重要的参数，代表了zk的地址。</li>\n<li>这也是一个 CSV 格式的参数，比 如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。</li>\n<li>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定:\n<ul>\n<li>zk1:2181,zk2:2181,zk3:2181/kafka1和 zk1:2181,zk2:2181,zk3:2181/kafka2。</li>\n<li>kafkaName 只需要写一次，而且是加到最后的。<br>反例 : zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3，这样的格式是不对的。</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"broker连接\"> Broker连接</span></h3>\n<h4><span id=\"compressiontype\"> compression.type</span></h4>\n<p>设置成producer，要按照生产者压缩格式来，防止 broker出现消息解压缩。</p>\n<h4><span id=\"uncleanleaderelectionenable\"> unclean.leader.election.enable</span></h4>\n<p>unclean.leader.election.enable = false。 如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false</p>\n<h4><span id=\"replicationfactor\"> replication.factor</span></h4>\n<p>replication.factor 配置要大于等于3。 最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余</p>\n<h4><span id=\"mininsyncreplicas\"> min.insync.replicas</span></h4>\n<p>min.insync.replicas 至少要大于1。 本属性代表，消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</p>\n<p>确保 replication.factor &gt; min.insync.replicas。 推荐设置成 replication.factor = min.insync.replicas + 1。</p>\n<h3><span id=\"topic管理\"> Topic管理</span></h3>\n<h4><span id=\"autocreatetopicsenable\"> auto.create.topics.enable</span></h4>\n<p>是否允许自动创建 Topic。建议否，由运维管理，要不然乱七八糟的topic满天飞。</p>\n<h4><span id=\"uncleanleaderelectionenable\"> unclean.leader.election.enable</span></h4>\n<p>是否允许 Unclean Leader 选举。建议你还是显式地把它设置成 false</p>\n<h4><span id=\"autoleaderrebalanceenable\"> auto.leader.rebalance.enable</span></h4>\n<p>是否允许定期进行 Leader 选举，建议在生产环境中把这个参数设置成 false，系统正常运行，没必要整活</p>\n<h3><span id=\"数据留存\"> 数据留存</span></h3>\n<h4><span id=\"logretentionhourminutesms\"> log.retention.{hour|minutes|ms}</span></h4>\n<p>都是控制一条消息数据被保存多长时间，根据业务需求来。</p>\n<h4><span id=\"logretentionbytes\"> log.retention.bytes</span></h4>\n<p>这是指定 Broker 为消息保存的总磁盘容量大小</p>\n<h4><span id=\"messagemaxbytes\"> message.max.bytes</span></h4>\n<p>控制 Broker 能够接收的最大消息大小。<br>默认的 1000012 (1MB)太少了，因此在线上环境中设置一个比较大的值比较保险。根据业务情况来</p>\n","site":{"data":{}},"excerpt":"<p>这是摘要</p>","more":"<hr />\n<h2 id=\"broker-端参数\"><a class=\"markdownIt-Anchor\" href=\"#broker-端参数\"></a> <strong>Broker 端参数</strong></h2>\n<h3 id=\"基本配置\"><a class=\"markdownIt-Anchor\" href=\"#基本配置\"></a> 基本配置</h3>\n<h4 id=\"logdirs\"><a class=\"markdownIt-Anchor\" href=\"#logdirs\"></a> log.dirs</h4>\n<ul>\n<li>这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。</li>\n<li>在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3</li>\n<li>如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上 多块物理磁盘同时读写数据有更高的吞吐量。 能够实现故障转移</li>\n</ul>\n<h3 id=\"配置zookeeper\"><a class=\"markdownIt-Anchor\" href=\"#配置zookeeper\"></a> 配置zookeeper</h3>\n<h4 id=\"zookeeperconnect\"><a class=\"markdownIt-Anchor\" href=\"#zookeeperconnect\"></a> zookeeper.connect</h4>\n<ul>\n<li>非常重要的参数，代表了zk的地址。</li>\n<li>这也是一个 CSV 格式的参数，比 如我可以指定它的值为 zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper 的默认端口。</li>\n<li>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定:\n<ul>\n<li>zk1:2181,zk2:2181,zk3:2181/kafka1和 zk1:2181,zk2:2181,zk3:2181/kafka2。</li>\n<li>kafkaName 只需要写一次，而且是加到最后的。<br>反例 : zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3，这样的格式是不对的。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"broker连接\"><a class=\"markdownIt-Anchor\" href=\"#broker连接\"></a> Broker连接</h3>\n<h4 id=\"compressiontype\"><a class=\"markdownIt-Anchor\" href=\"#compressiontype\"></a> compression.type</h4>\n<p>设置成producer，要按照生产者压缩格式来，防止 broker出现消息解压缩。</p>\n<h4 id=\"uncleanleaderelectionenable\"><a class=\"markdownIt-Anchor\" href=\"#uncleanleaderelectionenable\"></a> unclean.leader.election.enable</h4>\n<p>unclean.leader.election.enable = false。 如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false</p>\n<h4 id=\"replicationfactor\"><a class=\"markdownIt-Anchor\" href=\"#replicationfactor\"></a> replication.factor</h4>\n<p>replication.factor 配置要大于等于3。 最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余</p>\n<h4 id=\"mininsyncreplicas\"><a class=\"markdownIt-Anchor\" href=\"#mininsyncreplicas\"></a> min.insync.replicas</h4>\n<p>min.insync.replicas 至少要大于1。 本属性代表，消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。</p>\n<p>确保 replication.factor &gt; min.insync.replicas。 推荐设置成 replication.factor = min.insync.replicas + 1。</p>\n<h3 id=\"topic管理\"><a class=\"markdownIt-Anchor\" href=\"#topic管理\"></a> Topic管理</h3>\n<h4 id=\"autocreatetopicsenable\"><a class=\"markdownIt-Anchor\" href=\"#autocreatetopicsenable\"></a> auto.create.topics.enable</h4>\n<p>是否允许自动创建 Topic。建议否，由运维管理，要不然乱七八糟的topic满天飞。</p>\n<h4 id=\"uncleanleaderelectionenable-2\"><a class=\"markdownIt-Anchor\" href=\"#uncleanleaderelectionenable-2\"></a> unclean.leader.election.enable</h4>\n<p>是否允许 Unclean Leader 选举。建议你还是显式地把它设置成 false</p>\n<h4 id=\"autoleaderrebalanceenable\"><a class=\"markdownIt-Anchor\" href=\"#autoleaderrebalanceenable\"></a> auto.leader.rebalance.enable</h4>\n<p>是否允许定期进行 Leader 选举，建议在生产环境中把这个参数设置成 false，系统正常运行，没必要整活</p>\n<h3 id=\"数据留存\"><a class=\"markdownIt-Anchor\" href=\"#数据留存\"></a> 数据留存</h3>\n<h4 id=\"logretentionhourminutesms\"><a class=\"markdownIt-Anchor\" href=\"#logretentionhourminutesms\"></a> log.retention.{hour|minutes|ms}</h4>\n<p>都是控制一条消息数据被保存多长时间，根据业务需求来。</p>\n<h4 id=\"logretentionbytes\"><a class=\"markdownIt-Anchor\" href=\"#logretentionbytes\"></a> log.retention.bytes</h4>\n<p>这是指定 Broker 为消息保存的总磁盘容量大小</p>\n<h4 id=\"messagemaxbytes\"><a class=\"markdownIt-Anchor\" href=\"#messagemaxbytes\"></a> message.max.bytes</h4>\n<p>控制 Broker 能够接收的最大消息大小。<br>默认的 1000012 (1MB)太少了，因此在线上环境中设置一个比较大的值比较保险。根据业务情况来</p>"},{"title":"kafka【4】client端最佳实践","toc":true,"hide":false,"sortn":40,"date":"2021-08-02T05:19:51.000Z","_content":"\n\n<!-- more -->\n\n------\n\n# kafka【4】client端最佳实践\n\n\n\n## 生产者分区策略\n\n### 分区策略的意义\n\n- 分区实际上是调优Kafka并行度的最小单元\n\n- 所谓分区策略是决定生产者将消息发送到哪个分区的算法。\n\n- 如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。\n\n  \n\n### 自带的分区策略\n\n#### 轮询策略\n\n- 能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略\n\n#### 随机策略\n\n- 如果追求数据的均匀分布，还是使用轮询策略比较好，随机策略暂时没想到场景\n\n#### 按照key分区 Key-ordering 策略\n\n- 一旦消息被定义了 Key，则使用 key-ordering 策略，同一个 Key 的所有消息都进入到相同的partition\n- kafka只能保证同partition下的消息处理都是有顺序的，partition间无法做到有序。\n- 如果所有数据都用这一个key，会导致分区数据不平衡，降低吞吐量。所以建议使用区分度较大的值作为key。比如 uid，pid，不要使用 status、if_xxx等\n- 没有找到一个区分度大的key，又要保持顺序，则不要使用kafka，rocketMq不错。\n\n\n\n### 自定义分区策略\n\n- 编写生产者程序时，可以自定义分区策略接口 \n\n```java\n// org.apache.kafka.clients.producer.Partitioner \nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)\n\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic); \nreturn Math.abs(key.hashCode()) % partitions.size();\n\n```\n\n\n\n\n\n## producer 端配置实践\n\n\n\n### 生产者基本配置\n\n#### 消息版本\n\nProducer 和 Broker 的消息版本要统一（如果不统一，Broker要进行消息解析）\n\n#### 压缩\n\n- 最好开启LZ4压缩。\n- 压缩配置，Producer 端压缩、Broker 端保持、Consumer 端解压缩。\n\n#### 提交策略\n\n- 设置 acks = master。代表master Broker 收到消息，消息就算“已提交”。 \n- 设置 acks = all。 代表所有副本Broker 都接收到消息，该消息才算是“已提交”。\n\n#### 重试次数\n\n设置 retries 为一个较大的值 比如3\n\n#### 提交的方法\n\n使用 producer.send(msg, callback)，必须实现回调函数。\n\n\n\n#### 幂等消息\n\n- 幂等消息是 0.11.0.0 版本以后，引入的 \n- 开启方法：设置enable.idempotence=ture\n- 注意事项：\n  - 只能保证单分区上的幂等性，且当 Producer 进程重启以后之后，这种幂等性保证就丧失了\n  - 需要 **多分区，多会话**上的消息无重复，需要使用事务型Producer\n\n\n\n#### 事务型 Producer\n\n- 保证一批消息原子性地写入到多个分区中，这批消息要么全部写入成功，要么全部失败。\n\n- **开启方法**：\n\n  - 配置 enable.idempotence=ture\n\n  - 使用下面方法生产消息\n\n    ```java\n    //发送代码\n    producer.initTransactions();\n    try {\n                producer.beginTransaction();\n                producer.send(record1);\n                producer.send(record2);\n                producer.commitTransaction();\n    } catch (KafkaException e) {\n                producer.abortTransaction();\n    }\n    ```\n\n  - **需要注意**，事务消息，在consumer端也要进行配置成 read_committed，表明 Consumer 只会消费 事务型 Producer 成功提交事务写入的消息。<br>Consumer 默认 read_uncommitted ， 表示消费者会消费所有消息，如果用了事务型 Producer，对应的 Consumer 就不要使用这个值，这是个坑。\n\n\n\n\n\n## 消费者注意事项\n\n### 基本原则\n\n- 先实际消费，再提交位移。\n\n- 默认先关闭自动提交 enable.auto.commit =  false ， 看场景选择是否打开。\n\n- 必须配置消费者连接超时间， connection.max.idle.ms \n\n- 一个分区，只能被一个消费者消费。Consumer 实例的数量应该等于该 Group 订阅 Topic 的分区总数 。如果需要高可用，则 一个分区被两个消费者消费比较合理\n\n  \n\n### 独立消费者组\n\n- Kafka Java Consumer 提供了一个名为 Standalone Consumer 的独立消费者类型。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n- 独立消费者，仍然需要配置 group.id 。且一旦独立消费者 与 其他group.id 重名，当独立消费者提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，这已是一个坑，管理group.id 也是必要的。\n\n\n\n\n\n### 提交\n\n#### 自动提交\n\n- 尽量不要使用，除非数据丢失无所谓，比如坐标点数据。\n\n- enable.auto.commit = true 。 开启自动提交。\n\n- auto.commit.interval.ms=5 。表明 Kafka 每 5 秒会为你自动提交一次位移\n\n  \n\n#### 手动提交范例\n\n- 同步提交带重试功能 ，如果不需要高吞吐量，可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动\n\n- 提交模板\n\n```java\ntry {\n    while (true) {\n        ConsumerRecords<String, String> records = \n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch (Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n\n\n#### 精细管理位移\n\n- Kafka Consumer API 还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。\n\n```java\ncommitSync(Map<TopicPartition, OffsetAndMetadata>) \ncommitAsync(Map<TopicPartition, OffsetAndMetadata>)\n\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\n……  \nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1); \n        if（count % 100 == 0）{\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是 null\n        }\n                    \n        count++;\n    }\n}\n```\n\n\n\n### **防止不必要rebalance**\n\n消费者重平衡，是我们最经常遇到的问题。这里罗列一下常见的原因，尽量避免。\n\n- **心跳超时**会导致 Consumer 被 “踢出” Group \n\n- **消费时间过长** 会导致 Consumer 被 “踢出” Group \n\n- **频繁的 Full GC 导致的长时间停顿**，引发了 Rebalance，这个在高吞吐量的时候，也比较很常见。<br>需要联合gc情况一起排查。\n\n- **总结**：\n\n  - session.timeout.ms = 7s \n\n    heartbeat.interval.ms = 2s。\n\n    解释：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms >= 3 * heartbeat.interval.ms。\n\n  -  设置 max.poll.interval.ms  消费时长，根据业务的消费速度，预留充足的超时时间。\n\n\n\n\n\n## 消费者最佳实践\n\n\n\n### 消费者原则\n\n1. 缩短单条消息处理的时间。\n2. 减少下游系统一次性消费的消息总数。\n3. 消费系统使用多线程来加速消费。（**最好方法**）\n4. KafkaConsumer 类线程不安全，在多个线程中共享时，会抛 ConcurrentModificationException\n5. 消费者启动多线程，n个Consumer对应n个线程，根据业务模式选择同步消费还是异步消费。\n\n**选型**\n\n- 方案一：多consumer + 相同线程消费。\n\n```java\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n \n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n\t\t\tConsumerRecords records = \n\t\t\t\tconsumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n \n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n\n\n- 方案二：单consumer + 多线程消费。\n\n```java\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n \nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n\tworkerNum, workerNum, 0L, TimeUnit.MILLISECONDS,\n\tnew ArrayBlockingQueue<>(1000), \n\tnew ThreadPoolExecutor.CallerRunsPolicy());\n \n \n...\nwhile (true)  {\n\tConsumerRecords<String, String> records = \n\t\tconsumer.poll(Duration.ofSeconds(1));\n\tfor (final ConsumerRecord record : records) {\n\t\texecutors.submit(new Worker(record));\n\t}\n}\n..\n```\n\n\n\n## kafa拦截器\n\nKafka 拦截器最低版本是0.10.0.0 。\n\n\n\n### 生产者拦截器\n\n#### 实现方法\n\n`implement org.apache.kafka.clients.producer.ProducerInterceptor`\n\nhttps://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java\n\n- onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，可以使用此方法\n\n- onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。\n\n  onAcknowledgement 的调用要早于 callback 的调用。\n\n#### **备注**：\n\n- 两个方法不是在同一个线程中被调用的，如果两个方法中调用了某个共享可变对象，要保证线程安全\n- 不能阻塞，别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降\n\n\n\n### 消费者拦截器\n\n#### 实现方法\n\n`implement org.apache.kafka.clients.consumer.ConsumerInterceptor `\n\nhttps://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java\n\n- onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，\n\n  拦截器会先拦一道，搞一些事情，之后再返回给你。\n\n- onCommit：Consumer 在提交位移之后调用该方法。通常在该方法中做一些审计类业务\n\n  比如打日志，统计等。\n","source":"_posts/消息系统/kafka【4】client端最佳实践.md","raw":"---\ntitle: kafka【4】client端最佳实践\ntoc: true\ncategories:\n  - 消息系统\n  - kafka\ntags:\n  - kafka\nhide: false\nsortn: 40\ndate: 2021-08-02 13:19:51\n---\n\n\n<!-- more -->\n\n------\n\n# kafka【4】client端最佳实践\n\n\n\n## 生产者分区策略\n\n### 分区策略的意义\n\n- 分区实际上是调优Kafka并行度的最小单元\n\n- 所谓分区策略是决定生产者将消息发送到哪个分区的算法。\n\n- 如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。\n\n  \n\n### 自带的分区策略\n\n#### 轮询策略\n\n- 能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略\n\n#### 随机策略\n\n- 如果追求数据的均匀分布，还是使用轮询策略比较好，随机策略暂时没想到场景\n\n#### 按照key分区 Key-ordering 策略\n\n- 一旦消息被定义了 Key，则使用 key-ordering 策略，同一个 Key 的所有消息都进入到相同的partition\n- kafka只能保证同partition下的消息处理都是有顺序的，partition间无法做到有序。\n- 如果所有数据都用这一个key，会导致分区数据不平衡，降低吞吐量。所以建议使用区分度较大的值作为key。比如 uid，pid，不要使用 status、if_xxx等\n- 没有找到一个区分度大的key，又要保持顺序，则不要使用kafka，rocketMq不错。\n\n\n\n### 自定义分区策略\n\n- 编写生产者程序时，可以自定义分区策略接口 \n\n```java\n// org.apache.kafka.clients.producer.Partitioner \nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)\n\nList<PartitionInfo> partitions = cluster.partitionsForTopic(topic); \nreturn Math.abs(key.hashCode()) % partitions.size();\n\n```\n\n\n\n\n\n## producer 端配置实践\n\n\n\n### 生产者基本配置\n\n#### 消息版本\n\nProducer 和 Broker 的消息版本要统一（如果不统一，Broker要进行消息解析）\n\n#### 压缩\n\n- 最好开启LZ4压缩。\n- 压缩配置，Producer 端压缩、Broker 端保持、Consumer 端解压缩。\n\n#### 提交策略\n\n- 设置 acks = master。代表master Broker 收到消息，消息就算“已提交”。 \n- 设置 acks = all。 代表所有副本Broker 都接收到消息，该消息才算是“已提交”。\n\n#### 重试次数\n\n设置 retries 为一个较大的值 比如3\n\n#### 提交的方法\n\n使用 producer.send(msg, callback)，必须实现回调函数。\n\n\n\n#### 幂等消息\n\n- 幂等消息是 0.11.0.0 版本以后，引入的 \n- 开启方法：设置enable.idempotence=ture\n- 注意事项：\n  - 只能保证单分区上的幂等性，且当 Producer 进程重启以后之后，这种幂等性保证就丧失了\n  - 需要 **多分区，多会话**上的消息无重复，需要使用事务型Producer\n\n\n\n#### 事务型 Producer\n\n- 保证一批消息原子性地写入到多个分区中，这批消息要么全部写入成功，要么全部失败。\n\n- **开启方法**：\n\n  - 配置 enable.idempotence=ture\n\n  - 使用下面方法生产消息\n\n    ```java\n    //发送代码\n    producer.initTransactions();\n    try {\n                producer.beginTransaction();\n                producer.send(record1);\n                producer.send(record2);\n                producer.commitTransaction();\n    } catch (KafkaException e) {\n                producer.abortTransaction();\n    }\n    ```\n\n  - **需要注意**，事务消息，在consumer端也要进行配置成 read_committed，表明 Consumer 只会消费 事务型 Producer 成功提交事务写入的消息。<br>Consumer 默认 read_uncommitted ， 表示消费者会消费所有消息，如果用了事务型 Producer，对应的 Consumer 就不要使用这个值，这是个坑。\n\n\n\n\n\n## 消费者注意事项\n\n### 基本原则\n\n- 先实际消费，再提交位移。\n\n- 默认先关闭自动提交 enable.auto.commit =  false ， 看场景选择是否打开。\n\n- 必须配置消费者连接超时间， connection.max.idle.ms \n\n- 一个分区，只能被一个消费者消费。Consumer 实例的数量应该等于该 Group 订阅 Topic 的分区总数 。如果需要高可用，则 一个分区被两个消费者消费比较合理\n\n  \n\n### 独立消费者组\n\n- Kafka Java Consumer 提供了一个名为 Standalone Consumer 的独立消费者类型。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。\n\n- 独立消费者，仍然需要配置 group.id 。且一旦独立消费者 与 其他group.id 重名，当独立消费者提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，这已是一个坑，管理group.id 也是必要的。\n\n\n\n\n\n### 提交\n\n#### 自动提交\n\n- 尽量不要使用，除非数据丢失无所谓，比如坐标点数据。\n\n- enable.auto.commit = true 。 开启自动提交。\n\n- auto.commit.interval.ms=5 。表明 Kafka 每 5 秒会为你自动提交一次位移\n\n  \n\n#### 手动提交范例\n\n- 同步提交带重试功能 ，如果不需要高吞吐量，可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动\n\n- 提交模板\n\n```java\ntry {\n    while (true) {\n        ConsumerRecords<String, String> records = \n            consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch (Exception e) {\n    handle(e); // 处理异常\n} finally {\n    try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n    } finally {\n        consumer.close();\n    }\n}\n```\n\n\n\n#### 精细管理位移\n\n- Kafka Consumer API 还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。\n\n```java\ncommitSync(Map<TopicPartition, OffsetAndMetadata>) \ncommitAsync(Map<TopicPartition, OffsetAndMetadata>)\n\nprivate Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\nint count = 0;\n……\n……  \nwhile (true) {\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n    for (ConsumerRecord<String, String> record: records) {\n        process(record);  // 处理消息\n        offsets.put(new TopicPartition(record.topic(), record.partition()),\n                    new OffsetAndMetadata(record.offset() + 1); \n        if（count % 100 == 0）{\n            consumer.commitAsync(offsets, null); // 回调处理逻辑是 null\n        }\n                    \n        count++;\n    }\n}\n```\n\n\n\n### **防止不必要rebalance**\n\n消费者重平衡，是我们最经常遇到的问题。这里罗列一下常见的原因，尽量避免。\n\n- **心跳超时**会导致 Consumer 被 “踢出” Group \n\n- **消费时间过长** 会导致 Consumer 被 “踢出” Group \n\n- **频繁的 Full GC 导致的长时间停顿**，引发了 Rebalance，这个在高吞吐量的时候，也比较很常见。<br>需要联合gc情况一起排查。\n\n- **总结**：\n\n  - session.timeout.ms = 7s \n\n    heartbeat.interval.ms = 2s。\n\n    解释：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms >= 3 * heartbeat.interval.ms。\n\n  -  设置 max.poll.interval.ms  消费时长，根据业务的消费速度，预留充足的超时时间。\n\n\n\n\n\n## 消费者最佳实践\n\n\n\n### 消费者原则\n\n1. 缩短单条消息处理的时间。\n2. 减少下游系统一次性消费的消息总数。\n3. 消费系统使用多线程来加速消费。（**最好方法**）\n4. KafkaConsumer 类线程不安全，在多个线程中共享时，会抛 ConcurrentModificationException\n5. 消费者启动多线程，n个Consumer对应n个线程，根据业务模式选择同步消费还是异步消费。\n\n**选型**\n\n- 方案一：多consumer + 相同线程消费。\n\n```java\npublic class KafkaConsumerRunner implements Runnable {\n     private final AtomicBoolean closed = new AtomicBoolean(false);\n     private final KafkaConsumer consumer;\n \n     public void run() {\n         try {\n             consumer.subscribe(Arrays.asList(\"topic\"));\n             while (!closed.get()) {\n\t\t\tConsumerRecords records = \n\t\t\t\tconsumer.poll(Duration.ofMillis(10000));\n                 //  执行消息处理逻辑\n             }\n         } catch (WakeupException e) {\n             // Ignore exception if closing\n             if (!closed.get()) throw e;\n         } finally {\n             consumer.close();\n         }\n     }\n \n     // Shutdown hook which can be called from a separate thread\n     public void shutdown() {\n         closed.set(true);\n         consumer.wakeup();\n     }\n}\n```\n\n\n\n- 方案二：单consumer + 多线程消费。\n\n```java\nprivate final KafkaConsumer<String, String> consumer;\nprivate ExecutorService executors;\n...\n \nprivate int workerNum = ...;\nexecutors = new ThreadPoolExecutor(\n\tworkerNum, workerNum, 0L, TimeUnit.MILLISECONDS,\n\tnew ArrayBlockingQueue<>(1000), \n\tnew ThreadPoolExecutor.CallerRunsPolicy());\n \n \n...\nwhile (true)  {\n\tConsumerRecords<String, String> records = \n\t\tconsumer.poll(Duration.ofSeconds(1));\n\tfor (final ConsumerRecord record : records) {\n\t\texecutors.submit(new Worker(record));\n\t}\n}\n..\n```\n\n\n\n## kafa拦截器\n\nKafka 拦截器最低版本是0.10.0.0 。\n\n\n\n### 生产者拦截器\n\n#### 实现方法\n\n`implement org.apache.kafka.clients.producer.ProducerInterceptor`\n\nhttps://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java\n\n- onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，可以使用此方法\n\n- onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。\n\n  onAcknowledgement 的调用要早于 callback 的调用。\n\n#### **备注**：\n\n- 两个方法不是在同一个线程中被调用的，如果两个方法中调用了某个共享可变对象，要保证线程安全\n- 不能阻塞，别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降\n\n\n\n### 消费者拦截器\n\n#### 实现方法\n\n`implement org.apache.kafka.clients.consumer.ConsumerInterceptor `\n\nhttps://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java\n\n- onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，\n\n  拦截器会先拦一道，搞一些事情，之后再返回给你。\n\n- onCommit：Consumer 在提交位移之后调用该方法。通常在该方法中做一些审计类业务\n\n  比如打日志，统计等。\n","slug":"消息系统/kafka【4】client端最佳实践","published":1,"updated":"2021-08-02T05:19:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn5001mcpfy3m5cd3eu","content":"<span id=\"more\"></span>\n<hr>\n<h1><span id=\"kafka4client端最佳实践\"> kafka【4】client端最佳实践</span></h1>\n<h2><span id=\"生产者分区策略\"> 生产者分区策略</span></h2>\n<h3><span id=\"分区策略的意义\"> 分区策略的意义</span></h3>\n<ul>\n<li>\n<p>分区实际上是调优Kafka并行度的最小单元</p>\n</li>\n<li>\n<p>所谓分区策略是决定生产者将消息发送到哪个分区的算法。</p>\n</li>\n<li>\n<p>如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。</p>\n</li>\n</ul>\n<h3><span id=\"自带的分区策略\"> 自带的分区策略</span></h3>\n<h4><span id=\"轮询策略\"> 轮询策略</span></h4>\n<ul>\n<li>能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略</li>\n</ul>\n<h4><span id=\"随机策略\"> 随机策略</span></h4>\n<ul>\n<li>如果追求数据的均匀分布，还是使用轮询策略比较好，随机策略暂时没想到场景</li>\n</ul>\n<h4><span id=\"按照key分区-key-ordering-策略\"> 按照key分区 Key-ordering 策略</span></h4>\n<ul>\n<li>一旦消息被定义了 Key，则使用 key-ordering 策略，同一个 Key 的所有消息都进入到相同的partition</li>\n<li>kafka只能保证同partition下的消息处理都是有顺序的，partition间无法做到有序。</li>\n<li>如果所有数据都用这一个key，会导致分区数据不平衡，降低吞吐量。所以建议使用区分度较大的值作为key。比如 uid，pid，不要使用 status、if_xxx等</li>\n<li>没有找到一个区分度大的key，又要保持顺序，则不要使用kafka，rocketMq不错。</li>\n</ul>\n<h3><span id=\"自定义分区策略\"> 自定义分区策略</span></h3>\n<ul>\n<li>编写生产者程序时，可以自定义分区策略接口</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">// org.apache.kafka.clients.producer.Partitioner </span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">partition</span><span class=\"hljs-params\">(String topic, Object key, <span class=\"hljs-keyword\">byte</span>[] keyBytes, Object value, <span class=\"hljs-keyword\">byte</span>[] valueBytes, Cluster cluster)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">List&lt;PartitionInfo&gt; partitions </span>= cluster.partitionsForTopic(topic); <br><span class=\"hljs-keyword\">return</span> Math.abs(key.hashCode()) % partitions.size();<br><br></code></pre></div></td></tr></table></figure>\n<h2><span id=\"producer-端配置实践\"> producer 端配置实践</span></h2>\n<h3><span id=\"生产者基本配置\"> 生产者基本配置</span></h3>\n<h4><span id=\"消息版本\"> 消息版本</span></h4>\n<p>Producer 和 Broker 的消息版本要统一（如果不统一，Broker要进行消息解析）</p>\n<h4><span id=\"压缩\"> 压缩</span></h4>\n<ul>\n<li>最好开启LZ4压缩。</li>\n<li>压缩配置，Producer 端压缩、Broker 端保持、Consumer 端解压缩。</li>\n</ul>\n<h4><span id=\"提交策略\"> 提交策略</span></h4>\n<ul>\n<li>设置 acks = master。代表master Broker 收到消息，消息就算“已提交”。</li>\n<li>设置 acks = all。 代表所有副本Broker 都接收到消息，该消息才算是“已提交”。</li>\n</ul>\n<h4><span id=\"重试次数\"> 重试次数</span></h4>\n<p>设置 retries 为一个较大的值 比如3</p>\n<h4><span id=\"提交的方法\"> 提交的方法</span></h4>\n<p>使用 producer.send(msg, callback)，必须实现回调函数。</p>\n<h4><span id=\"幂等消息\"> 幂等消息</span></h4>\n<ul>\n<li>幂等消息是 0.11.0.0 版本以后，引入的</li>\n<li>开启方法：设置enable.idempotence=ture</li>\n<li>注意事项：\n<ul>\n<li>只能保证单分区上的幂等性，且当 Producer 进程重启以后之后，这种幂等性保证就丧失了</li>\n<li>需要 <strong>多分区，多会话</strong>上的消息无重复，需要使用事务型Producer</li>\n</ul>\n</li>\n</ul>\n<h4><span id=\"事务型-producer\"> 事务型 Producer</span></h4>\n<ul>\n<li>\n<p>保证一批消息原子性地写入到多个分区中，这批消息要么全部写入成功，要么全部失败。</p>\n</li>\n<li>\n<p><strong>开启方法</strong>：</p>\n<ul>\n<li>\n<p>配置 enable.idempotence=ture</p>\n</li>\n<li>\n<p>使用下面方法生产消息</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//发送代码</span><br>producer.initTransactions();<br><span class=\"hljs-keyword\">try</span> &#123;<br>            producer.beginTransaction();<br>            producer.send(record1);<br>            producer.send(record2);<br>            producer.commitTransaction();<br>&#125; <span class=\"hljs-keyword\">catch</span> (KafkaException e) &#123;<br>            producer.abortTransaction();<br>&#125;<br></code></pre></div></td></tr></table></figure>\n</li>\n<li>\n<p><strong>需要注意</strong>，事务消息，在consumer端也要进行配置成 read_committed，表明 Consumer 只会消费 事务型 Producer 成功提交事务写入的消息。<br>Consumer 默认 read_uncommitted ， 表示消费者会消费所有消息，如果用了事务型 Producer，对应的 Consumer 就不要使用这个值，这是个坑。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"消费者注意事项\"> 消费者注意事项</span></h2>\n<h3><span id=\"基本原则\"> 基本原则</span></h3>\n<ul>\n<li>\n<p>先实际消费，再提交位移。</p>\n</li>\n<li>\n<p>默认先关闭自动提交 enable.auto.commit =  false ， 看场景选择是否打开。</p>\n</li>\n<li>\n<p>必须配置消费者连接超时间， <a href=\"http://connection.max.idle.ms\">connection.max.idle.ms</a></p>\n</li>\n<li>\n<p>一个分区，只能被一个消费者消费。Consumer 实例的数量应该等于该 Group 订阅 Topic 的分区总数 。如果需要高可用，则 一个分区被两个消费者消费比较合理</p>\n</li>\n</ul>\n<h3><span id=\"独立消费者组\"> 独立消费者组</span></h3>\n<ul>\n<li>\n<p>Kafka Java Consumer 提供了一个名为 Standalone Consumer 的独立消费者类型。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n</li>\n<li>\n<p>独立消费者，仍然需要配置 <a href=\"http://group.id\">group.id</a> 。且一旦独立消费者 与 <a href=\"http://xn--group-3h2hx0n.id\">其他group.id</a> 重名，当独立消费者提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，这已是一个坑，<a href=\"http://xn--group-338lt35b.id\">管理group.id</a> 也是必要的。</p>\n</li>\n</ul>\n<h3><span id=\"提交\"> 提交</span></h3>\n<h4><span id=\"自动提交\"> 自动提交</span></h4>\n<ul>\n<li>\n<p>尽量不要使用，除非数据丢失无所谓，比如坐标点数据。</p>\n</li>\n<li>\n<p>enable.auto.commit = true 。 开启自动提交。</p>\n</li>\n<li>\n<p>auto.commit.interval.ms=5 。表明 Kafka 每 5 秒会为你自动提交一次位移</p>\n</li>\n</ul>\n<h4><span id=\"手动提交范例\"> 手动提交范例</span></h4>\n<ul>\n<li>\n<p>同步提交带重试功能 ，如果不需要高吞吐量，可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动</p>\n</li>\n<li>\n<p>提交模板</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">try</span> &#123;<br>    <span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>) &#123;<br>        ConsumerRecords&lt;String, String&gt; records = <br>            consumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>        process(records); <span class=\"hljs-comment\">// 处理消息</span><br>        commitAysnc(); <span class=\"hljs-comment\">// 使用异步提交规避阻塞</span><br>    &#125;<br>&#125; <span class=\"hljs-keyword\">catch</span> (Exception e) &#123;<br>    handle(e); <span class=\"hljs-comment\">// 处理异常</span><br>&#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>    <span class=\"hljs-keyword\">try</span> &#123;<br>        consumer.commitSync(); <span class=\"hljs-comment\">// 最后一次提交使用同步阻塞式提交</span><br>    &#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>        consumer.close();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n<h4><span id=\"精细管理位移\"> 精细管理位移</span></h4>\n<ul>\n<li>Kafka Consumer API 还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\">commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;) <br>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)<br><br><span class=\"hljs-keyword\">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();<br><span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">0</span>;<br>……<br>……  <br><span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>) &#123;<br>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>    <span class=\"hljs-keyword\">for</span> (ConsumerRecord&lt;String, String&gt; record: records) &#123;<br>        process(record);  <span class=\"hljs-comment\">// 处理消息</span><br>        offsets.put(<span class=\"hljs-keyword\">new</span> TopicPartition(record.topic(), record.partition()),<br>                    <span class=\"hljs-keyword\">new</span> OffsetAndMetadata(record.offset() + <span class=\"hljs-number\">1</span>); <br>        <span class=\"hljs-keyword\">if</span>（count % <span class=\"hljs-number\">100</span> == <span class=\"hljs-number\">0</span>）&#123;<br>            consumer.commitAsync(offsets, <span class=\"hljs-keyword\">null</span>); <span class=\"hljs-comment\">// 回调处理逻辑是 null</span><br>        &#125;<br>                    <br>        count++;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n<h3><span id=\"防止不必要rebalance\"> <strong>防止不必要rebalance</strong></span></h3>\n<p>消费者重平衡，是我们最经常遇到的问题。这里罗列一下常见的原因，尽量避免。</p>\n<ul>\n<li>\n<p><strong>心跳超时</strong>会导致 Consumer 被 “踢出” Group</p>\n</li>\n<li>\n<p><strong>消费时间过长</strong> 会导致 Consumer 被 “踢出” Group</p>\n</li>\n<li>\n<p><strong>频繁的 Full GC 导致的长时间停顿</strong>，引发了 Rebalance，这个在高吞吐量的时候，也比较很常见。<br>需要联合gc情况一起排查。</p>\n</li>\n<li>\n<p><strong>总结</strong>：</p>\n<ul>\n<li>\n<p><a href=\"http://session.timeout.ms\">session.timeout.ms</a> = 7s</p>\n<p><a href=\"http://heartbeat.interval.ms\">heartbeat.interval.ms</a> = 2s。</p>\n<p>解释：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 <a href=\"http://session.timeout.ms\">session.timeout.ms</a> &gt;= 3 * <a href=\"http://heartbeat.interval.ms\">heartbeat.interval.ms</a>。</p>\n</li>\n<li>\n<p>设置 <a href=\"http://max.poll.interval.ms\">max.poll.interval.ms</a>  消费时长，根据业务的消费速度，预留充足的超时时间。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"消费者最佳实践\"> 消费者最佳实践</span></h2>\n<h3><span id=\"消费者原则\"> 消费者原则</span></h3>\n<ol>\n<li>缩短单条消息处理的时间。</li>\n<li>减少下游系统一次性消费的消息总数。</li>\n<li>消费系统使用多线程来加速消费。（<strong>最好方法</strong>）</li>\n<li>KafkaConsumer 类线程不安全，在多个线程中共享时，会抛 ConcurrentModificationException</li>\n<li>消费者启动多线程，n个Consumer对应n个线程，根据业务模式选择同步消费还是异步消费。</li>\n</ol>\n<p><strong>选型</strong></p>\n<ul>\n<li>方案一：多consumer + 相同线程消费。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">KafkaConsumerRunner</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Runnable</span> </span>&#123;<br>     <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> AtomicBoolean closed = <span class=\"hljs-keyword\">new</span> AtomicBoolean(<span class=\"hljs-keyword\">false</span>);<br>     <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> KafkaConsumer consumer;<br> <br>     <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">run</span><span class=\"hljs-params\">()</span> </span>&#123;<br>         <span class=\"hljs-keyword\">try</span> &#123;<br>             consumer.subscribe(Arrays.asList(<span class=\"hljs-string\">&quot;topic&quot;</span>));<br>             <span class=\"hljs-keyword\">while</span> (!closed.get()) &#123;<br>\t\t\tConsumerRecords records = <br>\t\t\t\tconsumer.poll(Duration.ofMillis(<span class=\"hljs-number\">10000</span>));<br>                 <span class=\"hljs-comment\">//  执行消息处理逻辑</span><br>             &#125;<br>         &#125; <span class=\"hljs-keyword\">catch</span> (WakeupException e) &#123;<br>             <span class=\"hljs-comment\">// Ignore exception if closing</span><br>             <span class=\"hljs-keyword\">if</span> (!closed.get()) <span class=\"hljs-keyword\">throw</span> e;<br>         &#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>             consumer.close();<br>         &#125;<br>     &#125;<br> <br>     <span class=\"hljs-comment\">// Shutdown hook which can be called from a separate thread</span><br>     <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">shutdown</span><span class=\"hljs-params\">()</span> </span>&#123;<br>         closed.set(<span class=\"hljs-keyword\">true</span>);<br>         consumer.wakeup();<br>     &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>方案二：单consumer + 多线程消费。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> KafkaConsumer&lt;String, String&gt; consumer;<br><span class=\"hljs-keyword\">private</span> ExecutorService executors;<br>...<br> <br><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> workerNum = ...;<br>executors = <span class=\"hljs-keyword\">new</span> ThreadPoolExecutor(<br>\tworkerNum, workerNum, <span class=\"hljs-number\">0L</span>, TimeUnit.MILLISECONDS,<br>\t<span class=\"hljs-keyword\">new</span> ArrayBlockingQueue&lt;&gt;(<span class=\"hljs-number\">1000</span>), <br>\t<span class=\"hljs-keyword\">new</span> ThreadPoolExecutor.CallerRunsPolicy());<br> <br> <br>...<br><span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>)  &#123;<br>\tConsumerRecords&lt;String, String&gt; records = <br>\t\tconsumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">final</span> ConsumerRecord record : records) &#123;<br>\t\texecutors.submit(<span class=\"hljs-keyword\">new</span> Worker(record));<br>\t&#125;<br>&#125;<br>..<br></code></pre></div></td></tr></table></figure>\n<h2><span id=\"kafa拦截器\"> kafa拦截器</span></h2>\n<p>Kafka 拦截器最低版本是0.10.0.0 。</p>\n<h3><span id=\"生产者拦截器\"> 生产者拦截器</span></h3>\n<h4><span id=\"实现方法\"> 实现方法</span></h4>\n<p><code>implement org.apache.kafka.clients.producer.ProducerInterceptor</code></p>\n<p><a href=\"https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java\">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java</a></p>\n<ul>\n<li>\n<p>onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，可以使用此方法</p>\n</li>\n<li>\n<p>onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。</p>\n<p>onAcknowledgement 的调用要早于 callback 的调用。</p>\n</li>\n</ul>\n<h4><span id=\"备注\"> <strong>备注</strong>：</span></h4>\n<ul>\n<li>两个方法不是在同一个线程中被调用的，如果两个方法中调用了某个共享可变对象，要保证线程安全</li>\n<li>不能阻塞，别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降</li>\n</ul>\n<h3><span id=\"消费者拦截器\"> 消费者拦截器</span></h3>\n<h4><span id=\"实现方法\"> 实现方法</span></h4>\n<p><code>implement org.apache.kafka.clients.consumer.ConsumerInterceptor</code></p>\n<p><a href=\"https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java\">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java</a></p>\n<ul>\n<li>\n<p>onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，</p>\n<p>拦截器会先拦一道，搞一些事情，之后再返回给你。</p>\n</li>\n<li>\n<p>onCommit：Consumer 在提交位移之后调用该方法。通常在该方法中做一些审计类业务</p>\n<p>比如打日志，统计等。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<hr />\n<h1 id=\"kafka4client端最佳实践\"><a class=\"markdownIt-Anchor\" href=\"#kafka4client端最佳实践\"></a> kafka【4】client端最佳实践</h1>\n<h2 id=\"生产者分区策略\"><a class=\"markdownIt-Anchor\" href=\"#生产者分区策略\"></a> 生产者分区策略</h2>\n<h3 id=\"分区策略的意义\"><a class=\"markdownIt-Anchor\" href=\"#分区策略的意义\"></a> 分区策略的意义</h3>\n<ul>\n<li>\n<p>分区实际上是调优Kafka并行度的最小单元</p>\n</li>\n<li>\n<p>所谓分区策略是决定生产者将消息发送到哪个分区的算法。</p>\n</li>\n<li>\n<p>如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。</p>\n</li>\n</ul>\n<h3 id=\"自带的分区策略\"><a class=\"markdownIt-Anchor\" href=\"#自带的分区策略\"></a> 自带的分区策略</h3>\n<h4 id=\"轮询策略\"><a class=\"markdownIt-Anchor\" href=\"#轮询策略\"></a> 轮询策略</h4>\n<ul>\n<li>能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略</li>\n</ul>\n<h4 id=\"随机策略\"><a class=\"markdownIt-Anchor\" href=\"#随机策略\"></a> 随机策略</h4>\n<ul>\n<li>如果追求数据的均匀分布，还是使用轮询策略比较好，随机策略暂时没想到场景</li>\n</ul>\n<h4 id=\"按照key分区-key-ordering-策略\"><a class=\"markdownIt-Anchor\" href=\"#按照key分区-key-ordering-策略\"></a> 按照key分区 Key-ordering 策略</h4>\n<ul>\n<li>一旦消息被定义了 Key，则使用 key-ordering 策略，同一个 Key 的所有消息都进入到相同的partition</li>\n<li>kafka只能保证同partition下的消息处理都是有顺序的，partition间无法做到有序。</li>\n<li>如果所有数据都用这一个key，会导致分区数据不平衡，降低吞吐量。所以建议使用区分度较大的值作为key。比如 uid，pid，不要使用 status、if_xxx等</li>\n<li>没有找到一个区分度大的key，又要保持顺序，则不要使用kafka，rocketMq不错。</li>\n</ul>\n<h3 id=\"自定义分区策略\"><a class=\"markdownIt-Anchor\" href=\"#自定义分区策略\"></a> 自定义分区策略</h3>\n<ul>\n<li>编写生产者程序时，可以自定义分区策略接口</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">// org.apache.kafka.clients.producer.Partitioner </span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">partition</span><span class=\"hljs-params\">(String topic, Object key, <span class=\"hljs-keyword\">byte</span>[] keyBytes, Object value, <span class=\"hljs-keyword\">byte</span>[] valueBytes, Cluster cluster)</span></span><br><span class=\"hljs-function\"></span><br><span class=\"hljs-function\">List&lt;PartitionInfo&gt; partitions </span>= cluster.partitionsForTopic(topic); <br><span class=\"hljs-keyword\">return</span> Math.abs(key.hashCode()) % partitions.size();<br><br></code></pre></td></tr></table></figure>\n<h2 id=\"producer-端配置实践\"><a class=\"markdownIt-Anchor\" href=\"#producer-端配置实践\"></a> producer 端配置实践</h2>\n<h3 id=\"生产者基本配置\"><a class=\"markdownIt-Anchor\" href=\"#生产者基本配置\"></a> 生产者基本配置</h3>\n<h4 id=\"消息版本\"><a class=\"markdownIt-Anchor\" href=\"#消息版本\"></a> 消息版本</h4>\n<p>Producer 和 Broker 的消息版本要统一（如果不统一，Broker要进行消息解析）</p>\n<h4 id=\"压缩\"><a class=\"markdownIt-Anchor\" href=\"#压缩\"></a> 压缩</h4>\n<ul>\n<li>最好开启LZ4压缩。</li>\n<li>压缩配置，Producer 端压缩、Broker 端保持、Consumer 端解压缩。</li>\n</ul>\n<h4 id=\"提交策略\"><a class=\"markdownIt-Anchor\" href=\"#提交策略\"></a> 提交策略</h4>\n<ul>\n<li>设置 acks = master。代表master Broker 收到消息，消息就算“已提交”。</li>\n<li>设置 acks = all。 代表所有副本Broker 都接收到消息，该消息才算是“已提交”。</li>\n</ul>\n<h4 id=\"重试次数\"><a class=\"markdownIt-Anchor\" href=\"#重试次数\"></a> 重试次数</h4>\n<p>设置 retries 为一个较大的值 比如3</p>\n<h4 id=\"提交的方法\"><a class=\"markdownIt-Anchor\" href=\"#提交的方法\"></a> 提交的方法</h4>\n<p>使用 producer.send(msg, callback)，必须实现回调函数。</p>\n<h4 id=\"幂等消息\"><a class=\"markdownIt-Anchor\" href=\"#幂等消息\"></a> 幂等消息</h4>\n<ul>\n<li>幂等消息是 0.11.0.0 版本以后，引入的</li>\n<li>开启方法：设置enable.idempotence=ture</li>\n<li>注意事项：\n<ul>\n<li>只能保证单分区上的幂等性，且当 Producer 进程重启以后之后，这种幂等性保证就丧失了</li>\n<li>需要 <strong>多分区，多会话</strong>上的消息无重复，需要使用事务型Producer</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"事务型-producer\"><a class=\"markdownIt-Anchor\" href=\"#事务型-producer\"></a> 事务型 Producer</h4>\n<ul>\n<li>\n<p>保证一批消息原子性地写入到多个分区中，这批消息要么全部写入成功，要么全部失败。</p>\n</li>\n<li>\n<p><strong>开启方法</strong>：</p>\n<ul>\n<li>\n<p>配置 enable.idempotence=ture</p>\n</li>\n<li>\n<p>使用下面方法生产消息</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-comment\">//发送代码</span><br>producer.initTransactions();<br><span class=\"hljs-keyword\">try</span> &#123;<br>            producer.beginTransaction();<br>            producer.send(record1);<br>            producer.send(record2);<br>            producer.commitTransaction();<br>&#125; <span class=\"hljs-keyword\">catch</span> (KafkaException e) &#123;<br>            producer.abortTransaction();<br>&#125;<br></code></pre></td></tr></table></figure>\n</li>\n<li>\n<p><strong>需要注意</strong>，事务消息，在consumer端也要进行配置成 read_committed，表明 Consumer 只会消费 事务型 Producer 成功提交事务写入的消息。<br>Consumer 默认 read_uncommitted ， 表示消费者会消费所有消息，如果用了事务型 Producer，对应的 Consumer 就不要使用这个值，这是个坑。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者注意事项\"><a class=\"markdownIt-Anchor\" href=\"#消费者注意事项\"></a> 消费者注意事项</h2>\n<h3 id=\"基本原则\"><a class=\"markdownIt-Anchor\" href=\"#基本原则\"></a> 基本原则</h3>\n<ul>\n<li>\n<p>先实际消费，再提交位移。</p>\n</li>\n<li>\n<p>默认先关闭自动提交 enable.auto.commit =  false ， 看场景选择是否打开。</p>\n</li>\n<li>\n<p>必须配置消费者连接超时间， <a href=\"http://connection.max.idle.ms\">connection.max.idle.ms</a></p>\n</li>\n<li>\n<p>一个分区，只能被一个消费者消费。Consumer 实例的数量应该等于该 Group 订阅 Topic 的分区总数 。如果需要高可用，则 一个分区被两个消费者消费比较合理</p>\n</li>\n</ul>\n<h3 id=\"独立消费者组\"><a class=\"markdownIt-Anchor\" href=\"#独立消费者组\"></a> 独立消费者组</h3>\n<ul>\n<li>\n<p>Kafka Java Consumer 提供了一个名为 Standalone Consumer 的独立消费者类型。它没有消费者组的概念，每个消费者实例都是独立工作的，彼此之间毫无联系。</p>\n</li>\n<li>\n<p>独立消费者，仍然需要配置 <a href=\"http://group.id\">group.id</a> 。且一旦独立消费者 与 <a href=\"http://xn--group-3h2hx0n.id\">其他group.id</a> 重名，当独立消费者提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，这已是一个坑，<a href=\"http://xn--group-338lt35b.id\">管理group.id</a> 也是必要的。</p>\n</li>\n</ul>\n<h3 id=\"提交\"><a class=\"markdownIt-Anchor\" href=\"#提交\"></a> 提交</h3>\n<h4 id=\"自动提交\"><a class=\"markdownIt-Anchor\" href=\"#自动提交\"></a> 自动提交</h4>\n<ul>\n<li>\n<p>尽量不要使用，除非数据丢失无所谓，比如坐标点数据。</p>\n</li>\n<li>\n<p>enable.auto.commit = true 。 开启自动提交。</p>\n</li>\n<li>\n<p>auto.commit.interval.ms=5 。表明 Kafka 每 5 秒会为你自动提交一次位移</p>\n</li>\n</ul>\n<h4 id=\"手动提交范例\"><a class=\"markdownIt-Anchor\" href=\"#手动提交范例\"></a> 手动提交范例</h4>\n<ul>\n<li>\n<p>同步提交带重试功能 ，如果不需要高吞吐量，可以利用 commitSync 的自动重试来规避那些瞬时错误，比如网络的瞬时抖动</p>\n</li>\n<li>\n<p>提交模板</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">try</span> &#123;<br>    <span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>) &#123;<br>        ConsumerRecords&lt;String, String&gt; records = <br>            consumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>        process(records); <span class=\"hljs-comment\">// 处理消息</span><br>        commitAysnc(); <span class=\"hljs-comment\">// 使用异步提交规避阻塞</span><br>    &#125;<br>&#125; <span class=\"hljs-keyword\">catch</span> (Exception e) &#123;<br>    handle(e); <span class=\"hljs-comment\">// 处理异常</span><br>&#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>    <span class=\"hljs-keyword\">try</span> &#123;<br>        consumer.commitSync(); <span class=\"hljs-comment\">// 最后一次提交使用同步阻塞式提交</span><br>    &#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>        consumer.close();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h4 id=\"精细管理位移\"><a class=\"markdownIt-Anchor\" href=\"#精细管理位移\"></a> 精细管理位移</h4>\n<ul>\n<li>Kafka Consumer API 还提供了一组更为方便的方法，可以帮助你实现更精细化的位移管理功能。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\">commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt;) <br>commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt;)<br><br><span class=\"hljs-keyword\">private</span> Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = <span class=\"hljs-keyword\">new</span> HashMap&lt;&gt;();<br><span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">0</span>;<br>……<br>……  <br><span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>) &#123;<br>    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>    <span class=\"hljs-keyword\">for</span> (ConsumerRecord&lt;String, String&gt; record: records) &#123;<br>        process(record);  <span class=\"hljs-comment\">// 处理消息</span><br>        offsets.put(<span class=\"hljs-keyword\">new</span> TopicPartition(record.topic(), record.partition()),<br>                    <span class=\"hljs-keyword\">new</span> OffsetAndMetadata(record.offset() + <span class=\"hljs-number\">1</span>); <br>        <span class=\"hljs-keyword\">if</span>（count % <span class=\"hljs-number\">100</span> == <span class=\"hljs-number\">0</span>）&#123;<br>            consumer.commitAsync(offsets, <span class=\"hljs-keyword\">null</span>); <span class=\"hljs-comment\">// 回调处理逻辑是 null</span><br>        &#125;<br>                    <br>        count++;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<h3 id=\"防止不必要rebalance\"><a class=\"markdownIt-Anchor\" href=\"#防止不必要rebalance\"></a> <strong>防止不必要rebalance</strong></h3>\n<p>消费者重平衡，是我们最经常遇到的问题。这里罗列一下常见的原因，尽量避免。</p>\n<ul>\n<li>\n<p><strong>心跳超时</strong>会导致 Consumer 被 “踢出” Group</p>\n</li>\n<li>\n<p><strong>消费时间过长</strong> 会导致 Consumer 被 “踢出” Group</p>\n</li>\n<li>\n<p><strong>频繁的 Full GC 导致的长时间停顿</strong>，引发了 Rebalance，这个在高吞吐量的时候，也比较很常见。<br>需要联合gc情况一起排查。</p>\n</li>\n<li>\n<p><strong>总结</strong>：</p>\n<ul>\n<li>\n<p><a href=\"http://session.timeout.ms\">session.timeout.ms</a> = 7s</p>\n<p><a href=\"http://heartbeat.interval.ms\">heartbeat.interval.ms</a> = 2s。</p>\n<p>解释：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 <a href=\"http://session.timeout.ms\">session.timeout.ms</a> &gt;= 3 * <a href=\"http://heartbeat.interval.ms\">heartbeat.interval.ms</a>。</p>\n</li>\n<li>\n<p>设置 <a href=\"http://max.poll.interval.ms\">max.poll.interval.ms</a>  消费时长，根据业务的消费速度，预留充足的超时时间。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"消费者最佳实践\"><a class=\"markdownIt-Anchor\" href=\"#消费者最佳实践\"></a> 消费者最佳实践</h2>\n<h3 id=\"消费者原则\"><a class=\"markdownIt-Anchor\" href=\"#消费者原则\"></a> 消费者原则</h3>\n<ol>\n<li>缩短单条消息处理的时间。</li>\n<li>减少下游系统一次性消费的消息总数。</li>\n<li>消费系统使用多线程来加速消费。（<strong>最好方法</strong>）</li>\n<li>KafkaConsumer 类线程不安全，在多个线程中共享时，会抛 ConcurrentModificationException</li>\n<li>消费者启动多线程，n个Consumer对应n个线程，根据业务模式选择同步消费还是异步消费。</li>\n</ol>\n<p><strong>选型</strong></p>\n<ul>\n<li>方案一：多consumer + 相同线程消费。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">KafkaConsumerRunner</span> <span class=\"hljs-keyword\">implements</span> <span class=\"hljs-title\">Runnable</span> </span>&#123;<br>     <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> AtomicBoolean closed = <span class=\"hljs-keyword\">new</span> AtomicBoolean(<span class=\"hljs-keyword\">false</span>);<br>     <span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> KafkaConsumer consumer;<br> <br>     <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">run</span><span class=\"hljs-params\">()</span> </span>&#123;<br>         <span class=\"hljs-keyword\">try</span> &#123;<br>             consumer.subscribe(Arrays.asList(<span class=\"hljs-string\">&quot;topic&quot;</span>));<br>             <span class=\"hljs-keyword\">while</span> (!closed.get()) &#123;<br>\t\t\tConsumerRecords records = <br>\t\t\t\tconsumer.poll(Duration.ofMillis(<span class=\"hljs-number\">10000</span>));<br>                 <span class=\"hljs-comment\">//  执行消息处理逻辑</span><br>             &#125;<br>         &#125; <span class=\"hljs-keyword\">catch</span> (WakeupException e) &#123;<br>             <span class=\"hljs-comment\">// Ignore exception if closing</span><br>             <span class=\"hljs-keyword\">if</span> (!closed.get()) <span class=\"hljs-keyword\">throw</span> e;<br>         &#125; <span class=\"hljs-keyword\">finally</span> &#123;<br>             consumer.close();<br>         &#125;<br>     &#125;<br> <br>     <span class=\"hljs-comment\">// Shutdown hook which can be called from a separate thread</span><br>     <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">shutdown</span><span class=\"hljs-params\">()</span> </span>&#123;<br>         closed.set(<span class=\"hljs-keyword\">true</span>);<br>         consumer.wakeup();<br>     &#125;<br>&#125;<br></code></pre></td></tr></table></figure>\n<ul>\n<li>方案二：单consumer + 多线程消费。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">final</span> KafkaConsumer&lt;String, String&gt; consumer;<br><span class=\"hljs-keyword\">private</span> ExecutorService executors;<br>...<br> <br><span class=\"hljs-keyword\">private</span> <span class=\"hljs-keyword\">int</span> workerNum = ...;<br>executors = <span class=\"hljs-keyword\">new</span> ThreadPoolExecutor(<br>\tworkerNum, workerNum, <span class=\"hljs-number\">0L</span>, TimeUnit.MILLISECONDS,<br>\t<span class=\"hljs-keyword\">new</span> ArrayBlockingQueue&lt;&gt;(<span class=\"hljs-number\">1000</span>), <br>\t<span class=\"hljs-keyword\">new</span> ThreadPoolExecutor.CallerRunsPolicy());<br> <br> <br>...<br><span class=\"hljs-keyword\">while</span> (<span class=\"hljs-keyword\">true</span>)  &#123;<br>\tConsumerRecords&lt;String, String&gt; records = <br>\t\tconsumer.poll(Duration.ofSeconds(<span class=\"hljs-number\">1</span>));<br>\t<span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">final</span> ConsumerRecord record : records) &#123;<br>\t\texecutors.submit(<span class=\"hljs-keyword\">new</span> Worker(record));<br>\t&#125;<br>&#125;<br>..<br></code></pre></td></tr></table></figure>\n<h2 id=\"kafa拦截器\"><a class=\"markdownIt-Anchor\" href=\"#kafa拦截器\"></a> kafa拦截器</h2>\n<p>Kafka 拦截器最低版本是0.10.0.0 。</p>\n<h3 id=\"生产者拦截器\"><a class=\"markdownIt-Anchor\" href=\"#生产者拦截器\"></a> 生产者拦截器</h3>\n<h4 id=\"实现方法\"><a class=\"markdownIt-Anchor\" href=\"#实现方法\"></a> 实现方法</h4>\n<p><code>implement org.apache.kafka.clients.producer.ProducerInterceptor</code></p>\n<p><a href=\"https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java\">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/producer/ProducerInterceptor.java</a></p>\n<ul>\n<li>\n<p>onSend：该方法会在消息发送之前被调用。如果想在发送之前对消息“美美容”，可以使用此方法</p>\n</li>\n<li>\n<p>onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。</p>\n<p>onAcknowledgement 的调用要早于 callback 的调用。</p>\n</li>\n</ul>\n<h4 id=\"备注\"><a class=\"markdownIt-Anchor\" href=\"#备注\"></a> <strong>备注</strong>：</h4>\n<ul>\n<li>两个方法不是在同一个线程中被调用的，如果两个方法中调用了某个共享可变对象，要保证线程安全</li>\n<li>不能阻塞，别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降</li>\n</ul>\n<h3 id=\"消费者拦截器\"><a class=\"markdownIt-Anchor\" href=\"#消费者拦截器\"></a> 消费者拦截器</h3>\n<h4 id=\"实现方法-2\"><a class=\"markdownIt-Anchor\" href=\"#实现方法-2\"></a> 实现方法</h4>\n<p><code>implement org.apache.kafka.clients.consumer.ConsumerInterceptor</code></p>\n<p><a href=\"https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java\">https://github.com/apache/kafka/blob/1a7ad70f24a1fa6b1640c2f768457324bbcda0df/clients/src/main/java/org/apache/kafka/clients/consumer/ConsumerInterceptor.java</a></p>\n<ul>\n<li>\n<p>onConsume：该方法在消息返回给 Consumer 程序之前调用。在开始正式处理消息之前，</p>\n<p>拦截器会先拦一道，搞一些事情，之后再返回给你。</p>\n</li>\n<li>\n<p>onCommit：Consumer 在提交位移之后调用该方法。通常在该方法中做一些审计类业务</p>\n<p>比如打日志，统计等。</p>\n</li>\n</ul>"},{"title":"kafka【5】命令行工具","toc":true,"hide":false,"sortn":50,"date":"2021-08-02T08:24:12.000Z","_content":"\n\n<!-- more -->\n\n------\n\n\n\n## 命令行工具\n\n### 生产消息\n\n生产消息使用 kafka-console-producer 脚本：\n\n\n```shell\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n```\n\n\n\n### 消费消息\n\n```shell\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n\n\n### 测试生产者性能\n\n```shell\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 \n\n#返回值\nlinger.ms=2000 compression.type=lz4 2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency. 4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency. 10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n- 上述命令， 向指定主题发送了 1 千万条消息，每条消息大小是 1KB，\n\n- 上述输出，表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。\n\n  你完全可以把这个数据当作这个生产者对外承诺的 SLA。\n\n\n\n### 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic \n#返回值\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n\n\n### 查看topic消息总数\n\n```shell\n#最早位移\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n \ntest-topic:0:0\ntest-topic:1:0\n\n#最新位移\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n \ntest-topic:0:5500000\ntest-topic:1:5500000\n\n```\n\n- 消息总数 =  最早位移 + 最新位移\n\n- 对于本例，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。\n\n  \n\n### 查询消费者组位移\n\n```shell\n$ bin/kafka-console-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group\n```\n\n- CURRENT-OFFSET 表示该消费者当前消费的最新位移，\n- LOG-END-OFFSET 表示对应分区最新生产消息的位移，\n- LAG 列是两者的差值。\n","source":"_posts/消息系统/kafka【5】命令行工具.md","raw":"---\ntitle: kafka【5】命令行工具\ntoc: true\ncategories:\n  - 消息系统\n  - kafka\ntags:\n  - kafka\nhide: false\nsortn: 50\ndate: 2021-08-02 16:24:12\n---\n\n\n<!-- more -->\n\n------\n\n\n\n## 命令行工具\n\n### 生产消息\n\n生产消息使用 kafka-console-producer 脚本：\n\n\n```shell\n$ bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4\n```\n\n\n\n### 消费消息\n\n```shell\n$ bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=false \n```\n\n\n\n### 测试生产者性能\n\n```shell\n$ bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1 \n\n#返回值\nlinger.ms=2000 compression.type=lz4 2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency. 4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency. 10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.\n```\n\n- 上述命令， 向指定主题发送了 1 千万条消息，每条消息大小是 1KB，\n\n- 上述输出，表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。\n\n  你完全可以把这个数据当作这个生产者对外承诺的 SLA。\n\n\n\n### 测试消费者性能\n\n```shell\n$ bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic \n#返回值\nstart.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012\n```\n\n\n\n### 查看topic消息总数\n\n```shell\n#最早位移\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic\n \ntest-topic:0:0\ntest-topic:1:0\n\n#最新位移\n$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic\n \ntest-topic:0:5500000\ntest-topic:1:5500000\n\n```\n\n- 消息总数 =  最早位移 + 最新位移\n\n- 对于本例，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。\n\n  \n\n### 查询消费者组位移\n\n```shell\n$ bin/kafka-console-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group\n```\n\n- CURRENT-OFFSET 表示该消费者当前消费的最新位移，\n- LOG-END-OFFSET 表示对应分区最新生产消息的位移，\n- LAG 列是两者的差值。\n","slug":"消息系统/kafka【5】命令行工具","published":1,"updated":"2021-08-02T08:24:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckrw7oxn6001pcpfyfm990z67","content":"<span id=\"more\"></span>\n<hr>\n<h2><span id=\"命令行工具\"> 命令行工具</span></h2>\n<h3><span id=\"生产消息\"> 生产消息</span></h3>\n<p>生产消息使用 kafka-console-producer 脚本：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4</span><br></code></pre></div></td></tr></table></figure>\n<h3><span id=\"消费消息\"> 消费消息</span></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=<span class=\"hljs-literal\">false</span></span> <br></code></pre></div></td></tr></table></figure>\n<h3><span id=\"测试生产者性能\"> 测试生产者性能</span></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1</span> <br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">返回值</span><br>linger.ms=2000 compression.type=lz4 2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency. 4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency. 10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>\n<p>上述命令， 向指定主题发送了 1 千万条消息，每条消息大小是 1KB，</p>\n</li>\n<li>\n<p>上述输出，表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。</p>\n<p>你完全可以把这个数据当作这个生产者对外承诺的 SLA。</p>\n</li>\n</ul>\n<h3><span id=\"测试消费者性能\"> 测试消费者性能</span></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</span> <br><span class=\"hljs-meta\">#</span><span class=\"bash\">返回值</span><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<br></code></pre></div></td></tr></table></figure>\n<h3><span id=\"查看topic消息总数\"> 查看topic消息总数</span></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">最早位移</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic</span><br> <br>test-topic:0:0<br>test-topic:1:0<br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">最新位移</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic</span><br> <br>test-topic:0:5500000<br>test-topic:1:5500000<br><br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>\n<p>消息总数 =  最早位移 + 最新位移</p>\n</li>\n<li>\n<p>对于本例，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。</p>\n</li>\n</ul>\n<h3><span id=\"查询消费者组位移\"> 查询消费者组位移</span></h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter hljs\"><div class=\"hljs code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><div class=\"hljs code-wrapper\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group</span><br></code></pre></div></td></tr></table></figure>\n<ul>\n<li>CURRENT-OFFSET 表示该消费者当前消费的最新位移，</li>\n<li>LOG-END-OFFSET 表示对应分区最新生产消息的位移，</li>\n<li>LAG 列是两者的差值。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<hr />\n<h2 id=\"命令行工具\"><a class=\"markdownIt-Anchor\" href=\"#命令行工具\"></a> 命令行工具</h2>\n<h3 id=\"生产消息\"><a class=\"markdownIt-Anchor\" href=\"#生产消息\"></a> 生产消息</h3>\n<p>生产消息使用 kafka-console-producer 脚本：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-producer.sh --broker-list kafka-host:port --topic test-topic --request-required-acks -1 --producer-property compression.type=lz4</span><br></code></pre></td></tr></table></figure>\n<h3 id=\"消费消息\"><a class=\"markdownIt-Anchor\" href=\"#消费消息\"></a> 消费消息</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-consumer.sh --bootstrap-server kafka-host:port --topic test-topic --group test-group --from-beginning --consumer-property enable.auto.commit=<span class=\"hljs-literal\">false</span></span> <br></code></pre></td></tr></table></figure>\n<h3 id=\"测试生产者性能\"><a class=\"markdownIt-Anchor\" href=\"#测试生产者性能\"></a> 测试生产者性能</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-producer-perf-test.sh --topic test-topic --num-records 10000000 --throughput -1 --record-size 1024 --producer-props bootstrap.servers=kafka-host:port acks=-1</span> <br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">返回值</span><br>linger.ms=2000 compression.type=lz4 2175479 records sent, 435095.8 records/sec (424.90 MB/sec), 131.1 ms avg latency, 681.0 ms max latency. 4190124 records sent, 838024.8 records/sec (818.38 MB/sec), 4.4 ms avg latency, 73.0 ms max latency. 10000000 records sent, 737463.126844 records/sec (720.18 MB/sec), 31.81 ms avg latency, 681.00 ms max latency, 4 ms 50th, 126 ms 95th, 604 ms 99th, 672 ms 99.9th.<br></code></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>上述命令， 向指定主题发送了 1 千万条消息，每条消息大小是 1KB，</p>\n</li>\n<li>\n<p>上述输出，表明测试生产者生产的消息中，有 99% 消息的延时都在 604ms 以内。</p>\n<p>你完全可以把这个数据当作这个生产者对外承诺的 SLA。</p>\n</li>\n</ul>\n<h3 id=\"测试消费者性能\"><a class=\"markdownIt-Anchor\" href=\"#测试消费者性能\"></a> 测试消费者性能</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-consumer-perf-test.sh --broker-list kafka-host:port --messages 10000000 --topic test-topic</span> <br><span class=\"hljs-meta\">#</span><span class=\"bash\">返回值</span><br>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec 2019-06-26 15:24:18:138, 2019-06-26 15:24:23:805, 9765.6202, 1723.2434, 10000000, 1764602.0822, 16, 5651, 1728.1225, 1769598.3012<br></code></pre></td></tr></table></figure>\n<h3 id=\"查看topic消息总数\"><a class=\"markdownIt-Anchor\" href=\"#查看topic消息总数\"></a> 查看topic消息总数</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">#</span><span class=\"bash\">最早位移</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -2 --topic test-topic</span><br> <br>test-topic:0:0<br>test-topic:1:0<br><span class=\"hljs-meta\"></span><br><span class=\"hljs-meta\">#</span><span class=\"bash\">最新位移</span><br><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list kafka-host:port --time -1 --topic test-topic</span><br> <br>test-topic:0:5500000<br>test-topic:1:5500000<br><br></code></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>消息总数 =  最早位移 + 最新位移</p>\n</li>\n<li>\n<p>对于本例，test-topic 总的消息数为 5500000 + 5500000，等于 1100 万条。</p>\n</li>\n</ul>\n<h3 id=\"查询消费者组位移\"><a class=\"markdownIt-Anchor\" href=\"#查询消费者组位移\"></a> 查询消费者组位移</h3>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs shell\"><span class=\"hljs-meta\">$</span><span class=\"bash\"> bin/kafka-console-consumer-groups.sh --bootstrap-server kafka-host:port --describe --group test-group</span><br></code></pre></td></tr></table></figure>\n<ul>\n<li>CURRENT-OFFSET 表示该消费者当前消费的最新位移，</li>\n<li>LOG-END-OFFSET 表示对应分区最新生产消息的位移，</li>\n<li>LAG 列是两者的差值。</li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"ckrw7oxmk0006cpfy6pus5thn","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxmw000scpfya029fvjw"},{"post_id":"ckrw7oxmk0006cpfy6pus5thn","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxmx000wcpfy4r3has97"},{"post_id":"ckrw7oxmd0001cpfydflo258b","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxmy000zcpfy27852uyg"},{"post_id":"ckrw7oxmd0001cpfydflo258b","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxmz0012cpfyfqau7slf"},{"post_id":"ckrw7oxml0007cpfy96tk8kkj","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn00015cpfy2yz0e6z1"},{"post_id":"ckrw7oxml0007cpfy96tk8kkj","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxn1001acpfyej5f9b3i"},{"post_id":"ckrw7oxmn000acpfy65xj4jj9","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn2001ecpfyad10e9ei"},{"post_id":"ckrw7oxmn000acpfy65xj4jj9","category_id":"ckrw7oxmy000ycpfy8zad24u2","_id":"ckrw7oxn3001hcpfy1zjs9gir"},{"post_id":"ckrw7oxmg0002cpfyar9gcl2u","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn4001kcpfy486yf4xd"},{"post_id":"ckrw7oxmg0002cpfyar9gcl2u","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxn5001ocpfydz986jgb"},{"post_id":"ckrw7oxmo000bcpfy2ve0dvea","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn6001scpfy3jz7cfgl"},{"post_id":"ckrw7oxmo000bcpfy2ve0dvea","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxn7001vcpfydegq7gcs"},{"post_id":"ckrw7oxmp000ecpfy3so7dcxv","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn7001xcpfy7qgx1hpk"},{"post_id":"ckrw7oxmp000ecpfy3so7dcxv","category_id":"ckrw7oxmy000ycpfy8zad24u2","_id":"ckrw7oxn8001zcpfy40ubg75g"},{"post_id":"ckrw7oxmj0005cpfycti684r8","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn80021cpfy402w9ba8"},{"post_id":"ckrw7oxmj0005cpfycti684r8","category_id":"ckrw7oxmr000gcpfy2med1uq7","_id":"ckrw7oxn90023cpfy9c4n5tdr"},{"post_id":"ckrw7oxmr000fcpfy12d2hmg6","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxn90026cpfy49d7ht72"},{"post_id":"ckrw7oxmr000fcpfy12d2hmg6","category_id":"ckrw7oxmy000ycpfy8zad24u2","_id":"ckrw7oxna0029cpfy4kb92olw"},{"post_id":"ckrw7oxms000icpfyarnne0v4","category_id":"ckrw7oxmh0003cpfyh409gmwa","_id":"ckrw7oxna002bcpfyh2d9b125"},{"post_id":"ckrw7oxms000icpfyarnne0v4","category_id":"ckrw7oxmy000ycpfy8zad24u2","_id":"ckrw7oxnc002fcpfyd1wr852g"},{"post_id":"ckrw7oxmt000kcpfy0fq316ig","category_id":"ckrw7oxn90025cpfyhh240stb","_id":"ckrw7oxnd002icpfy7i647fuy"},{"post_id":"ckrw7oxmv000qcpfy8ramf0l1","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxnf002tcpfybsun0yhp"},{"post_id":"ckrw7oxmw000vcpfy8hvl9n97","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxnf002xcpfy8pqn7pic"},{"post_id":"ckrw7oxmx000xcpfy2rubfwcu","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxng0032cpfy8dv39mao"},{"post_id":"ckrw7oxmz0011cpfy0a4ndh22","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxnh0036cpfy3qj1a3gi"},{"post_id":"ckrw7oxn00014cpfy6bh12q85","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxni0039cpfyhk4vfi2e"},{"post_id":"ckrw7oxn10019cpfy2mg38xhc","category_id":"ckrw7oxnd002jcpfycig7frzb","_id":"ckrw7oxni003ccpfy7jimfu2v"},{"post_id":"ckrw7oxmu000ocpfy22pl2lvc","category_id":"ckrw7oxna002dcpfy7turblvd","_id":"ckrw7oxnn003vcpfy1e4a894y"},{"post_id":"ckrw7oxmu000ocpfy22pl2lvc","category_id":"ckrw7oxnm003ocpfy8haebs3p","_id":"ckrw7oxnn003xcpfydg4v1ju7"},{"post_id":"ckrw7oxn2001ccpfyewdf8z1m","category_id":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxnp0041cpfycbgzhrw9"},{"post_id":"ckrw7oxn2001ccpfyewdf8z1m","category_id":"ckrw7oxnm003scpfy7ug16iys","_id":"ckrw7oxnq0043cpfy93cyc3so"},{"post_id":"ckrw7oxn3001gcpfydp892qnt","category_id":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxnq0046cpfygcmyer9r"},{"post_id":"ckrw7oxn3001gcpfydp892qnt","category_id":"ckrw7oxnm003scpfy7ug16iys","_id":"ckrw7oxnq0047cpfy4a7beb4w"},{"post_id":"ckrw7oxn4001icpfy3p8782yr","category_id":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxnr004bcpfydek73ait"},{"post_id":"ckrw7oxn4001icpfy3p8782yr","category_id":"ckrw7oxnm003scpfy7ug16iys","_id":"ckrw7oxnr004dcpfy46gh0816"},{"post_id":"ckrw7oxn5001mcpfy3m5cd3eu","category_id":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxns004fcpfydq1fbmkx"},{"post_id":"ckrw7oxn5001mcpfy3m5cd3eu","category_id":"ckrw7oxnm003scpfy7ug16iys","_id":"ckrw7oxns004gcpfy9w96hclp"},{"post_id":"ckrw7oxn6001pcpfyfm990z67","category_id":"ckrw7oxnh0038cpfy7sr913ug","_id":"ckrw7oxns004jcpfyhhxm5mgp"},{"post_id":"ckrw7oxn6001pcpfyfm990z67","category_id":"ckrw7oxnm003scpfy7ug16iys","_id":"ckrw7oxns004lcpfy211506u2"}],"PostTag":[{"post_id":"ckrw7oxmd0001cpfydflo258b","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxmt000jcpfycork64w3"},{"post_id":"ckrw7oxmd0001cpfydflo258b","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxmu000mcpfy325ne6c2"},{"post_id":"ckrw7oxmd0001cpfydflo258b","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxmv000pcpfyffm534e9"},{"post_id":"ckrw7oxms000icpfyarnne0v4","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxmw000tcpfy87ikhwue"},{"post_id":"ckrw7oxmg0002cpfyar9gcl2u","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxmz0013cpfy1einf1lz"},{"post_id":"ckrw7oxmg0002cpfyar9gcl2u","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxn00016cpfyhm3g7gg2"},{"post_id":"ckrw7oxmg0002cpfyar9gcl2u","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxn1001bcpfy67yw4a7h"},{"post_id":"ckrw7oxmj0005cpfycti684r8","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxn5001ncpfy89h8h938"},{"post_id":"ckrw7oxmj0005cpfycti684r8","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxn6001qcpfyaq90cl8w"},{"post_id":"ckrw7oxmj0005cpfycti684r8","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxn7001ucpfy70n88lof"},{"post_id":"ckrw7oxmk0006cpfy6pus5thn","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxn90024cpfye8cu5wfp"},{"post_id":"ckrw7oxmk0006cpfy6pus5thn","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxn90027cpfyg38w8vki"},{"post_id":"ckrw7oxmk0006cpfy6pus5thn","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxna002acpfy4b5ae9f0"},{"post_id":"ckrw7oxmk0006cpfy6pus5thn","tag_id":"ckrw7oxn7001ycpfy3t0u9iny","_id":"ckrw7oxna002ccpfy2ibud2r8"},{"post_id":"ckrw7oxml0007cpfy96tk8kkj","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxnc002gcpfy5cvd3icr"},{"post_id":"ckrw7oxml0007cpfy96tk8kkj","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxnd002hcpfy8hjje574"},{"post_id":"ckrw7oxml0007cpfy96tk8kkj","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxnd002lcpfyckgk4ejz"},{"post_id":"ckrw7oxmn000acpfy65xj4jj9","tag_id":"ckrw7oxna002ecpfye9da049h","_id":"ckrw7oxnd002mcpfyadmw8ffz"},{"post_id":"ckrw7oxmo000bcpfy2ve0dvea","tag_id":"ckrw7oxmj0004cpfy0se4g3tz","_id":"ckrw7oxne002pcpfy932a5hd7"},{"post_id":"ckrw7oxmo000bcpfy2ve0dvea","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxne002qcpfydmlnadmz"},{"post_id":"ckrw7oxmo000bcpfy2ve0dvea","tag_id":"ckrw7oxmp000dcpfygy92fovl","_id":"ckrw7oxnf002ucpfy05k51tjy"},{"post_id":"ckrw7oxmp000ecpfy3so7dcxv","tag_id":"ckrw7oxna002ecpfye9da049h","_id":"ckrw7oxnf002vcpfy8dipavza"},{"post_id":"ckrw7oxmr000fcpfy12d2hmg6","tag_id":"ckrw7oxmm0009cpfy50x94fgy","_id":"ckrw7oxng002zcpfy0w1u5huv"},{"post_id":"ckrw7oxmr000fcpfy12d2hmg6","tag_id":"ckrw7oxne002rcpfy27s74xdo","_id":"ckrw7oxng0030cpfy3x5fd3re"},{"post_id":"ckrw7oxmt000kcpfy0fq316ig","tag_id":"ckrw7oxnf002ycpfycksm5wrv","_id":"ckrw7oxnh0034cpfy4qix6mh8"},{"post_id":"ckrw7oxmu000ocpfy22pl2lvc","tag_id":"ckrw7oxng0033cpfy1er7dnij","_id":"ckrw7oxni003bcpfy9mts8de5"},{"post_id":"ckrw7oxmu000ocpfy22pl2lvc","tag_id":"ckrw7oxnh0037cpfy9h500anp","_id":"ckrw7oxnj003ecpfydhdddymr"},{"post_id":"ckrw7oxmv000qcpfy8ramf0l1","tag_id":"ckrw7oxni003acpfy9trw96zj","_id":"ckrw7oxnk003lcpfy6b2g9dvj"},{"post_id":"ckrw7oxmv000qcpfy8ramf0l1","tag_id":"ckrw7oxnj003fcpfyawp52pxv","_id":"ckrw7oxnk003mcpfyaj1f1haj"},{"post_id":"ckrw7oxmv000qcpfy8ramf0l1","tag_id":"ckrw7oxnj003hcpfy9mvp9fiz","_id":"ckrw7oxnm003pcpfyhag54htr"},{"post_id":"ckrw7oxmw000vcpfy8hvl9n97","tag_id":"ckrw7oxnj003hcpfy9mvp9fiz","_id":"ckrw7oxnm003rcpfyeijn9hu3"},{"post_id":"ckrw7oxmw000vcpfy8hvl9n97","tag_id":"ckrw7oxnj003fcpfyawp52pxv","_id":"ckrw7oxnn003tcpfy2ne91vdf"},{"post_id":"ckrw7oxmx000xcpfy2rubfwcu","tag_id":"ckrw7oxnj003hcpfy9mvp9fiz","_id":"ckrw7oxnp003zcpfye9grgnm4"},{"post_id":"ckrw7oxmx000xcpfy2rubfwcu","tag_id":"ckrw7oxnj003fcpfyawp52pxv","_id":"ckrw7oxnp0042cpfyabe4c088"},{"post_id":"ckrw7oxmz0011cpfy0a4ndh22","tag_id":"ckrw7oxnn003ycpfy0plnafvz","_id":"ckrw7oxnr0049cpfycz5oa5mt"},{"post_id":"ckrw7oxmz0011cpfy0a4ndh22","tag_id":"ckrw7oxnj003fcpfyawp52pxv","_id":"ckrw7oxnr004ccpfy3yg4d250"},{"post_id":"ckrw7oxn00014cpfy6bh12q85","tag_id":"ckrw7oxnn003ycpfy0plnafvz","_id":"ckrw7oxns004icpfy79r5hf9u"},{"post_id":"ckrw7oxn00014cpfy6bh12q85","tag_id":"ckrw7oxnj003fcpfyawp52pxv","_id":"ckrw7oxns004kcpfyh9l85vmk"},{"post_id":"ckrw7oxn10019cpfy2mg38xhc","tag_id":"ckrw7oxns004hcpfy039v7gve","_id":"ckrw7oxnt004ocpfybfe2hhwl"},{"post_id":"ckrw7oxn10019cpfy2mg38xhc","tag_id":"ckrw7oxnj003hcpfy9mvp9fiz","_id":"ckrw7oxnt004pcpfy4fp639mu"},{"post_id":"ckrw7oxn2001ccpfyewdf8z1m","tag_id":"ckrw7oxnt004ncpfy2hq0dquj","_id":"ckrw7oxnu004rcpfy9b5h63s3"},{"post_id":"ckrw7oxn3001gcpfydp892qnt","tag_id":"ckrw7oxnt004ncpfy2hq0dquj","_id":"ckrw7oxnu004tcpfyecdp82hv"},{"post_id":"ckrw7oxn4001icpfy3p8782yr","tag_id":"ckrw7oxnt004ncpfy2hq0dquj","_id":"ckrw7oxnu004vcpfy9l0kemdy"},{"post_id":"ckrw7oxn5001mcpfy3m5cd3eu","tag_id":"ckrw7oxnt004ncpfy2hq0dquj","_id":"ckrw7oxnv004xcpfy7gn0eij9"},{"post_id":"ckrw7oxn6001pcpfyfm990z67","tag_id":"ckrw7oxnt004ncpfy2hq0dquj","_id":"ckrw7oxnv004ycpfy9o9wfk0i"}],"Tag":[{"name":"中间件","_id":"ckrw7oxmj0004cpfy0se4g3tz"},{"name":"分库分表","_id":"ckrw7oxmm0009cpfy50x94fgy"},{"name":"mycat","_id":"ckrw7oxmp000dcpfygy92fovl"},{"name":"dockerfile","_id":"ckrw7oxn7001ycpfy3t0u9iny"},{"name":"innodb","_id":"ckrw7oxna002ecpfye9da049h"},{"name":"分布式事务","_id":"ckrw7oxne002rcpfy27s74xdo"},{"name":"rpc","_id":"ckrw7oxnf002ycpfycksm5wrv"},{"name":"java","_id":"ckrw7oxng0033cpfy1er7dnij"},{"name":"实用开发小抄","_id":"ckrw7oxnh0037cpfy9h500anp"},{"name":"mysql","_id":"ckrw7oxni003acpfy9trw96zj"},{"name":"技术规范","_id":"ckrw7oxnj003fcpfyawp52pxv"},{"name":"设计","_id":"ckrw7oxnj003hcpfy9mvp9fiz"},{"name":"devOps","_id":"ckrw7oxnn003ycpfy0plnafvz"},{"name":"注册中心","_id":"ckrw7oxns004hcpfy039v7gve"},{"name":"kafka","_id":"ckrw7oxnt004ncpfy2hq0dquj"}]}}