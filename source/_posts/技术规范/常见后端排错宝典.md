---
title: 常见后端排错宝典
toc: true
categories:
  - 技术规范

tags:
  - 技术规范
  - 运维
hide: true
sortn: 0
date: 2021-08-04 00:01:47
---

线上有问题，不要急着跑路。先试试这边排错宝典，无需自宫，轻松超神。
<!-- more -->

------



# 常见后端排错宝典



## 1. 确定排错的环境



### 测试环境

测试环境可以使用远程断点、 Arthas、等附加进程进行排错。

测试环境也允许造数据，制造压力场景。



### 生产环境

1. 线上服务，首先进行恢复，回滚。
2. 保留oom日志，dump日志。如果是死锁，cpu飙升，则先不管原因，回滚后去测试环境查。
3. 如果不紧急，比如mis后台，可以先申请暂停使用，尽量不要超过40分钟。
4. 通过日志，监控，快照，arthas进行分析。



#### 工具：Arthas 快速下载

- 神器：https://arthas.aliyun.com/doc/

- `wget https://arthas.aliyun.com/arthas-boot.jar;java -jar arthas-boot.jar`

- 命令列表https://arthas.aliyun.com/doc/commands.html



### 常见问题解决思路



#### 程序发布后，立即显现的bug

先无脑回滚，然后再解决，一般是数据问题，要不然早测出来了。





#### CPU

- 使用 top、vmstat、pidstat、ps 等工具排查

  1. $`top`：找到cpu100%的Pid。

  2. $`top -Hp 进程号`：查看java进程下的所有线程占CPU的情况。

  3. $`printf "%x\n" 线程ID`： 后面查看线程都需要16进制数。<br>例如，printf "%x\n" 线程ID ，打印：16b1，那么在jstack中线程号就是16b1

  4. $ `jstack 进程号 | grep 线程ID` ：通过jstack查看某一个线程。nid表示那个线程的状态。<br>例如`"VM Thread" os_prio=0 tid=0x00007f871806e000 nid=0x16b1 runnable`，<br>线程名=VM Thread，线程id=0x16b1，线程状态=runnable

  5. $`jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一直统计）`，查看某进程GC持续变化情况，

     ```shell
     shell@Alicloud:~$ jstat -gcutil 1287 100 100
       S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   
       0.00   0.00  58.86  60.00  98.26  96.89     93    0.409     3    0.265    0.674
       0.00   0.00  58.86  60.00  98.26  96.89     93    0.409     3    0.265    0.674
       0.00   0.00  58.86  60.00  98.26  96.89     93    0.409     3    0.265    0.674
       0.00   0.00  58.86  60.00  98.26  96.89     93    0.409     3    0.265    0.674
     ```

     如果FGC很大，且一直增大，可以确认Full GC! 

     S0 S1 E 为新生代
     O为老年代
     M是元区间(方法区)
     YGC新生代执行次数
     YGCT新生代执行时间
     FGC老年代执行次数
     FGCT老年代执行时间
     GCT总垃圾回收时间（单位秒）

  6. $`jmap -dump:format=b,file=dump_01.hprof pid`，导出某进程下内存heap输出到文件中。通过eclipse的mat工具查看内存中有哪些对象比较多。分析Full GC

- 使用 arthas

  - 查看CPU使用率top n线程的栈 

    `thread -n 3`

  - 查找线程是否有阻塞

    `thread -b`

- 有可能的点

  - hashmap，并发死循环
  - Full GC次数过多
  - 正则表达式非常消耗 CPU
  - 分布式锁的重试机制
  - 乐观锁、cas循环次数过多，或者竞争激烈
  - Redis的端口6379被注入挖矿程序
  - 突发压力，看看是不是攻击。查Nginx Access Log 



#### 内存

- 使用 free、top、ps、vmstat、cachestat、sar 等工具排查

排查流程：

​		通过堆转储后使用 MAT 分析。包含了堆现场全貌和线程栈信息，一般观察支配树图、直方图，查看占用大量内存的对象，快速定位到内存相关问题。

注意点：

​		Java 进程对内存的使用不仅仅是堆区，还包括线程使用的内存(线程个数 * 每一个线程的线程栈)和元数据区。每一个内存区都可能产生 OOM，可以结合监控观察 线程数、已加载类数量等指标分析。另外，我们需要注意看一下，JVM 参数的设置是否有 明显不合理的地方，限制了资源使用



**IO 问题**

IO 相关的问题，除非是代码问题引起的资源不释放等问题，否则通常都不是由 Java 进程 内部因素引发的。



**网络相关**

网络相关的问题，一般也是由外部因素引起的。对于连通性问题，结合异常信息通常比较容 易定位;对于性能或瞬断问题，可以先尝试使用 ping 等工具简单判断，如果不行再使用 tcpdump 或 Wireshark 来分析





1. 程序外部外部因素，主机问题。

   解决方案：

   **CPU** 相关问题，可以使用 top、vmstat、pidstat、ps 等工具排查;

   **内存**相关问题，可以使用 free、top、ps、vmstat、cachestat、sar 等工具排查;

   **IO** 相关问题，可以使用 lsof、iostat、pidstat、sar、iotop、df、du 等工具排查;

   **网络**相关问题，可以使用 ifconfig、ip、nslookup、dig、ping、tcpdump、iptables 等工具排查。

2. 依赖的中间件问题，比如 mysql， redis，kafka不可用

   1. 先排查网络问题，中间件稳定性较高，没有特殊情况，本身不容易挂
   2. 如果是私有化部署，排查那台机器有没有问题，可以通过运维平台看主机信息。
   3. 排查组件进程基本情况，观察各种监控指标;
   4. 查看组件的日志输出，特别是错误日志，中间件日志，尽量接入日志平台。
   5. 进入组件控制台，使用一些命令查看其运作情况。

3. 程序假死的问题，通常需要先通过重启和扩容解决问题，之后再进行分析，不过最好能留一个节点作为现场。

   

   
